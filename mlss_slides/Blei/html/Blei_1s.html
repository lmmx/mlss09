<!DOCTYPE html><html>
<head>
<title></title>
<style type="text/css">
<!--
.xflip {
    -moz-transform: scaleX(-1);
    -webkit-transform: scaleX(-1);
    -o-transform: scaleX(-1);
    transform: scaleX(-1);
    filter: fliph;
}
.yflip {
    -moz-transform: scaleY(-1);
    -webkit-transform: scaleY(-1);
    -o-transform: scaleY(-1);
    transform: scaleY(-1);
    filter: flipv;
}
.xyflip {
    -moz-transform: scaleX(-1) scaleY(-1);
    -webkit-transform: scaleX(-1) scaleY(-1);
    -o-transform: scaleX(-1) scaleY(-1);
    transform: scaleX(-1) scaleY(-1);
    filter: fliph + flipv;
}
-->
</style>
</head>
<body>
<a name=1></a>Topic&#160;Models<br/>
David&#160;M.&#160;Blei<br/>
Department&#160;of&#160;Computer&#160;Science<br/>
Princeton&#160;University<br/>
September&#160;1,&#160;2009<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#81">Topic&#160;Models</a><br/>
<hr/>
<a name=2></a><img src="./Blei_1-2_1.jpg"/><br/>
The&#160;problem&#160;with&#160;information<br/>
As&#160;more&#160;information&#160;becomes<br/>available,&#160;it&#160;becomes&#160;more&#160;difficult<br/>to&#160;access&#160;what&#160;we&#160;are&#160;looking&#160;for.<br/>
We&#160;need&#160;new&#160;tools&#160;to&#160;help&#160;us<br/>organize,&#160;search,&#160;and&#160;understand<br/>these&#160;vast&#160;amounts&#160;of&#160;information.<br/>
www.betaversion.org/~stefano/linotype/news/26/<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=3></a><img src="./Blei_1-3_1.jpg"/><br/>
Topic&#160;modeling<br/>
Candida Hofer&#160;<br/>
Topic&#160;modeling&#160;provides&#160;methods&#160;for&#160;automatically&#160;organizing,<br/>understanding,&#160;searching,&#160;and&#160;summarizing&#160;large&#160;electronic&#160;archives.<br/>
1&#160;Uncover&#160;the&#160;hidden&#160;topical&#160;patterns&#160;that&#160;pervade&#160;the&#160;collection.<br/>
2&#160;Annotate&#160;the&#160;documents&#160;according&#160;to&#160;those&#160;topics.<br/>
3&#160;Use&#160;the&#160;annotations&#160;to&#160;organize,&#160;summarize,&#160;and&#160;search&#160;the&#160;texts.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=4></a>Discover&#160;topics&#160;from&#160;a&#160;corpus<br/>
“Genetics”<br/>
“Evolution”<br/>
“Disease”<br/>
“Computers”<br/>
human<br/>
evolution<br/>
disease<br/>
computer<br/>
genome<br/>
evolutionary<br/>
host<br/>
models<br/>
dna<br/>
species<br/>
bacteria<br/>
information<br/>
genetic<br/>
organisms<br/>
diseases<br/>
data<br/>
genes<br/>
life<br/>
resistance<br/>
computers<br/>
sequence<br/>
origin<br/>
bacterial<br/>
system<br/>
gene<br/>
biology<br/>
new<br/>
network<br/>
molecular<br/>
groups<br/>
strains<br/>
systems<br/>
sequencing<br/>
phylogenetic<br/>
control<br/>
model<br/>
map<br/>
living<br/>
infectious<br/>
parallel<br/>
information<br/>
diversity<br/>
malaria<br/>
methods<br/>
genetics<br/>
group<br/>
parasite<br/>
networks<br/>
mapping<br/>
new<br/>
parasites<br/>
software<br/>
project<br/>
two<br/>
united<br/>
new<br/>
sequences<br/>
common<br/>
tuberculosis<br/>
simulations<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=5></a>Model&#160;the&#160;evolution&#160;of&#160;topics&#160;over&#160;time<br/>
<b>&#34;Theoretical Physics&#34;</b><br/>
<b>&#34;Neuroscience&#34;</b><br/>
FORCE<br/>
OXYGEN<br/>
o&#160;o<br/>
o<br/>
LASER<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o&#160;o&#160;o<br/>
NERVE<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o&#160;o<br/>
o&#160;o<br/>
o<br/>
o<br/>
o<br/>
o&#160;o<br/>
o&#160;o&#160;o&#160;o<br/>
o<br/>
o<br/>
o<br/>
o&#160;o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
RELATIVITY<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o&#160;o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o&#160;o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
NEURON<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o&#160;o&#160;o&#160;o&#160;o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o&#160;o&#160;o<br/>
o<br/>
o<br/>
o&#160;o&#160;o&#160;o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o<br/>
o&#160;o&#160;o&#160;o&#160;o&#160;o&#160;o&#160;o&#160;o&#160;o&#160;o&#160;o&#160;o<br/>
o<br/>
o&#160;o<br/>
o<br/>
o&#160;o&#160;o&#160;o&#160;o<br/>
o<br/>
o&#160;o&#160;o&#160;o&#160;o&#160;o&#160;o&#160;o&#160;o<br/>
o<br/>
o&#160;o<br/>
o&#160;o<br/>
1880<br/>
1900<br/>
1920<br/>
1940<br/>
1960<br/>
1980<br/>
2000<br/>
1880<br/>
1900<br/>
1920<br/>
1940<br/>
1960<br/>
1980<br/>
2000<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=6></a>Model&#160;connections&#160;between&#160;topics<br/>
neurons<br/>stimulus<br/>
brain<br/>
motor<br/>
memory<br/>
visual<br/>
activated<br/>
subjects<br/>
synapses<br/>
cortical<br/>
tyrosine phosphorylation<br/>
left<br/>
ltp<br/>
activation<br/>
p53<br/>
task<br/>
surface<br/>
glutamate<br/>
phosphorylation<br/>
cell cycle<br/>
proteins<br/>
kinase<br/>
tip<br/>
synaptic<br/>
activity<br/>
protein<br/>
neurons<br/>
cyclin<br/>
rna<br/>
image<br/>
binding<br/>
regulation<br/>
dna<br/>
domain<br/>
computer<br/>
sample<br/>
materials<br/>
rna polymerase<br/>
organic<br/>
receptor<br/>
domains<br/>
problem<br/>
cleavage<br/>
device<br/>
polymer<br/>
science<br/>
amino acids<br/>
information<br/>
research<br/>
site<br/>
polymers<br/>
receptors<br/>
scientists<br/>
cdna<br/>
computers<br/>
funding<br/>
molecules<br/>
physicists<br/>
says<br/>
ligand<br/>
sequence<br/>
problems<br/>
support<br/>
laser<br/>
particles<br/>
research<br/>
isolated<br/>
nih<br/>
ligands<br/>
optical<br/>
physics<br/>
people<br/>
protein<br/>
program<br/>
sequence<br/>
light<br/>
apoptosis<br/>
particle<br/>
sequences<br/>
surface<br/>
electrons<br/>
experiment<br/>
genome<br/>
liquid<br/>
wild type<br/>
quantum<br/>
dna<br/>
surfaces<br/>
stars<br/>
mutant<br/>
enzyme<br/>
sequencing<br/>
fluid<br/>
mutations<br/>
enzymes<br/>
model<br/>
reaction<br/>
astronomers<br/>
united states<br/>
iron<br/>
mutants<br/>
reactions<br/>
active site<br/>
universe<br/>
mutation<br/>
women<br/>
reduction<br/>
molecule<br/>
cells<br/>
galaxies<br/>
cell<br/>
universities<br/>
molecules<br/>
expression<br/>
magnetic<br/>
galaxy<br/>
cell lines<br/>
magnetic field<br/>
plants<br/>
students<br/>
transition state<br/>
bone marrow<br/>
spin<br/>
plant<br/>
superconductivity<br/>
gene<br/>
education<br/>
superconducting<br/>
genes<br/>
pressure<br/>
mantle<br/>
arabidopsis<br/>
bacteria<br/>
high pressure<br/>
crust<br/>
sun<br/>
bacterial<br/>
pressures<br/>
upper mantle<br/>
solar wind<br/>
host<br/>
fossil record<br/>
core<br/>
meteorites<br/>
earth<br/>
resistance<br/>
birds<br/>
inner core<br/>
ratios<br/>
development<br/>
planets<br/>
mice<br/>
parasite<br/>
fossils<br/>
planet<br/>
gene<br/>
embryos<br/>
antigen<br/>
dinosaurs<br/>
species<br/>
virus<br/>
disease<br/>
drosophila<br/>
t cells<br/>
fossil<br/>
forest<br/>
hiv<br/>
mutations<br/>
genes<br/>
antigens<br/>
forests<br/>
aids<br/>
families<br/>
expression<br/>
earthquake<br/>
immune response<br/>
populations<br/>
co2<br/>
infection<br/>
mutation<br/>
earthquakes<br/>
ecosystems<br/>
carbon<br/>
viruses<br/>
fault<br/>
carbon dioxide<br/>
ancient<br/>
images<br/>
methane<br/>
patients<br/>
genetic<br/>
found<br/>
data<br/>
water<br/>
disease<br/>
cells<br/>
population<br/>
impact<br/>
ozone<br/>
treatment<br/>
proteins<br/>
populations<br/>
million years ago<br/>
volcanic<br/>
atmospheric<br/>
drugs<br/>
differences<br/>
africa<br/>
clinical<br/>
researchers<br/>
deposits<br/>
measurements<br/>
climate<br/>
variation<br/>
magma<br/>
stratosphere<br/>
ocean<br/>
protein<br/>
eruption<br/>
ice<br/>
concentrations<br/>
found<br/>
volcanism<br/>
changes<br/>
climate change<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=7></a><img src="./Blei_1-7_1.jpg"/><br/>
<img src="./Blei_1-7_2.jpg"/><br/>
<img src="./Blei_1-7_3.jpg"/><br/>
<img src="./Blei_1-7_4.jpg"/><br/>
<img src="./Blei_1-7_5.jpg"/><br/>
<img src="./Blei_1-7_6.jpg"/><br/>
<img src="./Blei_1-7_7.jpg"/><br/>
<img src="./Blei_1-7_8.jpg"/><br/>
<img src="./Blei_1-7_9.jpg"/><br/>
<img src="./Blei_1-7_10.jpg"/><br/>
<img src="./Blei_1-7_11.jpg"/><br/>
<img src="./Blei_1-7_12.jpg"/><br/>
<img src="./Blei_1-7_13.jpg"/><br/>
<img src="./Blei_1-7_14.jpg"/><br/>
<img src="./Blei_1-7_15.jpg"/><br/>
<img src="./Blei_1-7_16.jpg"/><br/>
<img src="./Blei_1-7_17.jpg"/><br/>
<img src="./Blei_1-7_18.jpg"/><br/>
<img src="./Blei_1-7_19.jpg"/><br/>
<img src="./Blei_1-7_20.jpg"/><br/>
<img src="./Blei_1-7_21.jpg"/><br/>
<img src="./Blei_1-7_22.jpg"/><br/>
<img src="./Blei_1-7_23.jpg"/><br/>
<img src="./Blei_1-7_24.jpg"/><br/>
<img src="./Blei_1-7_25.jpg"/><br/>
<img src="./Blei_1-7_26.jpg"/><br/>
<img src="./Blei_1-7_27.jpg"/><br/>
<img src="./Blei_1-7_28.jpg"/><br/>
<img src="./Blei_1-7_29.jpg"/><br/>
<img src="./Blei_1-7_30.jpg"/><br/>
<img src="./Blei_1-7_31.jpg"/><br/>
<img src="./Blei_1-7_32.jpg"/><br/>
<img src="./Blei_1-7_33.jpg"/><br/>
<img src="./Blei_1-7_34.jpg"/><br/>
<img src="./Blei_1-7_35.jpg"/><br/>
<img src="./Blei_1-7_36.jpg"/><br/>
<b>Automatic&#160;image&#160;annotationAutomatic&#160;image&#160;annotation</b><br/>
Annotate&#160;images<br/>
<b>Automatic&#160;image&#160;annotation</b><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<b>Automatic&#160;image&#160;annotation</b><br/>
sky water tree mountain people<br/>
birds nest leaves branch tree<br/>
people market pattern textile display<br/>
sky water tree mountain people<br/>
birds nest leaves branch tree<br/>
people market pattern textile display<br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<b>Automatic&#160;image&#160;annotationAutomatic&#160;image&#160;annotation</b><br/>
fish water ocean tree coral<br/>
sky water tree mountain people<br/>
SKY&#160;WATER&#160;TREE<br/>
SCOTLAND&#160;WATER<br/>
birds nest leaves branch tree<br/>
sky water buildings people mountain<br/>
people market pattern textile display<br/>
scotland water flowers hills tree<br/>
fish water ocean tree coral<br/>
SK&#160;sky water buildings people mountain<br/>
Y&#160;WATER&#160;BUILDING<br/>
scotland water flowers hills tree<br/>
MOUNTAIN&#160;P<br/>
<i>predicted caption:&#160;</i>EOPLE<br/>
FLOWER&#160;H<br/>
<i>predicted caption:&#160;</i>ILLS&#160;TREE<br/>
PEO<br/>
<i>predicted caption:&#160;</i>PLE&#160;WATER<br/>
sky water tree mountain people<br/>
birds nest leaves branch tree<br/>
people market pattern textile display<br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
fish water ocean tree coral<br/>
sky water buildings people mountain&#160;scotland water flowers hills tree<br/>
Probabilistic&#160;modelsof&#160;text&#160;and&#160;images&#160;–&#160;p.5/53<br/>
Probabilistic&#160;modelsof&#160;text&#160;and&#160;images&#160;–&#160;p.5/53<br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
FI&#160;fish water ocean tree coral<br/>
SH&#160;WATER&#160;OCEAN<br/>
sky water tree mountain people<br/>
birds nest leaves branch treePsky water buildings people mountain<br/>
EOPLE&#160;MARKET&#160;PATT&#160;scotland water flowers hills tree<br/>
people market pattern textile display<br/>
ERN<br/>
sky water tree mountain people<br/>
birds nest leaves branch tree<br/>
BIRDS&#160;NEST&#160;TREE<br/>
people market pattern textile display<br/>
TREE&#160;CORAL<br/>
TEXTILE&#160;DISPLAY<br/>
BRANCH&#160;LEAVES<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
Probabilistic&#160;modelsof&#160;text&#160;and&#160;images&#160;–&#160;p.5/53<br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
<i>predicted caption:</i><br/>
fish water ocean tree coral<br/>
sky water buildings people mountain&#160;scotland water flowers hills tree<br/>
fish water ocean tree coral<br/>
sky water buildings people mountain&#160;scotland water flowers hills tree<br/>
Probabilistic&#160;modelsof&#160;text&#160;and&#160;images&#160;–&#160;p.5/53<br/>
Probabilistic&#160;modelsof&#160;text&#160;and&#160;images&#160;–&#160;p.5/53<br/>
Probabilistic&#160;modelsof&#160;text&#160;and&#160;images&#160;–&#160;p.5/53<br/>
<hr/>
<a name=8></a>Topic&#160;modeling&#160;topics<br/>
From&#160;a&#160;machine&#160;learning&#160;perspective,&#160;topic&#160;modeling&#160;is&#160;a&#160;case&#160;study&#160;in<br/>applying&#160;hierarchical&#160;Bayesian&#160;models&#160;to&#160;grouped&#160;data,&#160;like&#160;documents&#160;or<br/>images.&#160;Topic&#160;modeling&#160;research&#160;touches&#160;on<br/>
•&#160;Directed&#160;graphical&#160;models<br/>•&#160;Conjugate&#160;priors&#160;and&#160;nonconjugate&#160;priors<br/>•&#160;Time&#160;series&#160;modeling<br/>•&#160;Modeling&#160;with&#160;graphs<br/>•&#160;Hierarchical&#160;Bayesian&#160;methods<br/>•&#160;Fast&#160;approximate&#160;posterior&#160;inference&#160;(MCMC,&#160;variational&#160;methods)<br/>•&#160;Exploratory&#160;data&#160;analysis<br/>•&#160;Model&#160;selection&#160;and&#160;nonparametric&#160;Bayesian&#160;methods<br/>•&#160;Mixed&#160;membership&#160;models<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=9></a>Latent&#160;Dirichlet&#160;allocation&#160;(LDA)<br/>
1&#160;Introduction&#160;to&#160;LDA<br/>
2&#160;The&#160;posterior&#160;distribution&#160;for&#160;LDA<br/>
Approximate&#160;posterior&#160;inference<br/>
1&#160;Gibbs&#160;sampling<br/>
2&#160;Variational&#160;inference<br/>
3&#160;Comparison/Theory/Advice<br/>
Other&#160;topic&#160;models<br/>
1&#160;Topic&#160;models&#160;for&#160;prediction:&#160;Relational&#160;and&#160;supervised&#160;topic&#160;models<br/>
2&#160;The&#160;logistic&#160;normal:&#160;Dynamic&#160;and&#160;correlated&#160;topic&#160;models<br/>
3&#160;“Infinite”&#160;topic&#160;models,&#160;i.e.,&#160;the&#160;hierarchical&#160;Dirichlet&#160;process<br/>
Interpreting&#160;and&#160;evaluating&#160;topic&#160;models<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=10></a>Latent&#160;Dirichlet&#160;Allocation<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=11></a>Probabilistic&#160;modeling<br/>
1&#160;Treat&#160;data&#160;as&#160;observations&#160;that&#160;arise&#160;from&#160;a&#160;generative&#160;probabilistic<br/>
process&#160;that&#160;includes&#160;hidden&#160;variables<br/>
•&#160;For&#160;documents,&#160;the&#160;hidden&#160;variables&#160;reflect&#160;the&#160;thematic<br/>
structure&#160;of&#160;the&#160;collection.<br/>
2&#160;Infer&#160;the&#160;hidden&#160;structure&#160;using&#160;posterior&#160;inference<br/>
•&#160;What&#160;are&#160;the&#160;topics&#160;that&#160;describe&#160;this&#160;collection?<br/>
3&#160;Situate&#160;new&#160;data&#160;into&#160;the&#160;estimated&#160;model.<br/>
•&#160;How&#160;does&#160;this&#160;query&#160;or&#160;new&#160;document&#160;fit&#160;into&#160;the&#160;estimated<br/>
topic&#160;structure?<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=12></a><img src="./Blei_1-12_1.png"/><br/>
Intuition&#160;behind&#160;LDA<br/>
Simple&#160;intuition:&#160;Documents&#160;exhibit&#160;multiple&#160;topics.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=13></a><img src="./Blei_1-13_1.png"/><br/>
<img src="./Blei_1-13_2.png"/><br/>
<img src="./Blei_1-13_3.png"/><br/>
<img src="./Blei_1-13_4.png"/><br/>
<img src="./Blei_1-13_5.png"/><br/>
<img src="./Blei_1-13_6.png"/><br/>
<img src="./Blei_1-13_7.png"/><br/>
<img src="./Blei_1-13_8.png"/><br/>
<img src="./Blei_1-13_9.png"/><br/>
Generative&#160;model<br/>
<i>Topic proportions and</i><br/>
<i>Topics</i><br/>
<i>Documents</i><br/>
<i>assignments</i><br/>
gene &#160; &#160; 0.04<br/>dna &#160; &#160; &#160;0.02<br/>genetic &#160;0.01<br/>.,,<br/>
life &#160; &#160; 0.02<br/>evolve &#160; 0.01<br/>organism 0.01<br/>.,,<br/>
brain &#160; &#160;0.04<br/>neuron &#160; 0.02<br/>nerve &#160; &#160;0.01<br/>...<br/>
data &#160; &#160; 0.02<br/>number &#160; 0.02<br/>computer 0.01<br/>.,,<br/>
•&#160;Each&#160;document&#160;is&#160;a&#160;random&#160;mixture&#160;of&#160;corpus-wide&#160;topics<br/>
•&#160;Each&#160;word&#160;is&#160;drawn&#160;from&#160;one&#160;of&#160;those&#160;topics<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=14></a><img src="./Blei_1-14_1.png"/><br/>
<img src="./Blei_1-14_2.png"/><br/>
<img src="./Blei_1-14_3.png"/><br/>
<img src="./Blei_1-14_4.png"/><br/>
<img src="./Blei_1-14_5.png"/><br/>
<img src="./Blei_1-14_6.png"/><br/>
<img src="./Blei_1-14_7.png"/><br/>
<img src="./Blei_1-14_8.png"/><br/>
<img src="./Blei_1-14_9.png"/><br/>
The&#160;posterior&#160;distribution<br/>
<i>Topic proportions and</i><br/>
<i>Topics</i><br/>
<i>Documents</i><br/>
<i>assignments</i><br/>
•&#160;In&#160;reality,&#160;we&#160;only&#160;observe&#160;the&#160;documents<br/>
•&#160;Our&#160;goal&#160;is&#160;to&#160;infer&#160;the&#160;underlying&#160;topic&#160;structure<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=15></a>Graphical&#160;models&#160;(Aside)<br/>
Y<br/>
Y<br/>
≡<br/>
·&#160;·&#160;·<br/>
Xn<br/>
X<br/>
N<br/>
1<br/>
X2<br/>
XN<br/>
•&#160;Nodes&#160;are&#160;random&#160;variables<br/>•&#160;Edges&#160;denote&#160;possible&#160;dependence<br/>•&#160;Observed&#160;variables&#160;are&#160;shaded<br/>•&#160;Plates&#160;denote&#160;replicated&#160;structure<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=16></a>Graphical&#160;models&#160;(Aside)<br/>
Y<br/>
Y<br/>
≡<br/>
·&#160;·&#160;·<br/>
Xn<br/>
X<br/>
N<br/>
1<br/>
X2<br/>
XN<br/>
•&#160;Structure&#160;of&#160;the&#160;graph&#160;defines&#160;the&#160;pattern&#160;of&#160;conditional&#160;dependence<br/>
between&#160;the&#160;ensemble&#160;of&#160;random&#160;variables<br/>
•&#160;E.g.,&#160;this&#160;graph&#160;corresponds&#160;to<br/>
N<br/>
Y<br/>
p(y&#160;,&#160;x1,&#160;.&#160;.&#160;.&#160;,&#160;xN&#160;)&#160;=&#160;p(y&#160;)<br/>
p(xn&#160;|&#160;y)<br/>
n=1<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=17></a>Latent&#160;Dirichlet&#160;allocation<br/>
Per-word<br/>
Dirichlet<br/>
topic assignment<br/>
parameter<br/>
Per-document<br/>
Observed<br/>
Topic<br/>
topic proportions<br/>
word<br/>
Topics<br/>
hyperparameter<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k<br/>
η<br/>
D<br/>
K<br/>
Each&#160;piece&#160;of&#160;the&#160;structure&#160;is&#160;a&#160;random&#160;variable.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=18></a>The&#160;Dirichlet&#160;distribution<br/>
•&#160;The&#160;Dirichlet&#160;distribution&#160;is&#160;an&#160;exponential&#160;family&#160;distribution&#160;over<br/>
the&#160;simplex,&#160;i.e.,&#160;positive&#160;vectors&#160;that&#160;sum&#160;to&#160;one<br/>
P<br/>
Γ&#160;(<br/>
α&#160;Y<br/>
i&#160;)<br/>
p(θ&#160;|&#160;~α)&#160;=<br/>
i<br/>
Q<br/>
θαi−1.<br/>
Γ(α<br/>
i<br/>
i<br/>
i&#160;)<br/>
i<br/>
•&#160;The&#160;Dirichlet&#160;is&#160;conjugate&#160;to&#160;the&#160;multinomial.&#160;Given&#160;a&#160;multinomial<br/>
observation,&#160;the&#160;posterior&#160;distribution&#160;of&#160;θ&#160;is&#160;a&#160;Dirichlet.<br/>
•&#160;The&#160;parameter&#160;α&#160;controls&#160;the&#160;mean&#160;shape&#160;and&#160;sparsity&#160;of&#160;θ.<br/>
•&#160;The&#160;topic&#160;proportions&#160;are&#160;a&#160;K&#160;dimensional&#160;Dirichlet.<br/>
The&#160;topics&#160;are&#160;a&#160;V&#160;dimensional&#160;Dirichlet.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=19></a><img src="./Blei_1-19_1.png"/><br/>
The&#160;Dirichlet&#160;distribution<br/>
(From&#160;Wikipedia)<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=20></a>Latent&#160;Dirichlet&#160;allocation<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k<br/>
η<br/>
D<br/>
K<br/>
•&#160;LDA&#160;is&#160;a&#160;mixed&#160;membership&#160;model&#160;(Erosheva,&#160;2004)&#160;that&#160;builds&#160;on<br/>
the&#160;work&#160;of&#160;Deerwester&#160;et&#160;al.&#160;(1990)&#160;and&#160;Hofmann&#160;(1999).<br/>
•&#160;For&#160;document&#160;collections&#160;and&#160;other&#160;grouped&#160;data,&#160;this&#160;might&#160;be<br/>
more&#160;appropriate&#160;than&#160;a&#160;simple&#160;finite&#160;mixture.<br/>
•&#160;The&#160;same&#160;model&#160;was&#160;independently&#160;invented&#160;for&#160;population&#160;genetics<br/>
analysis&#160;(Pritchard&#160;et&#160;al.,&#160;2000).<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=21></a>Latent&#160;Dirichlet&#160;allocation<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k<br/>
η<br/>
D<br/>
K<br/>
•&#160;From&#160;a&#160;collection&#160;of&#160;documents,&#160;infer<br/>
•&#160;Per-word&#160;topic&#160;assignment&#160;zd,n<br/>•&#160;Per-document&#160;topic&#160;proportions&#160;θd<br/>•&#160;Per-corpus&#160;topic&#160;distributions&#160;βk<br/>
•&#160;Use&#160;posterior&#160;expectations&#160;to&#160;perform&#160;the&#160;task&#160;at&#160;hand,&#160;e.g.,<br/>
information&#160;retrieval,&#160;document&#160;similarity,&#160;etc.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=22></a>Latent&#160;Dirichlet&#160;allocation<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k<br/>
η<br/>
D<br/>
K<br/>
Approximate&#160;posterior&#160;inference&#160;algorithms<br/>
•&#160;Mean&#160;field&#160;variational&#160;methods&#160;(Blei&#160;et&#160;al.,&#160;2001,&#160;2003)<br/>•&#160;Expectation&#160;propagation&#160;(Minka&#160;and&#160;Lafferty,&#160;2002)<br/>•&#160;Collapsed&#160;Gibbs&#160;sampling&#160;(Griffiths&#160;and&#160;Steyvers,&#160;2002)<br/>•&#160;Collapsed&#160;variational&#160;inference&#160;(Teh&#160;et&#160;al.,&#160;2006)<br/>
For&#160;comparison,&#160;see&#160;Mukherjee&#160;and&#160;Blei&#160;(2009)&#160;and&#160;Asuncion&#160;et&#160;al.&#160;(2009).<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=23></a><img src="./Blei_1-23_1.png"/><br/>
Example&#160;inference<br/>
•&#160;Data:&#160;The&#160;OCR’ed&#160;collection&#160;of&#160;Science&#160;from&#160;1990–2000<br/>
•&#160;17K&#160;documents<br/>•&#160;11M&#160;words<br/>•&#160;20K&#160;unique&#160;terms&#160;(stop&#160;words&#160;and&#160;rare&#160;words&#160;removed)<br/>
•&#160;Model:&#160;100-topic&#160;LDA&#160;model&#160;using&#160;variational&#160;inference.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=24></a><img src="./Blei_1-24_1.png"/><br/>
Example&#160;inference<br/>
0.4<br/>
0.3<br/>
0.2<br/>
Probability<br/>
0.1<br/>
0.0<br/>
1&#160;8&#160;16&#160;26&#160;36&#160;46&#160;56&#160;66&#160;76&#160;86&#160;96<br/>
Topics<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=25></a>Example&#160;inference<br/>
“Genetics”<br/>
“Evolution”<br/>
“Disease”<br/>
“Computers”<br/>
human<br/>
evolution<br/>
disease<br/>
computer<br/>
genome<br/>
evolutionary<br/>
host<br/>
models<br/>
dna<br/>
species<br/>
bacteria<br/>
information<br/>
genetic<br/>
organisms<br/>
diseases<br/>
data<br/>
genes<br/>
life<br/>
resistance<br/>
computers<br/>
sequence<br/>
origin<br/>
bacterial<br/>
system<br/>
gene<br/>
biology<br/>
new<br/>
network<br/>
molecular<br/>
groups<br/>
strains<br/>
systems<br/>
sequencing<br/>
phylogenetic<br/>
control<br/>
model<br/>
map<br/>
living<br/>
infectious<br/>
parallel<br/>
information<br/>
diversity<br/>
malaria<br/>
methods<br/>
genetics<br/>
group<br/>
parasite<br/>
networks<br/>
mapping<br/>
new<br/>
parasites<br/>
software<br/>
project<br/>
two<br/>
united<br/>
new<br/>
sequences<br/>
common<br/>
tuberculosis<br/>
simulations<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=26></a><img src="./Blei_1-26_1.png"/><br/>
Example&#160;inference&#160;(II)<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=27></a>Example&#160;inference&#160;(II)<br/>
problem<br/>
model<br/>
selection<br/>
species<br/>
problems<br/>
rate<br/>
male<br/>
forest<br/>
mathematical<br/>
constant<br/>
males<br/>
ecology<br/>
number<br/>
distribution<br/>
females<br/>
fish<br/>
new<br/>
time<br/>
sex<br/>
ecological<br/>
mathematics<br/>
number<br/>
species<br/>
conservation<br/>
university<br/>
size<br/>
female<br/>
diversity<br/>
two<br/>
values<br/>
evolution<br/>
population<br/>
first<br/>
value<br/>
populations<br/>
natural<br/>
numbers<br/>
average<br/>
population<br/>
ecosystems<br/>
work<br/>
rates<br/>
sexual<br/>
populations<br/>
time<br/>
data<br/>
behavior<br/>
endangered<br/>
mathematicians<br/>
density<br/>
evolutionary<br/>
tropical<br/>
chaos<br/>
measured<br/>
genetic<br/>
forests<br/>
chaotic<br/>
models<br/>
reproductive<br/>
ecosystem<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=28></a><img src="./Blei_1-28_1.png"/><br/>
<img src="./Blei_1-28_2.png"/><br/>
Used&#160;to&#160;explore&#160;and&#160;browse&#160;document&#160;collections<br/>
<b>Top words from the top topics (by term score)</b><br/>
<b>Expected topic proportions</b><br/>
<b>sequence</b><br/>
<b>measured</b><br/>
<b>residues</b><br/>
<b>computer</b><br/>
<b>region</b><br/>
<b>average</b><br/>
<b>binding</b><br/>
<b>methods</b><br/>
<b>pcr</b><br/>
<b>range</b><br/>
<b>domains</b><br/>
<b>number</b><br/>
<b>identified</b><br/>
<b>values</b><br/>
<b>helix</b><br/>
<b>two</b><br/>
0.20<br/>
<b>fragments&#160;</b><br/>
<b>different</b><br/>
<b>cys</b><br/>
<b>principle</b><br/>
<b>two</b><br/>
<b>size</b><br/>
<b>regions</b><br/>
<b>design</b><br/>
<b>genes</b><br/>
<b>three</b><br/>
<b>structure</b><br/>
<b>access</b><br/>
0.10<br/>
<b>three</b><br/>
<b>calculated</b><br/>
<b>terminus</b><br/>
<b>processing</b><br/>
<b>cdna</b><br/>
<b>two</b><br/>
<b>terminal</b><br/>
<b>advantage</b><br/>
<b>analysis &#160;</b><br/>
<b>low</b><br/>
<b>site</b><br/>
<b>important</b><br/>
0.00<br/>
<b>Abstract with the most likely topic assignments</b><br/>
<b>Top Ten Similar Documents</b><br/>
Exhaustive Matching of the Entire Protein Sequence Database<br/>How Big Is the Universe of Exons?<br/>Counting and Discounting the Universe of Exons<br/>Detecting Subtle Sequence Signals:&#160;A&#160;Gibbs Sampling Strategy for Multiple&#160;Alignment<br/>Ancient Conserved Regions in New Gene Sequences and the Protein Databases<br/>A&#160;Method to Identify Protein Sequences that Fold into a Known&#160;Three- Dimensional Structure<br/>Testing the Exon&#160;Theory of Genes:&#160;The Evidence from Protein Structure<br/>Predicting Coiled Coils from Protein Sequences<br/>Genome Sequence of the Nematode C. elegans:&#160;A&#160;Platform for Investigating Biology<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=29></a>Why&#160;does&#160;LDA&#160;“work”?<br/>
Why&#160;does&#160;the&#160;LDA&#160;posterior&#160;put&#160;“topical”&#160;words&#160;together?<br/>
•&#160;Word&#160;probabilities&#160;are&#160;maximized&#160;by&#160;dividing&#160;the&#160;words&#160;among&#160;the<br/>
topics.&#160;(More&#160;terms&#160;means&#160;more&#160;mass&#160;to&#160;be&#160;spread&#160;around.)<br/>
•&#160;In&#160;a&#160;mixture,&#160;this&#160;is&#160;enough&#160;to&#160;find&#160;clusters&#160;of&#160;co-occurring&#160;words.<br/>
•&#160;In&#160;LDA,&#160;the&#160;Dirichlet&#160;on&#160;the&#160;topic&#160;proportions&#160;can&#160;encourage<br/>
sparsity,&#160;i.e.,&#160;a&#160;document&#160;is&#160;penalized&#160;for&#160;using&#160;many&#160;topics.<br/>
•&#160;Loosely,&#160;this&#160;can&#160;be&#160;thought&#160;of&#160;as&#160;softening&#160;the&#160;strict&#160;definition&#160;of<br/>
“co-occurrence”&#160;in&#160;a&#160;mixture&#160;model.<br/>
•&#160;This&#160;flexibility&#160;leads&#160;to&#160;sets&#160;of&#160;terms&#160;that&#160;more&#160;tightly&#160;co-occur.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=30></a><img class="yflip" src="./Blei_1-30_1.png"/><br/>
<img class="yflip" src="./Blei_1-30_2.png"/><br/>
<img class="yflip" src="./Blei_1-30_3.png"/><br/>
<img class="yflip" src="./Blei_1-30_4.png"/><br/>
<img class="yflip" src="./Blei_1-30_5.png"/><br/>
<img class="yflip" src="./Blei_1-30_6.png"/><br/>
<img class="yflip" src="./Blei_1-30_7.png"/><br/>
<img class="yflip" src="./Blei_1-30_8.png"/><br/>
<img class="yflip" src="./Blei_1-30_9.png"/><br/>
<img class="yflip" src="./Blei_1-30_10.png"/><br/>
<img class="yflip" src="./Blei_1-30_11.png"/><br/>
<img class="yflip" src="./Blei_1-30_12.png"/><br/>
<img class="yflip" src="./Blei_1-30_13.png"/><br/>
constraints&#160;of&#160;word&#160;alignment,&#160;i.e.,&#160;words&#160;“close-in-source”&#160;are&#160;usually&#160;aligned&#160;to&#160;words&#160;“close-in-<br/>
target”,&#160;under&#160;document-specific&#160;topical&#160;assignment.&#160;To&#160;incorporate&#160;such&#160;constituents,&#160;we&#160;integrate<br/>
the&#160;strengths&#160;of&#160;both&#160;HMM&#160;and&#160;BiTAM,&#160;and&#160;propose&#160;a&#160;Hidden&#160;Markov&#160;Bilingual&#160;Topic-AdMixture<br/>
model,&#160;or&#160;HM-BiTAM,&#160;for&#160;word&#160;alignment&#160;to&#160;leverage&#160;both&#160;locality&#160;constraints&#160;and&#160;topical&#160;context<br/>
underlying&#160;parallel&#160;document-pairs.<br/>In&#160;the&#160;HM-BiTAM&#160;framework,&#160;one&#160;can&#160;estimate&#160;topic-specific&#160;word-to-word&#160;translation&#160;lexicons<br/>
(lexical&#160;mappings),&#160;as&#160;well&#160;as&#160;the&#160;monolingual&#160;topic-specific&#160;word-frequencies&#160;for&#160;both&#160;languages,<br/>
based&#160;on&#160;parallel&#160;document-pairs.&#160;The&#160;resulting&#160;model&#160;offers&#160;a&#160;principled&#160;way&#160;of&#160;inferring&#160;optimal<br/>
translation&#160;from&#160;a&#160;given&#160;source&#160;language&#160;in&#160;a&#160;context-dependent&#160;fashion.&#160;We&#160;report&#160;an&#160;extensive<br/>
empirical&#160;analysis&#160;of&#160;HM-BiTAM,&#160;in&#160;comparison&#160;with&#160;related&#160;methods.&#160;We&#160;show&#160;our&#160;model’s&#160;ef-<br/>
fectiveness&#160;on&#160;the&#160;word-alignment&#160;task;&#160;we&#160;also&#160;demonstrate&#160;two&#160;application&#160;aspects&#160;which&#160;were<br/>
untouched&#160;in&#160;[10]:&#160;the&#160;utility&#160;of&#160;HM-BiTAM&#160;for&#160;bilingual&#160;topic&#160;exploration,&#160;and&#160;its&#160;application&#160;for<br/>
improving&#160;translation&#160;qualities.<br/>
2&#160;Revisit&#160;HMM&#160;for&#160;SMT<br/>An&#160;SMT&#160;system&#160;can&#160;be&#160;formulated&#160;as&#160;a&#160;noisy-channel&#160;model&#160;[2]:<br/>
e∗&#160;=&#160;arg&#160;max&#160;P&#160;(e|f)&#160;=&#160;arg&#160;max&#160;P&#160;(f|e)P&#160;(e),<br/>
(1)<br/>
e<br/>
e<br/>
where&#160;a&#160;translation&#160;corresponds&#160;to&#160;searching&#160;for&#160;the&#160;target&#160;sentence&#160;e∗&#160;which&#160;explains&#160;the&#160;source<br/>
sentence&#160;f&#160;best.&#160;The&#160;key&#160;component&#160;is&#160;P&#160;(f|e),&#160;the&#160;translation&#160;model;&#160;P&#160;(e)&#160;is&#160;monolingual&#160;language<br/>
model.&#160;In&#160;this&#160;paper,&#160;we&#160;generalize&#160;P&#160;(f|e)&#160;with&#160;topic-admixture&#160;models.<br/>An&#160;HMM&#160;implements&#160;the&#160;“proximity-bias”&#160;assumption&#160;—&#160;that&#160;words&#160;“close-in-source”&#160;are&#160;aligned<br/>
LDA&#160;istomo<br/>
words<br/>
introduce&#160;thedula<br/>
“close-in-target”,<br/>
mapping&#160;j&#160;r,<br/>
which<br/>
→&#160;aj,<br/>
general,<br/>
is&#160;effective&#160;for&#160;improving&#160;w<br/>
which&#160;assigns&#160;a&#160;French&#160;word&#160;fuseful<br/>
ord&#160;alignment&#160;accuracies,&#160;especially<br/>
for&#160;linguistically&#160;close&#160;language-pairs&#160;[8].&#160;Following&#160;[8],&#160;to&#160;model&#160;word-to-word&#160;translation,&#160;we<br/>
McCallum,&#160;Wang,&#160;&amp;&#160;Corrada-Emmanuel<br/>
j&#160;in&#160;position&#160;j&#160;to&#160;an&#160;English&#160;word<br/>
ei&#160;in&#160;position&#160;i&#160;=&#160;aj&#160;denoted&#160;as&#160;ea&#160;.&#160;Each&#160;(ordered)&#160;French&#160;word&#160;f<br/>
j<br/>
j&#160;is&#160;an&#160;observation,&#160;and&#160;it&#160;is<br/>
generated&#160;by&#160;an&#160;HMM&#160;state&#160;defined&#160;as&#160;[ea&#160;,&#160;a<br/>
j<br/>
j&#160;],&#160;where&#160;the&#160;alignment&#160;indicator&#160;aj&#160;for&#160;position&#160;j&#160;is<br/>
considered&#160;to&#160;have&#160;a&#160;dependency&#160;on&#160;the&#160;previous&#160;alignment&#160;aj−1.&#160;Thus&#160;a&#160;first-order&#160;HMM&#160;for&#160;an<br/>
alignment&#160;between&#160;e&#160;≡&#160;e1:I&#160;and&#160;f&#160;≡&#160;f1:J&#160;is&#160;defined&#160;as:<br/>
<b>Latent Dirichlet&#160;Allocation</b><br/>
<b>Author&#160;Model</b><br/>
<b>Author-Topic Model</b><br/>
<b>Author-Recipient-Topic Model</b><br/>
!&#160;J<br/>
&#34;<br/>
(LDA)<br/>
(Multi-label Mixture Model)<br/>
(AT)<br/>
(ART)<br/>
<b>Dynamic&#160;Topic&#160;Models</b><br/>
p(f1:J&#160;|e1:I)&#160;=<br/>
p(fj|ea&#160;)p(aj|aj−1),<br/>
(2)<br/>
[Blei, Ng, Jordan, 2003]<br/>
[McCallum 1999]<br/>
[Rosen-Zvi, Griffiths, Steyvers, Smyth 2004]<br/>
[This paper]<br/>
j<br/>
a1:&#160;j=1<br/>
ways,&#160;and&#160;quantitative&#160;results&#160;that&#160;demonstrate&#160;greater<br/>
J<br/>
pre-<br/>
α<br/>
α<br/>
α<br/>
!<br/>
<b>a</b><br/>
<b>a</b><br/>
a<br/>
<b>r</b><br/>
d<br/>
dictivedaccuracy&#160;when&#160;compared&#160;withd&#160;staticd&#160;topic&#160;models.<br/>
topic&#160;zi&#160;and&#160;the&#160;author&#160;xi&#160;responsible&#160;for&#160;this&#160;word&#160;are<br/>
where&#160;p(aj|aj−1)&#160;is&#160;the&#160;state&#160;transition&#160;probability;&#160;J&#160;and&#160;I&#160;are&#160;sentence&#160;lengths&#160;of&#160;the&#160;French&#160;and<br/>
α<br/>
θ<br/>
assigned&#160;based&#160;on&#160;the&#160;posterior&#160;probability&#160;conditioned&#160;on<br/>
English&#160;sentences,&#160;respectively.&#160;The&#160;transition&#160;model&#160;enforces&#160;the&#160;proximity-bias.&#160;An&#160;additional<br/>
&#34;<br/>
z<br/>
<b>2.&#160;Dynamic</b><br/>
pseudo&#160;x<br/>
<b>Topic&#160;Models</b><br/>
θ<br/>
θ<br/>
θ<br/>
word&#160;”NULL”&#160;is&#160;used&#160;at&#160;the&#160;xbeginning&#160;of&#160;English&#160;sentences&#160;for&#160;HMM&#160;to&#160;start&#160;with.&#160;The<br/>
<i>C</i><br/>
all&#160;other&#160;variables:&#160;P&#160;(zi,&#160;xi|ωi,&#160;z−i,&#160;x−i,&#160;w−i,&#160;ad).&#160;zi&#160;and<br/>
(a)<br/>
!<br/>
(a)<br/>
(b)<br/>
(b)<br/>
&#34;<br/>
xi&#160;denote&#160;the&#160;topic&#160;and&#160;author&#160;assigned&#160;to&#160;ωi,&#160;while&#160;z<br/>
&#34;<br/>
1<br/>
'<br/>
HMM&#160;implemented&#160;in&#160;GIZA++&#160;[5]&#160;is&#160;used&#160;as&#160;our&#160;baseline,&#160;which&#160;includes&#160;refinements&#160;2<br/>
such&#160;as<br/>
#<br/>
−i<br/>
While&#160;traditional&#160;time&#160;series&#160;modeling&#160;has&#160;focused&#160;on&#160;con-<br/>
#<br/>
0.2<br/>
z<br/>
z<br/>
z<br/>
and&#160;x−i&#160;are&#160;all&#160;other&#160;assignments&#160;of&#160;topic&#160;and&#160;author&#160;ex-<br/>
!<br/>
&#34;<br/>
tinuous<br/>
special&#160;data,&#160;topic<br/>
treatment!ofmodels<br/>
a&#160;&#34;&#160;are<br/>
jump&#160;to&#160;designed<br/>
a<br/>
for<br/>
NULL&#160;w&#160;cate<br/>
ord.&#160;gorical<br/>
A&#160;graphical&#160;model&#160;representation&#160;for&#160;such&#160;an&#160;HMM<br/>
z<br/>
z<br/>
z<br/>
γ<br/>
ψ<br/>
cluding&#160;current&#160;instance.&#160;w<br/>
A<br/>
is&#160;data.&#160;Our&#160;approach<br/>
illustrated&#160;in<br/>
is&#160;to<br/>
Figure&#160;use<br/>
A,A<br/>
1&#160;state<br/>
(a).<br/>
space&#160;models&#160;on&#160;the&#160;nat-<br/>
−i&#160;represents&#160;other&#160;observed<br/>
0.5<br/>
0.4<br/>
0.1<br/>
w<br/>
w<br/>
w<br/>
network&#160;used&#160;&#160;for&#160;images&#160;words&#160;in&#160;the&#160;document&#160;set&#160;and&#160;a<br/>
ural&#160;parameter&#160;space&#160;of&#160;the&#160;underlying&#160;topic&#160;multinomials,<br/>
$<br/>
network<br/>
%image&#160;(&#160;kernel<br/>
<i>T</i><br/>
α<br/>
d&#160;is&#160;the&#160;observed&#160;author<br/>
<i>z</i>1<br/>
<i>z</i>2<br/>
<i>z</i>3<br/>
<i>z</i><br/>
$<br/>
&amp;<br/>
di<br/>
4<br/>
neural<br/>
images<br/>
support<br/>
set&#160;for&#160;this&#160;document.<br/>
$<br/>
#<br/>
w<br/>
$<br/>
#<br/>
$<br/>
#<br/>
w<br/>
as&#160;well<br/>
w&#160;as&#160;on&#160;the&#160;natural<br/>
$<br/>
#&#160;parameters&#160;for<br/>
w&#160;the&#160;logistic&#160;nor-<br/>
N<br/>
0.8<br/>
N<br/>
N<br/>
image&#160;obtained&#160;with&#160;kernel<br/>
A&#160;βk<br/>
A<br/>
A<br/>
0.7<br/>
T<br/>
A<br/>
T<br/>
T<br/>
networks<br/>
object<br/>
vector<br/>
A&#160;key&#160;issue&#160;in&#160;using&#160;Gibbs&#160;sampling&#160;for&#160;distribution<br/>
Nd<br/>
Nd<br/>
mal&#160;distrib<br/>
Nd&#160;utions&#160;used&#160;for&#160;modeling&#160;the&#160;document-specific<br/>
Nd<br/>
&#34;<br/>
K<br/>
output<br/>
objects<br/>
svm<br/>
β<br/>
φ<br/>
ω<br/>
output&#160;described&#160;with<br/>
appro<br/>
objects&#160;ximation&#160;is&#160;the&#160;evaluation&#160;of&#160;conditional&#160;posterior<br/>
topic&#160;proportions.<br/>
<i>z</i><br/>
...<br/>
&#34;<br/>
...<br/>
...<br/>
<i>x</i><br/>
0<br/>
<i>z</i><br/>
N<br/>
D<br/>
D<br/>
D<br/>
D<br/>
β<br/>
β<br/>
β<br/>
d<br/>
used<br/>
probability.&#160;In&#160;Author-Topic&#160;model,&#160;given&#160;T&#160;topics&#160;and&#160;V<br/>
I<br/>
<i>w</i><br/>
m,n<br/>
1<br/>
<i>w</i>2<br/>
<i>w</i>3<br/>
<i>w</i><br/>
in<br/>
K<br/>
<i>U</i><br/>
<i>D</i>neural&#160;network&#160;trained&#160;with&#160;svm&#160;images<br/>
First,&#160;we&#160;revie<br/>
Im,n<br/>
e&#160;w&#160;the&#160;underlying&#160;statistical&#160;assumptions&#160;of<br/>
4<br/>
m,i<br/>
em,i&#160;with<br/>
trained<br/>
words,&#160;P&#160;(zi,&#160;xi|ωi,&#160;z−i,&#160;x−i,&#160;w−i,&#160;ad)&#160;is&#160;estimated&#160;by:<br/>
a&#160;static&#160;topic&#160;model,&#160;such&#160;as&#160;latent&#160;Dirichlet<br/>
B&#160;=&#160;p(f&#160;|e)&#160;allocation<br/>
obtained<br/>
Figure<br/>
!<br/>
1.&#160;Graphical<br/>
<i>w</i><br/>
representation<br/>
for<br/>
of&#160;a&#160;dynamic&#160;topic<br/>
Bk&#160;model&#160;(for<br/>
Figure&#160;1:&#160;Three&#160;related&#160;models,&#160;and&#160;the&#160;ART&#160;model.&#160;In&#160;all&#160;models,&#160;each&#160;observed&#160;word,<br/>
K<br/>
α<br/>
θm<br/>
zm,n<br/>
on<br/>
!<br/>
<i>w</i><br/>
(LDA)&#160;(Blei&#160;et&#160;al.,&#160;2003).&#160;Let&#160;β<br/>
0.9<br/>
Figure&#160;5:&#160;Mode<br/>
described&#160;ling&#160;community&#160;with&#160;topics<br/>
1:K&#160;be&#160;K&#160;topics,&#160;each&#160;of<br/>
three&#160;time&#160;slices).&#160;Each<br/>
<i>N</i><br/>
topic’s&#160;natural&#160;parameters&#160;βt,k&#160;evolve<br/>
fm,1<br/>
fm,2<br/>
f<br/>
f<br/>
<i>T</i><br/>
<i>d</i><br/>
<i>N</i>...<br/>
which&#160;is&#160;a&#160;distribution&#160;ov<br/>
m,&#160;er<br/>
3<br/>
a&#160;fixedJ<br/>
fm,1<br/>
fm,2<br/>
f<br/>
f<br/>
m,v<br/>
n&#160;ocab<br/>
<i>s</i><br/>
m,3<br/>
J<br/>
1<br/>
ulary.<i>s</i>2In&#160;a&#160;static<br/>
...<br/>
<i>s</i>3<br/>
over<br/>
<i>s</i>4time,&#160;together&#160;with&#160;the<br/>
w,&#160;is&#160;generated&#160;from&#160;a&#160;multinomial&#160;word&#160;distribution,&#160;φ<br/>
<i>D</i><br/>
mean&#160;parameters<br/>
m,n<br/>
α<br/>
P&#160;(z<br/>
<i>T</i><br/>
<i>d</i><br/>
i&#160;=&#160;j,&#160;xi&#160;=&#160;k<br/>
<i>D</i><br/>
|ωi&#160;=&#160;m,&#160;z<br/>
t&#160;of&#160;the&#160;logistic<br/>
−i,&#160;x−i,&#160;w−i,&#160;ad)&#160;∝<br/>
(4)<br/>
z&#160;,&#160;specific&#160;to&#160;a&#160;particular<br/>
topic&#160;model,&#160;each&#160;document&#160;is&#160;assumed&#160;drawn&#160;from&#160;the<br/>
normal&#160;distribution&#160;for&#160;the&#160;topic&#160;proportions.<br/>
topic/author,&#160;z,&#160;however&#160;topics&#160;are&#160;selected&#160;differently&#160;in&#160;each&#160;of&#160;the&#160;models.<br/>
sider&#160;the&#160;conditional&#160;probability&#160;P&#160;(c,&#160;u,&#160;z<br/>
P&#160;(ωi&#160;=&#160;m|xi&#160;=&#160;k)P&#160;(xi&#160;=&#160;k|zi&#160;=&#160;j)&#160;∝<br/>
(5)<br/>
following&#160;generati<br/>
am,1<br/>
a&#160;v<br/>
m,&#160;e<br/>
2<br/>
process:<br/>
|ω),&#160;a&#160;word&#160;ω&#160;as-<br/>
am,3<br/>
aJ<br/>
am,1<br/>
am,2<br/>
a<br/>
a<br/>
m,n<br/>
m,3<br/>
Jm,n<br/>
Nm<br/>
Figure&#160;1:&#160;Graph<br/>
Figure&#160;ical<br/>
1:&#160;models<br/>
The&#160;for&#160;(a)&#160;the&#160;standa<br/>
composite&#160;rd&#160;LDA&#160;to<br/>
Nm&#160;pic<br/>
model.&#160;so<br/>
m&#160;ci<br/>
od<br/>
(a)&#160;aetles(letfht)ree<br/>
an&#160;v<br/>
d&#160;a<br/>
(&#160;ri<br/>
b&#160;a<br/>
)<br/>
Graphical&#160;bl<br/>
th&#160;es<br/>
e&#160;:<br/>
pr&#160;co<br/>
opmm<br/>
ose<br/>
model.udnsitpye,c<br/>
(b)&#160;u<br/>
ia&#160;s<br/>
l&#160;er&#160;and<br/>
Gene&#160;topic.&#160;O<br/>
rating&#160;ur<br/>
In&#160;LDA,&#160;the&#160;topic&#160;is&#160;sampled&#160;from&#160;a&#160;per-document&#160;topic&#160;distribution,<br/>
phrases.<br/>
CW&#160;T<br/>
θ,&#160;which<br/>
mj<br/>
+&#160;β<br/>
CAT<br/>
kj<br/>
+&#160;α<br/>
M<br/>
words&#160;topic&#160;model&#160;with&#160;a&#160;background&#160;distribution&#160;(SWB<br/>
M<br/>
)&#160;(&#160;in<br/>
r&#160;t<br/>
ig&#160;erp<br/>
ht).&#160;retation&#160;of&#160;the&#160;semantic&#160;meaning&#160;of&#160;P&#160;(c,&#160;u,&#160;z|ω)&#160;is<br/>
(6)<br/>
in&#160;turn&#160;is&#160;sampled&#160;from&#160;a&#160;Dirichlet&#160;over<br/>
1.&#160;Choose<br/>
topics.&#160;In&#160;topic<br/>
the&#160;proportions<br/>
Author&#160;θ&#160;from<br/>
Mo&#160;a<br/>
del,&#160;distrib<br/>
the&#160;ution<br/>
re&#160;is&#160;over<br/>
tion&#160;(Aitchison,&#160;1982)&#160;to&#160;time-series&#160;simplex&#160;data&#160;(West<br/>
Σm!&#160;CWT&#160;+&#160;V&#160;β&#160;Σj!&#160;CAT<br/>
the&#160;probability&#160;that&#160;word&#160;ω&#160;is&#160;generated&#160;by&#160;user&#160;u&#160;under<br/>
m!j<br/>
kj!&#160;+&#160;T&#160;α<br/>
the&#160;(K&#160;−&#160;1)-simplex,&#160;such&#160;as&#160;a&#160;Dirichlet.<br/>
and&#160;Harrison,&#160;1997).<br/>
one&#160;topic&#160;associated&#160;with&#160;each&#160;author&#160;(or&#160;category),&#160;and<br/>
Ti,i!<br/>
authors&#160;are<br/>
φ(z)sam<br/>
,&#160;pled<br/>
each&#160;class&#160;c&#160;!=&#160;1&#160;isTi,i!&#160;associated&#160;with&#160;a&#160;distribution&#160;over&#160;words&#160;φ(c),&#160;each&#160;document<br/>
topic&#160;z,&#160;in&#160;community&#160;c.<br/>
where&#160;m&#34;&#160;&#34;=&#160;m&#160;and&#160;j&#34;&#160;&#34;=&#160;j,&#160;α&#160;and&#160;β&#160;are&#160;prior&#160;parameters<br/>
2.&#160;For&#160;each&#160;word:<br/>
In&#160;LDA,&#160;the&#160;document-specific&#160;topic&#160;proportions&#160;θ&#160;are<br/>
uniformly.&#160;In&#160;the&#160;Author-Topic&#160;model,&#160;the&#160;topic<br/>
(a)&#160;is&#160;sam<br/>
HMM&#160;pled<br/>
for&#160;W&#160;from<br/>
ord<br/>
a&#160;p<br/>
Alignmenter-author<br/>
(b)&#160;HM-BiTAM<br/>
Unfortunately,&#160;this&#160;conditional&#160;probability&#160;cannot&#160;be&#160;com-<br/>
are&#160;generated&#160;by&#160;drawing&#160;a&#160;topic&#160;t&#160;from&#160;the&#160;document-topic&#160;distribution&#160;p(z<br/>
for&#160;word&#160;and&#160;topic&#160;Dirichlets,&#160;CW&#160;T<br/>
d&#160;has&#160;a&#160;distribution&#160;over&#160;topics&#160;θ(d),&#160;and<br/>
|θd)&#160;and&#160;then&#160;drawing<br/>
mj<br/>
represents&#160;the&#160;number<br/>
transitions&#160;between&#160;classes&#160;c<br/>
(a)&#160;Choose&#160;a&#160;topic&#160;assignment&#160;Z&#160;∼&#160;Mult(θ).<br/>
drawn&#160;from&#160;a&#160;Dirichlet&#160;distribution.&#160;In&#160;the&#160;dynamic&#160;topic<br/>
puted&#160;directly.&#160;To&#160;get&#160;P&#160;(c,&#160;u,&#160;z<br/>
i<br/>
multinomial&#160;distribution,<br/>
−1&#160;and&#160;ci&#160;follow&#160;a<br/>
Figure&#160;1:&#160;The&#160;graphical&#160;model<br/>
a&#160;wo<br/>
representations&#160;rd<br/>
of&#160;w<br/>
(a)&#160;from&#160;th<br/>
HMM,&#160;e<br/>
andtop<br/>
(b)ic-word<br/>
HM-BiT&#160;distr<br/>
AM,&#160;ibu<br/>
for&#160;tion&#160;p(<br/>
parallel&#160;w<br/>
|ω)&#160;,we&#160;have:<br/>
of&#160;times&#160;that&#160;word&#160;ωi&#160;=&#160;m&#160;is&#160;assigned&#160;to&#160;topic&#160;zi&#160;=&#160;j,<br/>
θ,&#160;and&#160;authors&#160;are&#160;sampled&#160;uniformly&#160;from&#160;the&#160;observed<br/>
|z&#160;=<br/>
corpora.&#160;t,&#160;φt).<br/>
Circles&#160;As&#160;shown&#160;in&#160;Griffiths&#160;and&#160;Steyvers<br/>
(b)&#160;Choose&#160;a&#160;word&#160;W&#160;∼&#160;Mult(β<br/>
model,&#160;we&#160;use&#160;a&#160;logistic&#160;normal&#160;with&#160;mean&#160;α&#160;to&#160;express<br/>
z&#160;).<br/>
represent&#160;random&#160;variables,&#160;hexagons<br/>
(20<br/>
denote&#160;04<br/>
distrib&#160;)&#160;the&#160;top<br/>
ution<br/>
parameters,&#160;ic<br/>
π(si−1)<br/>
and&#160;uncertainty<br/>
assignm<br/>
observ&#160;e<br/>
ed&#160;n<br/>
.vov<br/>
ts&#160;erz<br/>
A&#160;proportions.<br/>
fo<br/>
ariablesr&#160;ea<br/>
are&#160;ch&#160;The<br/>
wor<br/>
shaded.&#160;d&#160;sequential<br/>
to<br/>
document&#160;ke<br/>
is&#160;n&#160;in&#160;structure<br/>
the&#160;cor&#160;be<br/>
pu-<br/>
CAT<br/>
s<br/>
generated&#160;can&#160;b<br/>
viae&#160;effic<br/>
the&#160;iently&#160;sa<br/>
follo&#160;mpled<br/>
wingvia<br/>
procedure:<br/>
kj<br/>
represents&#160;the&#160;number&#160;of&#160;times&#160;that&#160;author&#160;xi&#160;=&#160;k&#160;is<br/>
list&#160;of&#160;the&#160;document’s&#160;authors.&#160;In&#160;the&#160;Author-Recipient-Topic&#160;model,&#160;there&#160;is<br/>
Gibbs&#160;sampling&#160;(tween<br/>
after&#160;models<br/>
margin&#160;is<br/>
a&#160;ag<br/>
liz&#160;ain<br/>
ing&#160;captured<br/>
over&#160;θ&#160;a&#160;with<br/>
nd&#160;φ&#160;a<br/>
).&#160;simple<br/>
Point&#160;dynamic<br/>
estimates&#160;for&#160;the&#160;θ&#160;and&#160;φ&#160;dis&#160;P<br/>
tr&#160;(c,<br/>
ibu&#160;u,<br/>
tio&#160;z<br/>
n&#160;,s&#160;ω)<br/>
assigned&#160;to&#160;topic&#160;j.<br/>
a&#160;separate&#160;topic-distribution&#160;for&#160;each<br/>
This&#160;process<br/>
author-rec<br/>
implicitly<br/>
ipient&#160;pair,&#160;assumes<br/>
and<br/>
that<br/>
the&#160;the<br/>
sele&#160;documents<br/>
ction&#160;of&#160;are<br/>
P&#160;(c,&#160;u,&#160;z|ω)&#160;=<br/>
(3)<br/>
can&#160;be&#160;comp<br/>
2uted&#160;model<br/>
conditioned&#160;on&#160;a&#160;particular&#160;sample,&#160;and&#160;predictive&#160;distributions&#160;can&#160;be&#160;Σ<br/>
The&#160;transformation&#160;from&#160;Eq.&#160;4&#160;to&#160;Eq.&#160;5&#160;drops&#160;the&#160;vari-<br/>
obtained&#160;by<br/>
drawn&#160;<i>exchangeably&#160;</i>from&#160;the&#160;same&#160;set&#160;of&#160;topics.&#160;For&#160;many<br/>
c,u,z&#160;P&#160;(c,&#160;u,&#160;z,&#160;ω)<br/>
ables,&#160;z<br/>
topic-distribution&#160;is&#160;determined&#160;from&#160;the&#160;observed&#160;author,&#160;and&#160;by&#160;uniformly&#160;sam<br/>
1.&#160;-Sample&#160;θ(d)&#160;from&#160;a&#160;Dirichlet(α)&#160;prior<br/>
−i,&#160;x−i,&#160;w−i,&#160;ad,&#160;because&#160;each&#160;instance&#160;of&#160;ωi&#160;is<br/>
averaging&#160;over&#160;multiple&#160;samples.<br/>
collections,&#160;however,&#160;the&#160;order&#160;of&#160;the&#160;documents&#160;reflects<br/>
αt&#160;|&#160;αt<br/>
•&#160;LDA&#160;can&#160;be&#160;embedded&#160;in&#160;more&#160;complicated&#160;models,&#160;embodying<br/>
−1&#160;∼&#160;N&#160;(αt−1&#160;,&#160;δ2&#160;I&#160;)&#160;.<br/>
(2)<br/>
Consider&#160;the&#160;denominator&#160;in&#160;Eq.&#160;3,&#160;summing&#160;over&#160;all&#160;c,<br/>
assumed&#160;independent&#160;of&#160;the&#160;other&#160;words&#160;in&#160;a&#160;message.<br/>
pling&#160;a&#160;recipient&#160;from&#160;the&#160;set&#160;of&#160;recipients&#160;an&#160;e<br/>
for&#160;volving<br/>
the&#160;set<br/>
doc&#160;of&#160;topics.<br/>
ument.&#160;In&#160;a&#160;dynamic&#160;topic&#160;model,&#160;we<br/>
We&#160;will<br/>
2.&#160;refe<br/>
F&#160;r&#160;to&#160;F<br/>
or&#160;th&#160;or<br/>
e&#160;simplicity<br/>
pr<br/>
eachopo<br/>
w&#160;sed,&#160;we<br/>
m<br/>
ord&#160;o&#160;do<br/>
d<br/>
w&#160;elnot<br/>
as&#160;model<br/>
the&#160;s&#160;the<br/>
pec&#160;dynamics<br/>
ial&#160;word&#160;of<br/>
s&#160;topic<br/>
u&#160;a<br/>
topic&#160;cor<br/>
nd<br/>
mo-z&#160;makes&#160;the&#160;computation&#160;impractical&#160;in&#160;terms&#160;of&#160;ef-<br/>
del&#160;with&#160;background&#160;distribution<br/>
i&#160;in&#160;document&#160;d<br/>
suppose&#160;that&#160;the&#160;data&#160;is&#160;divided&#160;by&#160;time&#160;slice,&#160;for&#160;example<br/>
(SWB)&#160;(Figure&#160;1(relation,<br/>
b)).<br/>
as<br/>
SWBwas<br/>
ha&#160;done<br/>
s&#160;a&#160;s&#160;for<br/>
im&#160;static<br/>
ilar&#160;gemodels<br/>
neral&#160;by<br/>
str&#160;Blei<br/>
uctu&#160;and<br/>
re&#160;Laf<br/>
fici<br/>
to&#160;thferty<br/>
ency.&#160;In&#160;addition,&#160;as&#160;shown&#160;in&#160;[7],&#160;the&#160;summing&#160;doesn’t<br/>
e&#160;LDA&#160;model&#160;(Figure&#160;1(a))&#160;but&#160;with<br/>
<b>4.2&#160;Semantic&#160;community&#160;discovery</b><br/>
by&#160;year.&#160;We&#160;model&#160;the&#160;documents&#160;of&#160;each&#160;slice&#160;with&#160;a&#160;K-<br/>
further&#160;intuitions&#160;about&#160;the&#160;structure&#160;of&#160;the&#160;texts.<br/>
(2006).<br/>
factorize,&#160;which&#160;makes&#160;the&#160;manipulation&#160;of&#160;denominator<br/>
additional&#160;mach<br/>
(a)&#160;inery&#160;to<br/>
Dra&#160;h<br/>
wanzdile&#160;specia<br/>
from&#160;l&#160;w<br/>
θ(d)<br/>
ords&#160;and&#160;background&#160;words.&#160;In&#160;particular,&#160;associated&#160;with<br/>
By&#160;applying&#160;the&#160;Gibbs&#160;sampling,&#160;we&#160;can&#160;discover&#160;the&#160;se-<br/>
component&#160;topic&#160;model,&#160;where&#160;the&#160;topics&#160;associated&#160;with<br/>
difficult.&#160;In&#160;the&#160;following&#160;section,&#160;we&#160;will&#160;show&#160;how&#160;an<br/>
each&#160;word&#160;token&#160;is&#160;a&#160;latent&#160;random&#160;variable&#160;x,&#160;taking&#160;value&#160;x&#160;=&#160;0&#160;if&#160;the&#160;word&#160;w&#160;is&#160;generated&#160;via<br/>
mantic&#160;communities&#160;by&#160;using&#160;the&#160;CUT&#160;models.&#160;Consider<br/>
slice&#160;t&#160;evolve&#160;from&#160;the&#160;topics&#160;associated&#160;with&#160;slice&#160;t&#160;−&#160;1.<br/>
By&#160;chaining&#160;together&#160;topics&#160;and&#160;topic&#160;proportion&#160;distribu-<br/>
(b)&#160;Draw&#160;ci&#160;from&#160;π(ci−1)<br/>
approximate&#160;approach&#160;of&#160;Gibbs&#160;sampling&#160;will&#160;provide&#160;so-<br/>
its&#160;generative&#160;process&#160;for&#160;each&#160;document<br/>
the&#160;topic&#160;route,&#160;v<br/>
d,&#160;a&#160;set&#160;of&#160;authors,&#160;a<br/>
tions,<br/>
alue&#160;we<br/>
x&#160;ha<br/>
=&#160;ve<br/>
1&#160;sequentially<br/>
if&#160;the&#160;wor&#160;tied<br/>
d&#160;is&#160;agcollection<br/>
enerated&#160;of<br/>
a&#160;topic<br/>
s&#160;a&#160;s&#160;mod-<br/>
pecial&#160;word&#160;(for&#160;that&#160;document)&#160;and<br/>
the&#160;conditional&#160;probability&#160;P&#160;(c,&#160;u,&#160;z|ω),&#160;where&#160;three&#160;vari-<br/>
d,&#160;is&#160;observed.&#160;To&#160;generate<br/>
For&#160;a&#160;K-component&#160;model&#160;with&#160;V&#160;terms,&#160;let&#160;β<br/>
lutions&#160;to&#160;such&#160;problems.&#160;A&#160;faster&#160;algorithm&#160;EnF-Gibbs<br/>
valuet,k&#160;denote<br/>
x&#160;=&#160;2&#160;if&#160;thels.<br/>
e&#160;The<br/>
word&#160;generati<br/>
is&#160;genveer&#160;process<br/>
ated&#160;fr&#160;for<br/>
om&#160;slice<br/>
a&#160;b&#160;t<br/>
a&#160;of<br/>
ck&#160;a<br/>
g&#160;sequential<br/>
round&#160;discorpus<br/>
tribution&#160;specific&#160;for&#160;the&#160;corpus.&#160;The<br/>
ables&#160;in&#160;the&#160;model,&#160;community,&#160;user4&#160;and&#160;topic,&#160;are&#160;asso-<br/>
each&#160;word,&#160;an&#160;author&#160;x&#160;is&#160;chosen&#160;uniformly&#160;from&#160;this&#160;set,&#160;then&#160;a&#160;topic<br/>
(c)&#160;If&#160;c<br/>
φ(zi),&#160;else&#160;draw&#160;w&#160;from&#160;φ(ci)<br/>
the&#160;V&#160;-vector&#160;of&#160;natural&#160;parameters<br/>
z&#160;is&#160;selected&#160;from&#160;a<br/>
for&#160;topic&#160;k&#160;in&#160;slice&#160;t.<br/>
i&#160;=&#160;1,&#160;then&#160;draw&#160;wi&#160;from&#160;sampling&#160;will&#160;also&#160;be&#160;introd<br/>
i&#160;uced.<br/>
variable&#160;x&#160;acts&#160;asisathus<br/>
sw&#160;as<br/>
itc&#160;follo<br/>
h:&#160;ws:<br/>
ciated&#160;by&#160;a&#160;word&#160;ω.&#160;The&#160;semantic&#160;meaning&#160;of&#160;P&#160;(c,&#160;u,&#160;z<br/>
if&#160;x&#160;=&#160;0,&#160;the&#160;previously&#160;described&#160;standard&#160;topic&#160;mechanism&#160;is&#160;used<br/>
|ω)<br/>
topic&#160;distribution&#160;θ<br/>
•&#160;E.g.,&#160;syntax;&#160;authorship;&#160;word&#160;sense;&#160;dynamics;&#160;correlation;<br/>
x&#160;that&#160;is&#160;specific&#160;to&#160;the&#160;author,<br/>
The<br/>
and&#160;usual&#160;representation<br/>
then&#160;a&#160;word&#160;wof&#160;a<br/>
is&#160;multinomial&#160;distrib<br/>
generated<br/>
ution<br/>
from&#160;a&#160;is&#160;by<br/>
is&#160;the&#160;probability&#160;that&#160;ω&#160;belongs&#160;to&#160;user&#160;u&#160;under&#160;topic&#160;z,<br/>
to&#160;generate&#160;the&#160;word,&#160;whereas&#160;if&#160;x&#160;=&#160;1&#160;or&#160;x&#160;=&#160;2,&#160;words&#160;are&#160;sampled&#160;from&#160;a&#160;document-specific<br/>
its&#160;mean&#160;parameterization.&#160;If&#160;we&#160;denote&#160;the&#160;mean&#160;param-<br/>
topic-specific&#160;multinomial&#160;distribution&#160;φ<br/>
of&#160;the<br/>
Figure&#160;se<br/>
<b>4.&#160;SEMANTIC&#160;COMMUNITY&#160;DISCOVERY:</b><br/>
z&#160;.&#160;However,&#160;as&#160;described&#160;previously,&#160;none&#160;multinomial&#160;Ψ<br/>
1(b)&#160;or&#160;a1.c<br/>
pro&#160;oDra<br/>
rp&#160;w<br/>
us&#160;topics<br/>
sp<br/>
vides&#160;ec&#160;β<br/>
in&#160;community&#160;c.&#160;By&#160;estimation&#160;of&#160;P&#160;(c,&#160;u,&#160;z|ω),&#160;we&#160;can&#160;la-<br/>
ific<br/>
an&#160;multinom<br/>
intuiti&#160;ia<br/>
v&#160;le&#160;Ω&#160;(with&#160;symmetric&#160;Diric<br/>
representation&#160;hlet<br/>
of&#160;prio<br/>
hors&#160;p<br/>
w&#160;arame<br/>
phr&#160;trized<br/>
asesbyare&#160;generated&#160;by&#160;the&#160;com-<br/>
eter&#160;of&#160;a&#160;V&#160;-dimensional&#160;multinomial&#160;by&#160;π,&#160;the&#160;ith&#160;com-<br/>
t&#160;|&#160;βt−1&#160;∼&#160;N&#160;(βt−1,&#160;σ2I&#160;).<br/>
models&#160;is&#160;suitable&#160;for&#160;modeling&#160;message&#160;data.<br/>
β1&#160;and&#160;β2)&#160;respectively.&#160;x&#160;is&#160;sampled&#160;from&#160;a&#160;document-specific<b>TH</b><br/>
mu&#160;<b>E&#160;ALG</b><br/>
ltinomial&#160;<b>O</b><br/>
λ,<b>RI</b><br/>
w&#160;<b>T</b><br/>
h&#160;<b>H</b><br/>
ich&#160;<b>MS</b><br/>
bel&#160;a&#160;community&#160;with&#160;semantic&#160;tags&#160;(topics)&#160;in&#160;addition&#160;to<br/>
in&#160;turn&#160;has<br/>
ponent&#160;of&#160;the&#160;<i>natural&#160;parameter&#160;</i>is&#160;given&#160;by&#160;the&#160;mapping<br/>
2.&#160;Draw&#160;αt&#160;|&#160;αt<br/>
hierarchies;&#160;nonparametric&#160;Bayes<br/>
−1&#160;∼&#160;N&#160;(αt−1&#160;,&#160;δ2&#160;I&#160;).<br/>
posite&#160;model.&#160;The&#160;figure&#160;shows&#160;a&#160;three&#160;class&#160;HMM.&#160;Two&#160;classes&#160;are&#160;simple<br/>
the&#160;affiliated&#160;us<br/>
multinomial&#160;ers.&#160;The&#160;problem&#160;of&#160;semantic&#160;community<br/>
β<br/>
a&#160;symmetric&#160;Diric&#160;3.<br/>
hle&#160;F<br/>
t&#160;or<br/>
pr&#160;each<br/>
ior,&#160;document:<br/>
γ.&#160;One&#160;could&#160;also&#160;use&#160;a&#160;hierarc&#160;In<br/>
hic&#160;t<br/>
a&#160;h<br/>
l&#160;is<br/>
Basect<br/>
yes&#160;io<br/>
ia&#160;n<br/>
n&#160;,a&#160;w<br/>
p&#160;e<br/>
pr&#160;fi<br/>
o&#160;rs<br/>
ac&#160;th&#160;in<br/>
to&#160;tro<br/>
in&#160;d<br/>
tr&#160;u<br/>
o&#160;ce<br/>
du&#160;t<br/>
c&#160;h<br/>
e&#160;e&#160;Gibbs&#160;sampling<br/>
i&#160;=&#160;log(πi/πV&#160;).&#160;In&#160;typical&#160;language&#160;modeling&#160;applica-<br/>
An&#160;email&#160;message&#160;has&#160;one&#160;sender&#160;and&#160;in&#160;general&#160;more&#160;than&#160;one&#160;recipients.&#160;We&#160;could<br/>
discovery&#160;is&#160;thus&#160;reduced&#160;to&#160;the&#160;estimation&#160;of&#160;P&#160;(c,&#160;u,&#160;z|ω).<br/>
tions,&#160;Dirichlet&#160;distributions&#160;are&#160;used&#160;to&#160;model<br/>
ano&#160;uncertain<br/>
ther&#160;leve<br/>
distrib<br/>
ty<br/>
l&#160;of&#160;uncer<br/>
utions&#160;ov&#160;(a)<br/>
tain<br/>
er&#160;Dra<br/>
ty<br/>
w&#160;w<br/>
ab&#160;ηo&#160;∼<br/>
ut<br/>
ords.Nth(eαDirichlet&#160;priors&#160;(e.g&#160;a.,lgsoeri<br/>
e&#160;th<br/>
B&#160;m.<br/>
lei,&#160;T<br/>
Nh<br/>
gen<br/>
,&#160;a&#160;w<br/>
n&#160;e<br/>
d&#160;a<br/>
J&#160;d<br/>
o&#160;d<br/>
r&#160;res<br/>
dan&#160;s<br/>
,&#160;t<br/>
2h<br/>
0&#160;e0&#160;p<br/>
3&#160;ro<br/>
)&#160;blem<br/>
—we&#160;of&#160;semantic&#160;com-<br/>
The&#160;third&#160;is&#160;a&#160;topic&#160;model,&#160;containing&#160;three&#160;topics.&#160;Transitions<br/>
t,&#160;a2I&#160;)<br/>
treat&#160;both&#160;the&#160;sender&#160;and&#160;the&#160;recipients&#160;as&#160;“authors”&#160;of&#160;the&#160;message,&#160;and&#160;then&#160;employ&#160;the<br/>
about&#160;the&#160;distributions&#160;over&#160;words.&#160;However<br/>
h&#160;,<br/>
a&#160;the<br/>
ve&#160;Dirichlet<br/>
not&#160;investigated&#160;this&#160;option,&#160;primarily&#160;for&#160;computatio&#160;m<br/>
n&#160;u<br/>
al&#160;nrit<br/>
e&#160;y<br/>
as&#160;d<br/>
o&#160;i<br/>
nsco<br/>
s.&#160;v<br/>
I&#160;ery<br/>
n&#160;allby<br/>
oua<br/>
r&#160;da<br/>
e&#160;p<br/>
x&#160;t<br/>
p&#160;i<br/>
en<br/>
r&#160;g<br/>
imG<br/>
e&#160;i<br/>
nbb<br/>
ts,&#160;s&#160;s<br/>
w&#160;a<br/>
e&#160;mpling&#160;framework<br/>
(b)&#160;For&#160;each&#160;word:<br/>
AT&#160;model,&#160;but&#160;this&#160;does&#160;not&#160;distinguish&#160;the&#160;author<br/>
between&#160;classes&#160;are&#160;shown&#160;with&#160;arrows,&#160;annotated&#160;with&#160;transition&#160;probabilities.&#160;The&#160;top-<br/>
is&#160;not<br/>
and&#160;amenable<br/>
the&#160;re<br/>
to<br/>
cipie&#160;sequential<br/>
nts&#160;of<br/>
modeling.<br/>
the&#160;mes&#160;Instead,<br/>
se<br/>
sage,t&#160;α&#160;we<br/>
=&#160;0<br/>
whic&#160;chain<br/>
.<br/>
h1,&#160;β0&#160;=&#160;β2&#160;=&#160;0.01,&#160;β1&#160;=&#160;0.0001&#160;and&#160;γ&#160;=&#160;0.3—all&#160;wto<br/>
ea&#160;o<br/>
k&#160;u<br/>
s&#160;r<br/>
y&#160;mo<br/>
mm&#160;d<br/>
e&#160;el<br/>
tr&#160;s.<br/>
ic&#160;p&#160;Fi<br/>
rion<br/>
r&#160;a<br/>
s&#160;l<br/>
.&#160;ly,&#160;we&#160;combine&#160;two&#160;powerful&#160;ideas:<br/>
i.&#160;Draw&#160;Z&#160;∼&#160;Mult(π(η)).<br/>
(1)<br/>
/*&#160;Initialization&#160;*/<br/>
the&#160;natural&#160;parameters&#160;of&#160;each&#160;topic&#160;β<br/>
Gibbs&#160;sampling&#160;and&#160;entropy&#160;filtering&#160;to&#160;improve&#160;efficiency<br/>
t,k&#160;in&#160;a&#160;state&#160;space<br/>
is&#160;undesirable&#160;in&#160;many&#160;real-world&#160;situations.&#160;A&#160;manager&#160;may&#160;send&#160;email&#160;to&#160;a&#160;seicsThe<br/>
cretary<br/>
in&#160;conditio<br/>
and<br/>
the&#160;nal&#160;probability<br/>
semantic&#160;of&#160;a&#160;wo<br/>
class&#160;rd&#160;w&#160;giv<br/>
also&#160;en&#160;a<br/>
ha&#160;do<br/>
v&#160;c<br/>
e&#160;ument&#160;d&#160;can&#160;be&#160;written<br/>
probabilities,&#160;as:<br/>
used&#160;to&#160;choose&#160;a&#160;topic&#160;when&#160;(2)<br/>
the&#160;for&#160;each&#160;ema<br/>
HMM&#160;il&#160;d<br/>
model&#160;that&#160;evolves&#160;with&#160;Gaussian&#160;noise;&#160;the&#160;simplest&#160;ver-<br/>
ii.&#160;Draw&#160;Wt,d,n&#160;∼&#160;Mult(π(βt,z)).<br/>
and&#160;performance,&#160;yielding&#160;a&#160;new&#160;algorithm:&#160;EnF-Gibbs<br/>
vice&#160;versa,&#160;but&#160;the&#160;nature&#160;of&#160;the&#160;requests&#160;and&#160;language&#160;used&#160;may&#160;be&#160;quite&#160;different.&#160;Even<br/>
(3)<br/>
for&#160;each&#160;word&#160;ω<br/>
sion&#160;of&#160;such&#160;a&#160;model&#160;is<br/>
sampling.<br/>
i&#160;in&#160;d<br/>
transitions&#160;to&#160;the&#160;T<br/>
semantic&#160;class.&#160;Phrases&#160;are&#160;generated&#160;by&#160;following&#160;a&#160;path&#160;through&#160;the<br/>
more&#160;dramatically,&#160;consider&#160;the&#160;large&#160;quantity&#160;of&#160;junk&#160;email&#160;that&#160;we&#160;receive;&#160;modeling&#160;the<br/>
Note&#160;that&#160;π&#160;maps<br/>
!<br/>
the&#160;<a href="Blei_1s.html#1">multinomial&#160;natural&#160;parameters&#160;to&#160;the</a><br/>
(4)<br/>
assign&#160;ωi&#160;to&#160;random&#160;community,&#160;topic&#160;and&#160;user;<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic</a><br/>
<a href="Blei_1s.html#1">=</a><br/>
<a href="Blei_1s.html#1">Mo&#160;1&#160;)</a><br/>
<a href="Blei_1s.html#1">dels&#160;</a>(<br/>
+<br/>
=&#160;2<br/>
β<br/>
p(w|d)&#160;=&#160;p(x&#160;=&#160;0|d)<br/>
p(w|z&#160;=&#160;t)p(z&#160;<a href="Blei_1s.html#1">=&#160;t|d)&#160;+&#160;p(x</a><br/>
model,&#160;choosing&#160;a&#160;word&#160;from&#160;<a href="Blei_1s.html#1">the</a><br/>
<a href="Blei_1s.html#1"><b>4</b></a><br/>
<a href="Blei_1s.html#1">distrib<b>.1</b>|d&#160;</a><b>G</b><br/>
p!&#160;<b>i</b><br/>
<a href="Blei_1s.html#1">ution&#160;</a><b>b</b>w<b>bs</b><br/>
|d)&#160;<b>samp</b><br/>
p(&#160;<b>l</b>x<b>ing</b>|d)p!!(w)<br/>
(5)<br/>
/*&#160;user&#160;in&#160;the&#160;list&#160;observed&#160;from&#160;d&#160;*/<br/>
t,k&#160;|&#160;βt<br/>
associated&#160;with&#160;each&#160;syntactic&#160;class,&#160;and&#160;a<br/>
−1,k&#160;∼&#160;N&#160;(βt−1,k&#160;,&#160;σ2&#160;I&#160;)&#160;.<br/>
(1)<br/>
mean&#160;parameters,&#160;π(βk,t)w&#160;=<br/>
<a href="Blei_1s.html#1">exp(βk,t,w)</a><br/>
<a href="Blei_1s.html#1">.</a><br/>
<a href="Blei_1s.html#1">P</a><br/>
topics&#160;of&#160;these&#160;messages&#160;as&#160;undistinguished&#160;from&#160;the&#160;topics&#160;we&#160;write&#160;about&#160;as&#160;authors&#160;would<br/>
exp(β<br/>
w<br/>
k,t,w&#160;)<br/>
t=1<br/>
Gibbs&#160;sampling&#160;is&#160;an&#160;algorithm&#160;to&#160;approximate&#160;the&#160;joint<br/>
(6)<br/>
/*&#160;Markov&#160;chain&#160;convergence&#160;*/<br/>
be&#160;extremely&#160;confounding&#160;and&#160;undesirable&#160;since&#160;the&#160;Our<br/>
y<br/>
approach<br/>
do&#160;not&#160;is&#160;thus<br/>
reflect&#160;to&#160;model<br/>
our<br/>
sequences<br/>
expertise&#160;of<br/>
or&#160;compositional<br/>
roles<br/>
topic<br/>
.<br/>
follo<br/>
The<br/>
wed&#160;graphical<br/>
by&#160;a&#160;model<br/>
w<br/>
for<br/>
ord&#160;this&#160;generati<br/>
from&#160;ve&#160;process<br/>
the<br/>
is&#160;shown<br/>
distrib&#160;in<br/>
ution&#160;associated&#160;with&#160;that&#160;topic&#160;for&#160;the&#160;seman-<br/>
distribution&#160;of&#160;multiple&#160;variables&#160;by&#160;drawing&#160;a&#160;sequence<br/>
(7)<br/>
i&#160;←&#160;0;<br/>
random&#160;variables&#160;by&#160;chaining&#160;Gaussian&#160;distrib<br/>
whe&#160;utions<br/>
re&#160;p!(&#160;in<br/>
w|&#160;a<br/>
d)&#160;is&#160;Figure<br/>
the&#160;sp&#160;1.<br/>
ec&#160;When<br/>
ial&#160;w&#160;the<br/>
ord&#160;horizontal<br/>
distribu&#160;arro<br/>
tion&#160;ws<br/>
for&#160;are<br/>
do&#160;remo<br/>
cumveed,<br/>
nt&#160;break-<br/>
d,&#160;and&#160;p!!(w)&#160;is&#160;the&#160;background&#160;word<br/>
Alternatively&#160;we&#160;could&#160;still&#160;employ&#160;the&#160;AT&#160;model&#160;by&#160;ignoring&#160;the&#160;recipient&#160;inform<br/>
tic<br/>
ation<br/>
of&#160;samples.&#160;As&#160;a&#160;special&#160;case&#160;of&#160;the&#160;Metropolis-Hastings<br/>
(8)<br/>
I&#160;←&#160;desired&#160;number&#160;of&#160;iterations;<br/>
dynamic&#160;model&#160;and&#160;mapping&#160;the&#160;emitted&#160;values<br/>
distr&#160;to<br/>
ib&#160;the<br/>
utio<br/>
class.&#160;sim-<br/>
n&#160;for&#160;thing<br/>
e&#160;c&#160;the<br/>
orptime<br/>
us.<br/>
Sentences&#160;dynamics,<br/>
Note&#160;th<br/>
withatthew&#160;graphical<br/>
he<br/>
the&#160;n&#160;commodel<br/>
par<br/>
same&#160;ed&#160;reduces<br/>
to&#160;the&#160;to<br/>
s<br/>
syntax&#160;a<br/>
ta&#160;set<br/>
nd<br/>
b&#160;ard<br/>
ut&#160;topic<br/>
dif&#160;model&#160;th<br/>
ferent&#160;e&#160;SWB<br/>
cont&#160;mod<br/>
ent&#160;elwould&#160;be&#160;generated&#160;if&#160;the<br/>
algorithm&#160;[18],&#160;Gibbs&#160;sampling&#160;is&#160;a&#160;Markov&#160;chain&#160;Monte<br/>
(9)<br/>
while&#160;i&#160;&lt;&#160;I<br/>
of&#160;email&#160;and&#160;treating&#160;each&#160;email&#160;document&#160;as&#160;if&#160;it&#160;plex.<br/>
only&#160;This<br/>
has&#160;is&#160;an<br/>
one&#160;extension&#160;of<br/>
author.&#160;the<br/>
Hologistic<br/>
weve&#160;normal<br/>
c<br/>
r,&#160;an<br/>
inex&#160;distrib<br/>
pla<br/>
thisin&#160;u-<br/>
word&#160;of<br/>
s&#160;independent<br/>
in&#160;three&#160;diff&#160;topic<br/>
erentmodels.<br/>
ways,&#160;W<br/>
v&#160;ith<br/>
ia&#160;time<br/>
topic&#160;dynamics,<br/>
s,&#160;via&#160;a&#160;spthe<br/>
ec&#160;k<br/>
iath<br/>
l&#160;word&#160;distribution,&#160;or&#160;via&#160;a&#160;back-<br/>
topic&#160;distribution&#160;were&#160;different.&#160;The<br/>
Carlo&#160;algo<br/>
generati&#160;ri<br/>
v&#160;th<br/>
e&#160;m&#160;and&#160;usu<br/>
model&#160;ally<br/>
th&#160;app<br/>
us&#160;lies&#160;wh<br/>
acts&#160;en&#160;th<br/>
lik&#160;ee&#160;con<br/>
it&#160;diti<br/>
isonal<br/>
(10)<br/>
for&#160;each&#160;email&#160;d<br/>
playing&#160;a&#160;game<br/>
ground&#160;word&#160;distribution.&#160;Given&#160;the&#160;graphical&#160;model&#160;above,&#160;it&#160;is&#160;relatively&#160;straightforward&#160;to&#160;derive<br/>
case&#160;(which&#160;is&#160;similar&#160;to&#160;the&#160;LDA&#160;model)&#160;we&#160;are&#160;losing&#160;all&#160;information&#160;about&#160;the&#160;recipients,<br/>
probability&#160;distribution&#160;of&#160;each&#160;variable&#160;can&#160;be&#160;evaluated.<br/>
(11)<br/>
for&#160;each&#160;ωi&#160;∈&#160;d<br/>
of&#160;Gibbs&#160;sampling&#160;e<br/>
“Madlibs”:quation<br/>
the&#160;s&#160;that&#160;allow&#160;join<br/>
semantic&#160;t&#160;sampling&#160;of&#160;the<br/>
component&#160;z<br/>
and&#160;the&#160;connections&#160;between&#160;people&#160;implied&#160;by&#160;the&#160;sender-recipient&#160;relationships.<br/>
provides&#160;a&#160;list&#160;of&#160;topical&#160;words&#160;(shown&#160;in&#160;black)<br/>
Ri&#160;and&#160;x<br/>
ather&#160;th<br/>
i&#160;latent&#160;variables&#160;for&#160;each&#160;word<br/>
an&#160;explicitly&#160;parameterizing&#160;the&#160;distributions&#160;for<br/>
(12)<br/>
estimate&#160;P&#160;(ci,&#160;ui,&#160;zi|ωi),&#160;u&#160;∈&#160;αd;<br/>
token&#160;wi,&#160;for&#160;xi&#160;=&#160;0:<br/>
variables,&#160;Gibbs&#160;sampling&#160;integrates&#160;out&#160;the&#160;parameters<br/>
(13)<br/>
(p,&#160;q,&#160;r)&#160;←&#160;argmax(P&#160;(cp,&#160;uq,&#160;zr|ωi));<br/>
which&#160;are&#160;slotted&#160;into&#160;templates&#160;generated&#160;by&#160;the&#160;syntactic&#160;component&#160;(shown&#160;in&#160;gray).<br/>
and&#160;estimates&#160;the&#160;corresponding&#160;posterior&#160;probability.<br/>
(14)<br/>
/*assign&#160;community&#160;p,user&#160;q,&#160;topic&#160;r&#160;to&#160;ωi*/<br/>
252<br/>
Gibbs&#160;sampling&#160;was&#160;first&#160;introduced&#160;to&#160;estimate&#160;the&#160;Topic-<br/>
(15)<br/>
record&#160;assignment&#160;τ&#160;(cp,&#160;uq,&#160;zr,&#160;ωi);<br/>
N<br/>
CT&#160;D&#160;+&#160;α<br/>
W&#160;T<br/>
+<br/>
d0,<br/>
Word&#160;mo<br/>
td,<br/>
del&#160;in&#160;[7].&#160;In&#160;Gib<br/>
C&#160;b<br/>
w&#160;s<br/>
t,&#160;sampli<br/>
βn<br/>
0&#160;g,&#160;a&#160;Markov&#160;chain&#160;is<br/>
(16)<br/>
i&#160;+&#160;+;<br/>
p&#160;(x<br/>
−i&#160;+&#160;γ<br/>
−i<br/>
−i<br/>
<b>2.2&#160;</b>i&#160;=&#160;0,&#160;zi&#160;=&#160;t<br/>
<b>Infer</b><br/>
|w,&#160;x<br/>
<b>ence&#160;</b>−i,&#160;z−i,&#160;α,&#160;β0,&#160;γ&#160;)&#160;∝<br/>
×&#160;formed<br/>
&#34;<br/>
,&#160;the&#160;transitio<br/>
×&#160;n<br/>
&#34;&#160;between&#160;successive&#160;states&#160;of&#160;which<br/>
Nd,−i&#160;+&#160;3γ<br/>
+&#160;T&#160;α<br/>
+&#160;W&#160;β0<br/>
is&#160;sim<br/>
t!&#160;CT&#160;D<br/>
u<br/>
t!la<br/>
d,ted<br/>
−i<br/>
by&#160;repeated<br/>
w!&#160;CW&#160;T<br/>
ly&#160;d<br/>
w!&#160;ra<br/>
t,&#160;w<br/>
−iing&#160;a&#160;topic&#160;for&#160;each&#160;ob-<br/>
Figure&#160;6:&#160;Gibbs&#160;sampling&#160;for&#160;CUT&#160;models<br/>
served&#160;word&#160;from&#160;its&#160;conditional&#160;probability&#160;on&#160;all&#160;other<br/>
an<br/>
The&#160;d&#160;for&#160;x<br/>
EM&#160;algorithm&#160;can&#160;be&#160;applied&#160;to&#160;the&#160;graphical&#160;model&#160;shown&#160;in&#160;Figure&#160;1,&#160;treating&#160;the<br/>
i&#160;=&#160;1:<br/>
variables.&#160;In&#160;the&#160;Author-Topic&#160;model,&#160;the&#160;algorithm&#160;goes<br/>
4Note&#160;we&#160;denote&#160;user&#160;with&#160;u&#160;in&#160;our&#160;models&#160;instead&#160;of&#160;x&#160;as<br/>
over&#160;all&#160;documents&#160;word&#160;by&#160;word.&#160;For&#160;each&#160;word&#160;ωi,&#160;the<br/>
in&#160;previous&#160;work.<br/>
document&#160;distributions&#160;θ,&#160;the<br/>
N<br/>
topics&#160;and<br/>
CW&#160;D<br/>
classes&#160;+<br/>
φ&#160;β<br/>
,&#160;and&#160;the&#160;transition&#160;probabilities&#160;π&#160;as<br/>
1<br/>
p&#160;(x<br/>
d1,−i&#160;+&#160;γ<br/>
wd,−i<br/>
i&#160;=&#160;1&#160;|w,&#160;x−i,&#160;z−i,&#160;β1,&#160;γ&#160;)&#160;∝<br/>
×&#160;&#34;<br/>
parameters.&#160;However,&#160;EM<br/>
Nd,−<br/>
produces&#160;i&#160;+&#160;3γ<br/>
poor&#160;results<br/>
+&#160;W<br/>
with&#160;β<br/>
topic&#160;models,&#160;which&#160;have&#160;many&#160;pa-<br/>
w!&#160;CW&#160;D<br/>
w!d,−i<br/>
1<br/>
177<br/>
rameters&#160;and&#160;many&#160;local&#160;maxima.&#160;Consequently,&#160;recent&#160;work&#160;has&#160;focused&#160;on&#160;approximate<br/>inference&#160;algorithms&#160;[6,&#160;8].&#160;We&#160;will&#160;use&#160;Markov&#160;chain&#160;Monte&#160;Carlo&#160;(MCMC;&#160;see&#160;[9])&#160;to<br/>perform&#160;full&#160;Bayesian&#160;inference&#160;in&#160;this&#160;model,&#160;sampling&#160;from&#160;a&#160;posterior&#160;distribution&#160;over<br/>assignments&#160;of&#160;words&#160;to&#160;classes&#160;and&#160;topics.<br/>
We&#160;assume&#160;that&#160;the&#160;document-specific&#160;distributions&#160;over&#160;topics,&#160;θ,&#160;are&#160;drawn&#160;from&#160;a<br/>Dirichlet(α)&#160;distribution,&#160;the&#160;topic&#160;distributions&#160;φ(z)&#160;are&#160;drawn&#160;from&#160;a&#160;Dirichlet(β)&#160;dis-<br/>tribution,&#160;the&#160;rows&#160;of&#160;the&#160;transition&#160;matrix&#160;for&#160;the&#160;HMM&#160;are&#160;drawn&#160;from&#160;a&#160;Dirichlet(γ)<br/>distribution,&#160;the&#160;class&#160;distributions&#160;φ(c)&#160;are&#160;drawn&#160;from&#160;a&#160;Dirichlet(δ)&#160;distribution,&#160;and&#160;all<br/>Dirichlet&#160;distributions&#160;are&#160;symmetric.&#160;We&#160;use&#160;Gibbs&#160;sampling&#160;to&#160;draw&#160;iteratively&#160;a&#160;topic<br/>assignment&#160;zi&#160;and&#160;class&#160;assignment&#160;ci&#160;for&#160;each&#160;word&#160;wi&#160;in&#160;the&#160;corpus&#160;(see&#160;[8,&#160;9]).<br/>Given&#160;the&#160;words&#160;w,&#160;the&#160;class&#160;assignments&#160;c,&#160;the&#160;other&#160;topic&#160;assignments&#160;z−i,&#160;and&#160;the<br/>
hyperparameters,&#160;each&#160;zi&#160;is&#160;drawn&#160;from:<br/>
P&#160;(zi|z−i,&#160;c,&#160;w)&#160;∝<br/>
P&#160;(zi|z−i)<br/>
P&#160;(wi|z,&#160;c,&#160;w−i)<br/>
!&#160;n(di)&#160;+&#160;α<br/>
c<br/>
∝<br/>
zi<br/>
(z<br/>
i&#160;!=&#160;1<br/>
i&#160;)<br/>
(<br/>
+β<br/>
n(di)<br/>
wi<br/>
c<br/>
z<br/>
+&#160;α)<br/>
n<br/>
i&#160;=&#160;1<br/>
i<br/>
n(zi)+W&#160;β<br/>
<hr/>
<a name=31></a><img class="yflip" src="./Blei_1-31_1.png"/><br/>
<img class="yflip" src="./Blei_1-31_2.png"/><br/>
<img class="yflip" src="./Blei_1-31_3.png"/><br/>
<img class="yflip" src="./Blei_1-31_4.png"/><br/>
<img class="yflip" src="./Blei_1-31_5.png"/><br/>
<img class="yflip" src="./Blei_1-31_6.png"/><br/>
<img class="yflip" src="./Blei_1-31_7.png"/><br/>
<img class="yflip" src="./Blei_1-31_8.png"/><br/>
<img class="yflip" src="./Blei_1-31_9.png"/><br/>
<img class="yflip" src="./Blei_1-31_10.png"/><br/>
<img class="yflip" src="./Blei_1-31_11.png"/><br/>
<img class="yflip" src="./Blei_1-31_12.png"/><br/>
<img class="yflip" src="./Blei_1-31_13.png"/><br/>
constraints&#160;of&#160;word&#160;alignment,&#160;i.e.,&#160;words&#160;“close-in-source”&#160;are&#160;usually&#160;aligned&#160;to&#160;words&#160;“close-in-<br/>
target”,&#160;under&#160;document-specific&#160;topical&#160;assignment.&#160;To&#160;incorporate&#160;such&#160;constituents,&#160;we&#160;integrate<br/>
the&#160;strengths&#160;of&#160;both&#160;HMM&#160;and&#160;BiTAM,&#160;and&#160;propose&#160;a&#160;Hidden&#160;Markov&#160;Bilingual&#160;Topic-AdMixture<br/>
model,&#160;or&#160;HM-BiTAM,&#160;for&#160;word&#160;alignment&#160;to&#160;leverage&#160;both&#160;locality&#160;constraints&#160;and&#160;topical&#160;context<br/>
underlying&#160;parallel&#160;document-pairs.<br/>In&#160;the&#160;HM-BiTAM&#160;framework,&#160;one&#160;can&#160;estimate&#160;topic-specific&#160;word-to-word&#160;translation&#160;lexicons<br/>
(lexical&#160;mappings),&#160;as&#160;well&#160;as&#160;the&#160;monolingual&#160;topic-specific&#160;word-frequencies&#160;for&#160;both&#160;languages,<br/>
based&#160;on&#160;parallel&#160;document-pairs.&#160;The&#160;resulting&#160;model&#160;offers&#160;a&#160;principled&#160;way&#160;of&#160;inferring&#160;optimal<br/>
translation&#160;from&#160;a&#160;given&#160;source&#160;language&#160;in&#160;a&#160;context-dependent&#160;fashion.&#160;We&#160;report&#160;an&#160;extensive<br/>
empirical&#160;analysis&#160;of&#160;HM-BiTAM,&#160;in&#160;comparison&#160;with&#160;related&#160;methods.&#160;We&#160;show&#160;our&#160;model’s&#160;ef-<br/>
fectiveness&#160;on&#160;the&#160;word-alignment&#160;task;&#160;we&#160;also&#160;demonstrate&#160;two&#160;application&#160;aspects&#160;which&#160;were<br/>
untouched&#160;in&#160;[10]:&#160;the&#160;utility&#160;of&#160;HM-BiTAM&#160;for&#160;bilingual&#160;topic&#160;exploration,&#160;and&#160;its&#160;application&#160;for<br/>
improving&#160;translation&#160;qualities.<br/>
2&#160;Revisit&#160;HMM&#160;for&#160;SMT<br/>An&#160;SMT&#160;system&#160;can&#160;be&#160;formulated&#160;as&#160;a&#160;noisy-channel&#160;model&#160;[2]:<br/>
e∗&#160;=&#160;arg&#160;max&#160;P&#160;(e|f)&#160;=&#160;arg&#160;max&#160;P&#160;(f|e)P&#160;(e),<br/>
(1)<br/>
e<br/>
e<br/>
where&#160;a&#160;translation&#160;corresponds&#160;to&#160;searching&#160;for&#160;the&#160;target&#160;sentence&#160;e∗&#160;which&#160;explains&#160;the&#160;source<br/>
sentence&#160;f&#160;best.&#160;The&#160;key&#160;component&#160;is&#160;P&#160;(f|e),&#160;the&#160;translation&#160;model;&#160;P&#160;(e)&#160;is&#160;monolingual&#160;language<br/>
model.&#160;In&#160;this&#160;paper,&#160;we&#160;generalize&#160;P&#160;(f|e)&#160;with&#160;topic-admixture&#160;models.<br/>An&#160;HMM&#160;implements&#160;the&#160;“proximity-bias”&#160;assumption&#160;—&#160;that&#160;words&#160;“close-in-source”&#160;are&#160;aligned<br/>
LDA&#160;istomo<br/>
words<br/>
introduce&#160;thedula<br/>
“close-in-target”,<br/>
mapping&#160;j&#160;r,<br/>
which<br/>
→&#160;aj,<br/>
general,<br/>
is&#160;effective&#160;for&#160;improving&#160;w<br/>
which&#160;assigns&#160;a&#160;French&#160;word&#160;fuseful<br/>
ord&#160;alignment&#160;accuracies,&#160;especially<br/>
for&#160;linguistically&#160;close&#160;language-pairs&#160;[8].&#160;Following&#160;[8],&#160;to&#160;model&#160;word-to-word&#160;translation,&#160;we<br/>
McCallum,&#160;Wang,&#160;&amp;&#160;Corrada-Emmanuel<br/>
j&#160;in&#160;position&#160;j&#160;to&#160;an&#160;English&#160;word<br/>
ei&#160;in&#160;position&#160;i&#160;=&#160;aj&#160;denoted&#160;as&#160;ea&#160;.&#160;Each&#160;(ordered)&#160;French&#160;word&#160;f<br/>
j<br/>
j&#160;is&#160;an&#160;observation,&#160;and&#160;it&#160;is<br/>
generated&#160;by&#160;an&#160;HMM&#160;state&#160;defined&#160;as&#160;[ea&#160;,&#160;a<br/>
j<br/>
j&#160;],&#160;where&#160;the&#160;alignment&#160;indicator&#160;aj&#160;for&#160;position&#160;j&#160;is<br/>
considered&#160;to&#160;have&#160;a&#160;dependency&#160;on&#160;the&#160;previous&#160;alignment&#160;aj−1.&#160;Thus&#160;a&#160;first-order&#160;HMM&#160;for&#160;an<br/>
alignment&#160;between&#160;e&#160;≡&#160;e1:I&#160;and&#160;f&#160;≡&#160;f1:J&#160;is&#160;defined&#160;as:<br/>
<b>Latent Dirichlet&#160;Allocation</b><br/>
<b>Author&#160;Model</b><br/>
<b>Author-Topic Model</b><br/>
<b>Author-Recipient-Topic Model</b><br/>
!&#160;J<br/>
&#34;<br/>
(LDA)<br/>
(Multi-label Mixture Model)<br/>
(AT)<br/>
(ART)<br/>
<b>Dynamic&#160;Topic&#160;Models</b><br/>
p(f1:J&#160;|e1:I)&#160;=<br/>
p(fj|ea&#160;)p(aj|aj−1),<br/>
(2)<br/>
[Blei, Ng, Jordan, 2003]<br/>
[McCallum 1999]<br/>
[Rosen-Zvi, Griffiths, Steyvers, Smyth 2004]<br/>
[This paper]<br/>
j<br/>
a1:&#160;j=1<br/>
ways,&#160;and&#160;quantitative&#160;results&#160;that&#160;demonstrate&#160;greater<br/>
J<br/>
pre-<br/>
α<br/>
α<br/>
α<br/>
!<br/>
<b>a</b><br/>
<b>a</b><br/>
a<br/>
<b>r</b><br/>
d<br/>
dictivedaccuracy&#160;when&#160;compared&#160;withd&#160;staticd&#160;topic&#160;models.<br/>
topic&#160;zi&#160;and&#160;the&#160;author&#160;xi&#160;responsible&#160;for&#160;this&#160;word&#160;are<br/>
where&#160;p(aj|aj−1)&#160;is&#160;the&#160;state&#160;transition&#160;probability;&#160;J&#160;and&#160;I&#160;are&#160;sentence&#160;lengths&#160;of&#160;the&#160;French&#160;and<br/>
α<br/>
θ<br/>
assigned&#160;based&#160;on&#160;the&#160;posterior&#160;probability&#160;conditioned&#160;on<br/>
English&#160;sentences,&#160;respectively.&#160;The&#160;transition&#160;model&#160;enforces&#160;the&#160;proximity-bias.&#160;An&#160;additional<br/>
&#34;<br/>
z<br/>
<b>2.&#160;Dynamic</b><br/>
pseudo&#160;x<br/>
<b>Topic&#160;Models</b><br/>
θ<br/>
θ<br/>
θ<br/>
word&#160;”NULL”&#160;is&#160;used&#160;at&#160;the&#160;xbeginning&#160;of&#160;English&#160;sentences&#160;for&#160;HMM&#160;to&#160;start&#160;with.&#160;The<br/>
<i>C</i><br/>
all&#160;other&#160;variables:&#160;P&#160;(zi,&#160;xi|ωi,&#160;z−i,&#160;x−i,&#160;w−i,&#160;ad).&#160;zi&#160;and<br/>
(a)<br/>
!<br/>
(a)<br/>
(b)<br/>
(b)<br/>
&#34;<br/>
xi&#160;denote&#160;the&#160;topic&#160;and&#160;author&#160;assigned&#160;to&#160;ωi,&#160;while&#160;z<br/>
&#34;<br/>
1<br/>
'<br/>
HMM&#160;implemented&#160;in&#160;GIZA++&#160;[5]&#160;is&#160;used&#160;as&#160;our&#160;baseline,&#160;which&#160;includes&#160;refinements&#160;2<br/>
such&#160;as<br/>
#<br/>
−i<br/>
While&#160;traditional&#160;time&#160;series&#160;modeling&#160;has&#160;focused&#160;on&#160;con-<br/>
#<br/>
0.2<br/>
z<br/>
z<br/>
z<br/>
and&#160;x−i&#160;are&#160;all&#160;other&#160;assignments&#160;of&#160;topic&#160;and&#160;author&#160;ex-<br/>
!<br/>
&#34;<br/>
tinuous<br/>
special&#160;data,&#160;topic<br/>
treatment!ofmodels<br/>
a&#160;&#34;&#160;are<br/>
jump&#160;to&#160;designed<br/>
a<br/>
for<br/>
NULL&#160;w&#160;cate<br/>
ord.&#160;gorical<br/>
A&#160;graphical&#160;model&#160;representation&#160;for&#160;such&#160;an&#160;HMM<br/>
z<br/>
z<br/>
z<br/>
γ<br/>
ψ<br/>
cluding&#160;current&#160;instance.&#160;w<br/>
A<br/>
is&#160;data.&#160;Our&#160;approach<br/>
illustrated&#160;in<br/>
is&#160;to<br/>
Figure&#160;use<br/>
A,A<br/>
1&#160;state<br/>
(a).<br/>
space&#160;models&#160;on&#160;the&#160;nat-<br/>
−i&#160;represents&#160;other&#160;observed<br/>
0.5<br/>
0.4<br/>
0.1<br/>
w<br/>
w<br/>
w<br/>
network&#160;used&#160;&#160;for&#160;images&#160;words&#160;in&#160;the&#160;document&#160;set&#160;and&#160;a<br/>
ural&#160;parameter&#160;space&#160;of&#160;the&#160;underlying&#160;topic&#160;multinomials,<br/>
$<br/>
network<br/>
%image&#160;(&#160;kernel<br/>
<i>T</i><br/>
α<br/>
d&#160;is&#160;the&#160;observed&#160;author<br/>
<i>z</i>1<br/>
<i>z</i>2<br/>
<i>z</i>3<br/>
<i>z</i><br/>
$<br/>
&amp;<br/>
di<br/>
4<br/>
neural<br/>
images<br/>
support<br/>
set&#160;for&#160;this&#160;document.<br/>
$<br/>
#<br/>
w<br/>
$<br/>
#<br/>
$<br/>
#<br/>
w<br/>
as&#160;well<br/>
w&#160;as&#160;on&#160;the&#160;natural<br/>
$<br/>
#&#160;parameters&#160;for<br/>
w&#160;the&#160;logistic&#160;nor-<br/>
N<br/>
0.8<br/>
N<br/>
N<br/>
image&#160;obtained&#160;with&#160;kernel<br/>
A&#160;βk<br/>
A<br/>
A<br/>
0.7<br/>
T<br/>
A<br/>
T<br/>
T<br/>
networks<br/>
object<br/>
vector<br/>
A&#160;key&#160;issue&#160;in&#160;using&#160;Gibbs&#160;sampling&#160;for&#160;distribution<br/>
Nd<br/>
Nd<br/>
mal&#160;distrib<br/>
Nd&#160;utions&#160;used&#160;for&#160;modeling&#160;the&#160;document-specific<br/>
Nd<br/>
&#34;<br/>
K<br/>
output<br/>
objects<br/>
svm<br/>
β<br/>
φ<br/>
ω<br/>
output&#160;described&#160;with<br/>
appro<br/>
objects&#160;ximation&#160;is&#160;the&#160;evaluation&#160;of&#160;conditional&#160;posterior<br/>
topic&#160;proportions.<br/>
<i>z</i><br/>
...<br/>
&#34;<br/>
...<br/>
...<br/>
<i>x</i><br/>
0<br/>
<i>z</i><br/>
N<br/>
D<br/>
D<br/>
D<br/>
D<br/>
β<br/>
β<br/>
β<br/>
d<br/>
used<br/>
probability.&#160;In&#160;Author-Topic&#160;model,&#160;given&#160;T&#160;topics&#160;and&#160;V<br/>
I<br/>
<i>w</i><br/>
m,n<br/>
1<br/>
<i>w</i>2<br/>
<i>w</i>3<br/>
<i>w</i><br/>
in<br/>
K<br/>
<i>U</i><br/>
<i>D</i>neural&#160;network&#160;trained&#160;with&#160;svm&#160;images<br/>
First,&#160;we&#160;revie<br/>
Im,n<br/>
e&#160;w&#160;the&#160;underlying&#160;statistical&#160;assumptions&#160;of<br/>
4<br/>
m,i<br/>
em,i&#160;with<br/>
trained<br/>
words,&#160;P&#160;(zi,&#160;xi|ωi,&#160;z−i,&#160;x−i,&#160;w−i,&#160;ad)&#160;is&#160;estimated&#160;by:<br/>
a&#160;static&#160;topic&#160;model,&#160;such&#160;as&#160;latent&#160;Dirichlet<br/>
B&#160;=&#160;p(f&#160;|e)&#160;allocation<br/>
obtained<br/>
Figure<br/>
!<br/>
1.&#160;Graphical<br/>
<i>w</i><br/>
representation<br/>
for<br/>
of&#160;a&#160;dynamic&#160;topic<br/>
Bk&#160;model&#160;(for<br/>
Figure&#160;1:&#160;Three&#160;related&#160;models,&#160;and&#160;the&#160;ART&#160;model.&#160;In&#160;all&#160;models,&#160;each&#160;observed&#160;word,<br/>
K<br/>
α<br/>
θm<br/>
zm,n<br/>
on<br/>
!<br/>
<i>w</i><br/>
(LDA)&#160;(Blei&#160;et&#160;al.,&#160;2003).&#160;Let&#160;β<br/>
0.9<br/>
Figure&#160;5:&#160;Mode<br/>
described&#160;ling&#160;community&#160;with&#160;topics<br/>
1:K&#160;be&#160;K&#160;topics,&#160;each&#160;of<br/>
three&#160;time&#160;slices).&#160;Each<br/>
<i>N</i><br/>
topic’s&#160;natural&#160;parameters&#160;βt,k&#160;evolve<br/>
fm,1<br/>
fm,2<br/>
f<br/>
f<br/>
<i>T</i><br/>
<i>d</i><br/>
<i>N</i>...<br/>
which&#160;is&#160;a&#160;distribution&#160;ov<br/>
m,&#160;er<br/>
3<br/>
a&#160;fixedJ<br/>
fm,1<br/>
fm,2<br/>
f<br/>
f<br/>
m,v<br/>
n&#160;ocab<br/>
<i>s</i><br/>
m,3<br/>
J<br/>
1<br/>
ulary.<i>s</i>2In&#160;a&#160;static<br/>
...<br/>
<i>s</i>3<br/>
over<br/>
<i>s</i>4time,&#160;together&#160;with&#160;the<br/>
w,&#160;is&#160;generated&#160;from&#160;a&#160;multinomial&#160;word&#160;distribution,&#160;φ<br/>
<i>D</i><br/>
mean&#160;parameters<br/>
m,n<br/>
α<br/>
P&#160;(z<br/>
<i>T</i><br/>
<i>d</i><br/>
i&#160;=&#160;j,&#160;xi&#160;=&#160;k<br/>
<i>D</i><br/>
|ωi&#160;=&#160;m,&#160;z<br/>
t&#160;of&#160;the&#160;logistic<br/>
−i,&#160;x−i,&#160;w−i,&#160;ad)&#160;∝<br/>
(4)<br/>
z&#160;,&#160;specific&#160;to&#160;a&#160;particular<br/>
topic&#160;model,&#160;each&#160;document&#160;is&#160;assumed&#160;drawn&#160;from&#160;the<br/>
normal&#160;distribution&#160;for&#160;the&#160;topic&#160;proportions.<br/>
topic/author,&#160;z,&#160;however&#160;topics&#160;are&#160;selected&#160;differently&#160;in&#160;each&#160;of&#160;the&#160;models.<br/>
sider&#160;the&#160;conditional&#160;probability&#160;P&#160;(c,&#160;u,&#160;z<br/>
P&#160;(ωi&#160;=&#160;m|xi&#160;=&#160;k)P&#160;(xi&#160;=&#160;k|zi&#160;=&#160;j)&#160;∝<br/>
(5)<br/>
following&#160;generati<br/>
am,1<br/>
a&#160;v<br/>
m,&#160;e<br/>
2<br/>
process:<br/>
|ω),&#160;a&#160;word&#160;ω&#160;as-<br/>
am,3<br/>
aJ<br/>
am,1<br/>
am,2<br/>
a<br/>
a<br/>
m,n<br/>
m,3<br/>
Jm,n<br/>
Nm<br/>
Figure&#160;1:&#160;Graph<br/>
Figure&#160;ical<br/>
1:&#160;models<br/>
The&#160;for&#160;(a)&#160;the&#160;standa<br/>
composite&#160;rd&#160;LDA&#160;to<br/>
Nm&#160;pic<br/>
model.&#160;so<br/>
m&#160;ci<br/>
od<br/>
(a)&#160;aetles(letfht)ree<br/>
an&#160;v<br/>
d&#160;a<br/>
(&#160;ri<br/>
b&#160;a<br/>
)<br/>
Graphical&#160;bl<br/>
th&#160;es<br/>
e&#160;:<br/>
pr&#160;co<br/>
opmm<br/>
ose<br/>
model.udnsitpye,c<br/>
(b)&#160;u<br/>
ia&#160;s<br/>
l&#160;er&#160;and<br/>
Gene&#160;topic.&#160;O<br/>
rating&#160;ur<br/>
In&#160;LDA,&#160;the&#160;topic&#160;is&#160;sampled&#160;from&#160;a&#160;per-document&#160;topic&#160;distribution,<br/>
phrases.<br/>
CW&#160;T<br/>
θ,&#160;which<br/>
mj<br/>
+&#160;β<br/>
CAT<br/>
kj<br/>
+&#160;α<br/>
M<br/>
words&#160;topic&#160;model&#160;with&#160;a&#160;background&#160;distribution&#160;(SWB<br/>
M<br/>
)&#160;(&#160;in<br/>
r&#160;t<br/>
ig&#160;erp<br/>
ht).&#160;retation&#160;of&#160;the&#160;semantic&#160;meaning&#160;of&#160;P&#160;(c,&#160;u,&#160;z|ω)&#160;is<br/>
(6)<br/>
in&#160;turn&#160;is&#160;sampled&#160;from&#160;a&#160;Dirichlet&#160;over<br/>
1.&#160;Choose<br/>
topics.&#160;In&#160;topic<br/>
the&#160;proportions<br/>
Author&#160;θ&#160;from<br/>
Mo&#160;a<br/>
del,&#160;distrib<br/>
the&#160;ution<br/>
re&#160;is&#160;over<br/>
tion&#160;(Aitchison,&#160;1982)&#160;to&#160;time-series&#160;simplex&#160;data&#160;(West<br/>
Σm!&#160;CWT&#160;+&#160;V&#160;β&#160;Σj!&#160;CAT<br/>
the&#160;probability&#160;that&#160;word&#160;ω&#160;is&#160;generated&#160;by&#160;user&#160;u&#160;under<br/>
m!j<br/>
kj!&#160;+&#160;T&#160;α<br/>
the&#160;(K&#160;−&#160;1)-simplex,&#160;such&#160;as&#160;a&#160;Dirichlet.<br/>
and&#160;Harrison,&#160;1997).<br/>
one&#160;topic&#160;associated&#160;with&#160;each&#160;author&#160;(or&#160;category),&#160;and<br/>
Ti,i!<br/>
authors&#160;are<br/>
φ(z)sam<br/>
,&#160;pled<br/>
each&#160;class&#160;c&#160;!=&#160;1&#160;isTi,i!&#160;associated&#160;with&#160;a&#160;distribution&#160;over&#160;words&#160;φ(c),&#160;each&#160;document<br/>
topic&#160;z,&#160;in&#160;community&#160;c.<br/>
where&#160;m&#34;&#160;&#34;=&#160;m&#160;and&#160;j&#34;&#160;&#34;=&#160;j,&#160;α&#160;and&#160;β&#160;are&#160;prior&#160;parameters<br/>
2.&#160;For&#160;each&#160;word:<br/>
In&#160;LDA,&#160;the&#160;document-specific&#160;topic&#160;proportions&#160;θ&#160;are<br/>
uniformly.&#160;In&#160;the&#160;Author-Topic&#160;model,&#160;the&#160;topic<br/>
(a)&#160;is&#160;sam<br/>
HMM&#160;pled<br/>
for&#160;W&#160;from<br/>
ord<br/>
a&#160;p<br/>
Alignmenter-author<br/>
(b)&#160;HM-BiTAM<br/>
Unfortunately,&#160;this&#160;conditional&#160;probability&#160;cannot&#160;be&#160;com-<br/>
are&#160;generated&#160;by&#160;drawing&#160;a&#160;topic&#160;t&#160;from&#160;the&#160;document-topic&#160;distribution&#160;p(z<br/>
for&#160;word&#160;and&#160;topic&#160;Dirichlets,&#160;CW&#160;T<br/>
d&#160;has&#160;a&#160;distribution&#160;over&#160;topics&#160;θ(d),&#160;and<br/>
|θd)&#160;and&#160;then&#160;drawing<br/>
mj<br/>
represents&#160;the&#160;number<br/>
transitions&#160;between&#160;classes&#160;c<br/>
(a)&#160;Choose&#160;a&#160;topic&#160;assignment&#160;Z&#160;∼&#160;Mult(θ).<br/>
drawn&#160;from&#160;a&#160;Dirichlet&#160;distribution.&#160;In&#160;the&#160;dynamic&#160;topic<br/>
puted&#160;directly.&#160;To&#160;get&#160;P&#160;(c,&#160;u,&#160;z<br/>
i<br/>
multinomial&#160;distribution,<br/>
−1&#160;and&#160;ci&#160;follow&#160;a<br/>
Figure&#160;1:&#160;The&#160;graphical&#160;model<br/>
a&#160;wo<br/>
representations&#160;rd<br/>
of&#160;w<br/>
(a)&#160;from&#160;th<br/>
HMM,&#160;e<br/>
andtop<br/>
(b)ic-word<br/>
HM-BiT&#160;distr<br/>
AM,&#160;ibu<br/>
for&#160;tion&#160;p(<br/>
parallel&#160;w<br/>
|ω)&#160;,we&#160;have:<br/>
of&#160;times&#160;that&#160;word&#160;ωi&#160;=&#160;m&#160;is&#160;assigned&#160;to&#160;topic&#160;zi&#160;=&#160;j,<br/>
θ,&#160;and&#160;authors&#160;are&#160;sampled&#160;uniformly&#160;from&#160;the&#160;observed<br/>
|z&#160;=<br/>
corpora.&#160;t,&#160;φt).<br/>
Circles&#160;As&#160;shown&#160;in&#160;Griffiths&#160;and&#160;Steyvers<br/>
(b)&#160;Choose&#160;a&#160;word&#160;W&#160;∼&#160;Mult(β<br/>
model,&#160;we&#160;use&#160;a&#160;logistic&#160;normal&#160;with&#160;mean&#160;α&#160;to&#160;express<br/>
z&#160;).<br/>
represent&#160;random&#160;variables,&#160;hexagons<br/>
(20<br/>
denote&#160;04<br/>
distrib&#160;)&#160;the&#160;top<br/>
ution<br/>
parameters,&#160;ic<br/>
π(si−1)<br/>
and&#160;uncertainty<br/>
assignm<br/>
observ&#160;e<br/>
ed&#160;n<br/>
.vov<br/>
ts&#160;erz<br/>
A&#160;proportions.<br/>
fo<br/>
ariablesr&#160;ea<br/>
are&#160;ch&#160;The<br/>
wor<br/>
shaded.&#160;d&#160;sequential<br/>
to<br/>
document&#160;ke<br/>
is&#160;n&#160;in&#160;structure<br/>
the&#160;cor&#160;be<br/>
pu-<br/>
CAT<br/>
s<br/>
generated&#160;can&#160;b<br/>
viae&#160;effic<br/>
the&#160;iently&#160;sa<br/>
follo&#160;mpled<br/>
wingvia<br/>
procedure:<br/>
kj<br/>
represents&#160;the&#160;number&#160;of&#160;times&#160;that&#160;author&#160;xi&#160;=&#160;k&#160;is<br/>
list&#160;of&#160;the&#160;document’s&#160;authors.&#160;In&#160;the&#160;Author-Recipient-Topic&#160;model,&#160;there&#160;is<br/>
Gibbs&#160;sampling&#160;(tween<br/>
after&#160;models<br/>
margin&#160;is<br/>
a&#160;ag<br/>
liz&#160;ain<br/>
ing&#160;captured<br/>
over&#160;θ&#160;a&#160;with<br/>
nd&#160;φ&#160;a<br/>
).&#160;simple<br/>
Point&#160;dynamic<br/>
estimates&#160;for&#160;the&#160;θ&#160;and&#160;φ&#160;dis&#160;P<br/>
tr&#160;(c,<br/>
ibu&#160;u,<br/>
tio&#160;z<br/>
n&#160;,s&#160;ω)<br/>
assigned&#160;to&#160;topic&#160;j.<br/>
a&#160;separate&#160;topic-distribution&#160;for&#160;each<br/>
This&#160;process<br/>
author-rec<br/>
implicitly<br/>
ipient&#160;pair,&#160;assumes<br/>
and<br/>
that<br/>
the&#160;the<br/>
sele&#160;documents<br/>
ction&#160;of&#160;are<br/>
P&#160;(c,&#160;u,&#160;z|ω)&#160;=<br/>
(3)<br/>
can&#160;be&#160;comp<br/>
2uted&#160;model<br/>
conditioned&#160;on&#160;a&#160;particular&#160;sample,&#160;and&#160;predictive&#160;distributions&#160;can&#160;be&#160;Σ<br/>
The&#160;transformation&#160;from&#160;Eq.&#160;4&#160;to&#160;Eq.&#160;5&#160;drops&#160;the&#160;vari-<br/>
obtained&#160;by<br/>
drawn&#160;<i>exchangeably&#160;</i>from&#160;the&#160;same&#160;set&#160;of&#160;topics.&#160;For&#160;many<br/>
c,u,z&#160;P&#160;(c,&#160;u,&#160;z,&#160;ω)<br/>
ables,&#160;z<br/>
topic-distribution&#160;is&#160;determined&#160;from&#160;the&#160;observed&#160;author,&#160;and&#160;by&#160;uniformly&#160;sam<br/>
1.&#160;-Sample&#160;θ(d)&#160;from&#160;a&#160;Dirichlet(α)&#160;prior<br/>
−i,&#160;x−i,&#160;w−i,&#160;ad,&#160;because&#160;each&#160;instance&#160;of&#160;ωi&#160;is<br/>
averaging&#160;over&#160;multiple&#160;samples.<br/>
collections,&#160;however,&#160;the&#160;order&#160;of&#160;the&#160;documents&#160;reflects<br/>
αt&#160;|&#160;αt<br/>
•&#160;The&#160;data&#160;generating&#160;distribution&#160;can&#160;be&#160;changed.<br/>
−1&#160;∼&#160;N&#160;(αt−1&#160;,&#160;δ2&#160;I&#160;)&#160;.<br/>
(2)<br/>
Consider&#160;the&#160;denominator&#160;in&#160;Eq.&#160;3,&#160;summing&#160;over&#160;all&#160;c,<br/>
assumed&#160;independent&#160;of&#160;the&#160;other&#160;words&#160;in&#160;a&#160;message.<br/>
pling&#160;a&#160;recipient&#160;from&#160;the&#160;set&#160;of&#160;recipients&#160;an&#160;e<br/>
for&#160;volving<br/>
the&#160;set<br/>
doc&#160;of&#160;topics.<br/>
ument.&#160;In&#160;a&#160;dynamic&#160;topic&#160;model,&#160;we<br/>
We&#160;will<br/>
2.&#160;refe<br/>
F&#160;r&#160;to&#160;F<br/>
or&#160;th&#160;or<br/>
e&#160;simplicity<br/>
pr<br/>
eachopo<br/>
w&#160;sed,&#160;we<br/>
m<br/>
ord&#160;o&#160;do<br/>
d<br/>
w&#160;elnot<br/>
as&#160;model<br/>
the&#160;s&#160;the<br/>
pec&#160;dynamics<br/>
ial&#160;word&#160;of<br/>
s&#160;topic<br/>
u&#160;a<br/>
topic&#160;cor<br/>
nd<br/>
mo-z&#160;makes&#160;the&#160;computation&#160;impractical&#160;in&#160;terms&#160;of&#160;ef-<br/>
del&#160;with&#160;background&#160;distribution<br/>
i&#160;in&#160;document&#160;d<br/>
suppose&#160;that&#160;the&#160;data&#160;is&#160;divided&#160;by&#160;time&#160;slice,&#160;for&#160;example<br/>
(SWB)&#160;(Figure&#160;1(relation,<br/>
b)).<br/>
as<br/>
SWBwas<br/>
ha&#160;done<br/>
s&#160;a&#160;s&#160;for<br/>
im&#160;static<br/>
ilar&#160;gemodels<br/>
neral&#160;by<br/>
str&#160;Blei<br/>
uctu&#160;and<br/>
re&#160;Laf<br/>
fici<br/>
to&#160;thferty<br/>
ency.&#160;In&#160;addition,&#160;as&#160;shown&#160;in&#160;[7],&#160;the&#160;summing&#160;doesn’t<br/>
e&#160;LDA&#160;model&#160;(Figure&#160;1(a))&#160;but&#160;with<br/>
<b>4.2&#160;Semantic&#160;community&#160;discovery</b><br/>
by&#160;year.&#160;We&#160;model&#160;the&#160;documents&#160;of&#160;each&#160;slice&#160;with&#160;a&#160;K-<br/>
(2006).<br/>
factorize,&#160;which&#160;makes&#160;the&#160;manipulation&#160;of&#160;denominator<br/>
additional&#160;mach<br/>
(a)&#160;inery&#160;to<br/>
Dra&#160;h<br/>
wanzdile&#160;specia<br/>
from&#160;l&#160;w<br/>
θ(d)<br/>
ords&#160;and&#160;background&#160;words.&#160;In&#160;particular,&#160;associated&#160;with<br/>
By&#160;applying&#160;the&#160;Gibbs&#160;sampling,&#160;we&#160;can&#160;discover&#160;the&#160;se-<br/>
component&#160;topic&#160;model,&#160;where&#160;the&#160;topics&#160;associated&#160;with<br/>
difficult.&#160;In&#160;the&#160;following&#160;section,&#160;we&#160;will&#160;show&#160;how&#160;an<br/>
each&#160;word&#160;token&#160;is&#160;a&#160;latent&#160;random&#160;variable&#160;x,&#160;taking&#160;value&#160;x&#160;=&#160;0&#160;if&#160;the&#160;word&#160;w&#160;is&#160;generated&#160;via<br/>
mantic&#160;communities&#160;by&#160;using&#160;the&#160;CUT&#160;models.&#160;Consider<br/>
slice&#160;t&#160;evolve&#160;from&#160;the&#160;topics&#160;associated&#160;with&#160;slice&#160;t&#160;−&#160;1.<br/>
By&#160;chaining&#160;together&#160;topics&#160;and&#160;topic&#160;proportion&#160;distribu-<br/>
(b)&#160;Draw&#160;ci&#160;from&#160;π(ci−1)<br/>
approximate&#160;approach&#160;of&#160;Gibbs&#160;sampling&#160;will&#160;provide&#160;so-<br/>
its&#160;generative&#160;process&#160;for&#160;each&#160;document<br/>
•&#160;E.g.,&#160;images,&#160;social&#160;networks,&#160;music,&#160;purchase&#160;histories,&#160;computer<br/>
the&#160;topic&#160;route,&#160;v<br/>
d,&#160;a&#160;set&#160;of&#160;authors,&#160;a<br/>
tions,<br/>
alue&#160;we<br/>
x&#160;ha<br/>
=&#160;ve<br/>
1&#160;sequentially<br/>
if&#160;the&#160;wor&#160;tied<br/>
d&#160;is&#160;agcollection<br/>
enerated&#160;of<br/>
a&#160;topic<br/>
s&#160;a&#160;s&#160;mod-<br/>
pecial&#160;word&#160;(for&#160;that&#160;document)&#160;and<br/>
the&#160;conditional&#160;probability&#160;P&#160;(c,&#160;u,&#160;z|ω),&#160;where&#160;three&#160;vari-<br/>
d,&#160;is&#160;observed.&#160;To&#160;generate<br/>
For&#160;a&#160;K-component&#160;model&#160;with&#160;V&#160;terms,&#160;let&#160;β<br/>
lutions&#160;to&#160;such&#160;problems.&#160;A&#160;faster&#160;algorithm&#160;EnF-Gibbs<br/>
valuet,k&#160;denote<br/>
x&#160;=&#160;2&#160;if&#160;thels.<br/>
e&#160;The<br/>
word&#160;generati<br/>
is&#160;genveer&#160;process<br/>
ated&#160;fr&#160;for<br/>
om&#160;slice<br/>
a&#160;b&#160;t<br/>
a&#160;of<br/>
ck&#160;a<br/>
g&#160;sequential<br/>
round&#160;discorpus<br/>
tribution&#160;specific&#160;for&#160;the&#160;corpus.&#160;The<br/>
ables&#160;in&#160;the&#160;model,&#160;community,&#160;user4&#160;and&#160;topic,&#160;are&#160;asso-<br/>
each&#160;word,&#160;an&#160;author&#160;x&#160;is&#160;chosen&#160;uniformly&#160;from&#160;this&#160;set,&#160;then&#160;a&#160;topic<br/>
(c)&#160;If&#160;c<br/>
φ(zi),&#160;else&#160;draw&#160;w&#160;from&#160;φ(ci)<br/>
the&#160;V&#160;-vector&#160;of&#160;natural&#160;parameters<br/>
z&#160;is&#160;selected&#160;from&#160;a<br/>
for&#160;topic&#160;k&#160;in&#160;slice&#160;t.<br/>
i&#160;=&#160;1,&#160;then&#160;draw&#160;wi&#160;from&#160;sampling&#160;will&#160;also&#160;be&#160;introd<br/>
i&#160;uced.<br/>
variable&#160;x&#160;acts&#160;asisathus<br/>
sw&#160;as<br/>
itc&#160;follo<br/>
h:&#160;ws:<br/>
ciated&#160;by&#160;a&#160;word&#160;ω.&#160;The&#160;semantic&#160;meaning&#160;of&#160;P&#160;(c,&#160;u,&#160;z<br/>
if&#160;x&#160;=&#160;0,&#160;the&#160;previously&#160;described&#160;standard&#160;topic&#160;mechanism&#160;is&#160;used<br/>
|ω)<br/>
topic&#160;distribution&#160;θ<br/>
code,&#160;genetic&#160;data,&#160;click-through&#160;data;&#160;...<br/>
x&#160;that&#160;is&#160;specific&#160;to&#160;the&#160;author,<br/>
The<br/>
and&#160;usual&#160;representation<br/>
then&#160;a&#160;word&#160;wof&#160;a<br/>
is&#160;multinomial&#160;distrib<br/>
generated<br/>
ution<br/>
from&#160;a&#160;is&#160;by<br/>
is&#160;the&#160;probability&#160;that&#160;ω&#160;belongs&#160;to&#160;user&#160;u&#160;under&#160;topic&#160;z,<br/>
to&#160;generate&#160;the&#160;word,&#160;whereas&#160;if&#160;x&#160;=&#160;1&#160;or&#160;x&#160;=&#160;2,&#160;words&#160;are&#160;sampled&#160;from&#160;a&#160;document-specific<br/>
its&#160;mean&#160;parameterization.&#160;If&#160;we&#160;denote&#160;the&#160;mean&#160;param-<br/>
topic-specific&#160;multinomial&#160;distribution&#160;φ<br/>
of&#160;the<br/>
Figure&#160;se<br/>
<b>4.&#160;SEMANTIC&#160;COMMUNITY&#160;DISCOVERY:</b><br/>
z&#160;.&#160;However,&#160;as&#160;described&#160;previously,&#160;none&#160;multinomial&#160;Ψ<br/>
1(b)&#160;or&#160;a1.c<br/>
pro&#160;oDra<br/>
rp&#160;w<br/>
us&#160;topics<br/>
sp<br/>
vides&#160;ec&#160;β<br/>
in&#160;community&#160;c.&#160;By&#160;estimation&#160;of&#160;P&#160;(c,&#160;u,&#160;z|ω),&#160;we&#160;can&#160;la-<br/>
ific<br/>
an&#160;multinom<br/>
intuiti&#160;ia<br/>
v&#160;le&#160;Ω&#160;(with&#160;symmetric&#160;Diric<br/>
representation&#160;hlet<br/>
of&#160;prio<br/>
hors&#160;p<br/>
w&#160;arame<br/>
phr&#160;trized<br/>
asesbyare&#160;generated&#160;by&#160;the&#160;com-<br/>
eter&#160;of&#160;a&#160;V&#160;-dimensional&#160;multinomial&#160;by&#160;π,&#160;the&#160;ith&#160;com-<br/>
t&#160;|&#160;βt−1&#160;∼&#160;N&#160;(βt−1,&#160;σ2I&#160;).<br/>
models&#160;is&#160;suitable&#160;for&#160;modeling&#160;message&#160;data.<br/>
β1&#160;and&#160;β2)&#160;respectively.&#160;x&#160;is&#160;sampled&#160;from&#160;a&#160;document-specific<b>TH</b><br/>
mu&#160;<b>E&#160;ALG</b><br/>
ltinomial&#160;<b>O</b><br/>
λ,<b>RI</b><br/>
w&#160;<b>T</b><br/>
h&#160;<b>H</b><br/>
ich&#160;<b>MS</b><br/>
bel&#160;a&#160;community&#160;with&#160;semantic&#160;tags&#160;(topics)&#160;in&#160;addition&#160;to<br/>
in&#160;turn&#160;has<br/>
ponent&#160;of&#160;the&#160;<i>natural&#160;parameter&#160;</i>is&#160;given&#160;by&#160;the&#160;mapping<br/>
2.&#160;Draw&#160;αt&#160;|&#160;αt−1&#160;∼&#160;N&#160;(αt−1,&#160;δ2I).<br/>
posite&#160;model.&#160;The&#160;figure&#160;shows&#160;a&#160;three&#160;class&#160;HMM.&#160;Two&#160;classes&#160;are&#160;simple<br/>
the&#160;affiliated&#160;us<br/>
multinomial&#160;ers.&#160;The&#160;problem&#160;of&#160;semantic&#160;community<br/>
β<br/>
a&#160;symmetric&#160;Diric&#160;3.<br/>
hle&#160;F<br/>
t&#160;or<br/>
pr&#160;each<br/>
ior,&#160;document:<br/>
γ.&#160;One&#160;could&#160;also&#160;use&#160;a&#160;hierarc&#160;In<br/>
hic&#160;t<br/>
a&#160;h<br/>
l&#160;is<br/>
Basect<br/>
yes&#160;io<br/>
ia&#160;n<br/>
n&#160;,a&#160;w<br/>
p&#160;e<br/>
pr&#160;fi<br/>
o&#160;rs<br/>
ac&#160;th&#160;in<br/>
to&#160;tro<br/>
in&#160;d<br/>
tr&#160;u<br/>
o&#160;ce<br/>
du&#160;t<br/>
c&#160;h<br/>
e&#160;e&#160;Gibbs&#160;sampling<br/>
i&#160;=&#160;log(πi/πV&#160;).&#160;In&#160;typical&#160;language&#160;modeling&#160;applica-<br/>
An&#160;email&#160;message&#160;has&#160;one&#160;sender&#160;and&#160;in&#160;general&#160;more&#160;than&#160;one&#160;recipients.&#160;We&#160;could<br/>
discovery&#160;is&#160;thus&#160;reduced&#160;to&#160;the&#160;estimation&#160;of&#160;P&#160;(c,&#160;u,&#160;z|ω).<br/>
tions,&#160;Dirichlet&#160;distributions&#160;are&#160;used&#160;to&#160;model<br/>
ano&#160;uncertain<br/>
ther&#160;leve<br/>
distrib<br/>
ty<br/>
l&#160;of&#160;uncer<br/>
utions&#160;ov&#160;(a)<br/>
tain<br/>
er&#160;Dra<br/>
ty<br/>
w&#160;w<br/>
ab&#160;ηo&#160;∼<br/>
ut<br/>
ords.Nth(eαDirichlet&#160;priors&#160;(e.g&#160;a.,lgsoeri<br/>
e&#160;th<br/>
B&#160;m.<br/>
lei,&#160;T<br/>
Nh<br/>
gen<br/>
,&#160;a&#160;w<br/>
n&#160;e<br/>
d&#160;a<br/>
J&#160;d<br/>
o&#160;d<br/>
r&#160;res<br/>
dan&#160;s<br/>
,&#160;t<br/>
2h<br/>
0&#160;e0&#160;p<br/>
3&#160;ro<br/>
)&#160;blem<br/>
—we&#160;of&#160;semantic&#160;com-<br/>
The&#160;third&#160;is&#160;a&#160;topic&#160;model,&#160;containing&#160;three&#160;topics.&#160;Transitions<br/>
t,&#160;a2I&#160;)<br/>
treat&#160;both&#160;the&#160;sender&#160;and&#160;the&#160;recipients&#160;as&#160;“authors”&#160;of&#160;the&#160;message,&#160;and&#160;then&#160;employ&#160;the<br/>
about&#160;the&#160;distributions&#160;over&#160;words.&#160;However<br/>
h&#160;,<br/>
a&#160;the<br/>
ve&#160;Dirichlet<br/>
not&#160;investigated&#160;this&#160;option,&#160;primarily&#160;for&#160;computatio&#160;m<br/>
n&#160;u<br/>
al&#160;nrit<br/>
e&#160;y<br/>
as&#160;d<br/>
o&#160;i<br/>
nsco<br/>
s.&#160;v<br/>
I&#160;ery<br/>
n&#160;allby<br/>
oua<br/>
r&#160;da<br/>
e&#160;p<br/>
x&#160;t<br/>
p&#160;i<br/>
en<br/>
r&#160;g<br/>
imG<br/>
e&#160;i<br/>
nbb<br/>
ts,&#160;s&#160;s<br/>
w&#160;a<br/>
e&#160;mpling&#160;framework<br/>
(b)&#160;For&#160;each&#160;word:<br/>
AT&#160;model,&#160;but&#160;this&#160;does&#160;not&#160;distinguish&#160;the&#160;author<br/>
between&#160;classes&#160;are&#160;shown&#160;with&#160;arrows,&#160;annotated&#160;with&#160;transition&#160;probabilities.&#160;The&#160;top-<br/>
is&#160;not<br/>
and&#160;amenable<br/>
the&#160;re<br/>
to<br/>
cipie&#160;sequential<br/>
nts&#160;of<br/>
modeling.<br/>
the&#160;mes&#160;Instead,<br/>
se<br/>
sage,t&#160;α&#160;we<br/>
=&#160;0<br/>
whic&#160;chain<br/>
.<br/>
h1,&#160;β0&#160;=&#160;β2&#160;=&#160;0.01,&#160;β1&#160;=&#160;0.0001&#160;and&#160;γ&#160;=&#160;0.3—all&#160;wto<br/>
ea&#160;o<br/>
k&#160;u<br/>
s&#160;r<br/>
y&#160;mo<br/>
mm&#160;d<br/>
e&#160;el<br/>
tr&#160;s.<br/>
ic&#160;p&#160;Fi<br/>
rion<br/>
r&#160;a<br/>
s&#160;l<br/>
.&#160;ly,&#160;we&#160;combine&#160;two&#160;powerful&#160;ideas:<br/>
i.&#160;Draw&#160;Z&#160;∼&#160;Mult(π(η)).<br/>
(1)<br/>
/*&#160;Initialization&#160;*/<br/>
the&#160;natural&#160;parameters&#160;of&#160;each&#160;topic&#160;β<br/>
Gibbs&#160;sampling&#160;and&#160;entropy&#160;filtering&#160;to&#160;improve&#160;efficiency<br/>
t,k&#160;in&#160;a&#160;state&#160;space<br/>
is&#160;undesirable&#160;in&#160;many&#160;real-world&#160;situations.&#160;A&#160;manager&#160;may&#160;send&#160;email&#160;to&#160;a&#160;seicsThe<br/>
cretary<br/>
in&#160;conditio<br/>
and<br/>
the&#160;nal&#160;probability<br/>
semantic&#160;of&#160;a&#160;wo<br/>
class&#160;rd&#160;w&#160;giv<br/>
also&#160;en&#160;a<br/>
ha&#160;do<br/>
v&#160;c<br/>
e&#160;ument&#160;d&#160;can&#160;be&#160;written<br/>
probabilities,&#160;as:<br/>
used&#160;to&#160;choose&#160;a&#160;topic&#160;when&#160;(2)<br/>
the&#160;for&#160;each&#160;ema<br/>
HMM&#160;il&#160;d<br/>
model&#160;that&#160;evolves&#160;with&#160;Gaussian&#160;noise;&#160;the&#160;simplest&#160;ver-<br/>
ii.&#160;Draw&#160;Wt,d,n&#160;∼&#160;Mult(π(βt,z)).<br/>
and&#160;performance,&#160;yielding&#160;a&#160;new&#160;algorithm:&#160;EnF-Gibbs<br/>
vice&#160;versa,&#160;but&#160;the&#160;nature&#160;of&#160;the&#160;requests&#160;and&#160;language&#160;used&#160;may&#160;be&#160;quite&#160;different.&#160;Even<br/>
(3)<br/>
for&#160;each&#160;word&#160;ω<br/>
sion&#160;of&#160;such&#160;a&#160;model&#160;is<br/>
sampling.<br/>
i&#160;in&#160;d<br/>
transitions&#160;to&#160;the&#160;T<br/>
semantic&#160;class.&#160;Phrases&#160;are&#160;generated&#160;by&#160;following&#160;a&#160;path&#160;through&#160;the<br/>
more&#160;dramatically,&#160;consider&#160;the&#160;large&#160;quantity&#160;of&#160;junk&#160;email&#160;that&#160;we&#160;receive;&#160;modeling&#160;the<br/>
Note&#160;that&#160;π&#160;maps<br/>
!<br/>
the&#160;<a href="Blei_1s.html#1">multinomial&#160;natural&#160;parameters&#160;to&#160;the</a><br/>
(4)<br/>
assign&#160;ωi&#160;to&#160;random&#160;community,&#160;topic&#160;and&#160;user;<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic</a><br/>
<a href="Blei_1s.html#1">=</a><br/>
<a href="Blei_1s.html#1">Mo&#160;1&#160;)</a><br/>
<a href="Blei_1s.html#1">dels&#160;</a>(<br/>
+<br/>
=&#160;2<br/>
β<br/>
p(w|d)&#160;=&#160;p(x&#160;=&#160;0|d)<br/>
p(w|z&#160;=&#160;t)p(z&#160;<a href="Blei_1s.html#1">=&#160;t|d)&#160;+&#160;p(x</a><br/>
model,&#160;choosing&#160;a&#160;word&#160;from&#160;<a href="Blei_1s.html#1">the</a><br/>
<a href="Blei_1s.html#1"><b>4</b></a><br/>
<a href="Blei_1s.html#1">distrib<b>.1</b>|d&#160;</a><b>G</b><br/>
p!&#160;<b>i</b><br/>
<a href="Blei_1s.html#1">ution&#160;</a><b>b</b>w<b>bs</b><br/>
|d)&#160;<b>samp</b><br/>
p(&#160;<b>l</b>x<b>ing</b>|d)p!!(w)<br/>
(5)<br/>
/*&#160;user&#160;in&#160;the&#160;list&#160;observed&#160;from&#160;d&#160;*/<br/>
t,k&#160;|&#160;βt<br/>
associated&#160;with&#160;each&#160;syntactic&#160;class,&#160;and&#160;a<br/>
−1,k&#160;∼&#160;N&#160;(βt−1,k&#160;,&#160;σ2&#160;I&#160;)&#160;.<br/>
(1)<br/>
mean&#160;parameters,&#160;π(βk,t)w&#160;=<br/>
<a href="Blei_1s.html#1">exp(βk,t,w)</a><br/>
<a href="Blei_1s.html#1">.</a><br/>
<a href="Blei_1s.html#1">P</a><br/>
topics&#160;of&#160;these&#160;messages&#160;as&#160;undistinguished&#160;from&#160;the&#160;topics&#160;we&#160;write&#160;about&#160;as&#160;authors&#160;would<br/>
exp(β<br/>
w<br/>
k,t,w&#160;)<br/>
t=1<br/>
Gibbs&#160;sampling&#160;is&#160;an&#160;algorithm&#160;to&#160;approximate&#160;the&#160;joint<br/>
(6)<br/>
/*&#160;Markov&#160;chain&#160;convergence&#160;*/<br/>
be&#160;extremely&#160;confounding&#160;and&#160;undesirable&#160;since&#160;the&#160;Our<br/>
y<br/>
approach<br/>
do&#160;not&#160;is&#160;thus<br/>
reflect&#160;to&#160;model<br/>
our<br/>
sequences<br/>
expertise&#160;of<br/>
or&#160;compositional<br/>
roles<br/>
topic<br/>
.<br/>
follo<br/>
The<br/>
wed&#160;graphical<br/>
by&#160;a&#160;model<br/>
w<br/>
for<br/>
ord&#160;this&#160;generati<br/>
from&#160;ve&#160;process<br/>
the<br/>
is&#160;shown<br/>
distrib&#160;in<br/>
ution&#160;associated&#160;with&#160;that&#160;topic&#160;for&#160;the&#160;seman-<br/>
distribution&#160;of&#160;multiple&#160;variables&#160;by&#160;drawing&#160;a&#160;sequence<br/>
(7)<br/>
i&#160;←&#160;0;<br/>
random&#160;variables&#160;by&#160;chaining&#160;Gaussian&#160;distrib<br/>
whe&#160;utions<br/>
re&#160;p!(&#160;in<br/>
w|&#160;a<br/>
d)&#160;is&#160;Figure<br/>
the&#160;sp&#160;1.<br/>
ec&#160;When<br/>
ial&#160;w&#160;the<br/>
ord&#160;horizontal<br/>
distribu&#160;arro<br/>
tion&#160;ws<br/>
for&#160;are<br/>
do&#160;remo<br/>
cumveed,<br/>
nt&#160;break-<br/>
d,&#160;and&#160;p!!(w)&#160;is&#160;the&#160;background&#160;word<br/>
Alternatively&#160;we&#160;could&#160;still&#160;employ&#160;the&#160;AT&#160;model&#160;by&#160;ignoring&#160;the&#160;recipient&#160;inform<br/>
tic<br/>
ation<br/>
of&#160;samples.&#160;As&#160;a&#160;special&#160;case&#160;of&#160;the&#160;Metropolis-Hastings<br/>
(8)<br/>
I&#160;←&#160;desired&#160;number&#160;of&#160;iterations;<br/>
dynamic&#160;model&#160;and&#160;mapping&#160;the&#160;emitted&#160;values<br/>
distr&#160;to<br/>
ib&#160;the<br/>
utio<br/>
class.&#160;sim-<br/>
n&#160;for&#160;thing<br/>
e&#160;c&#160;the<br/>
orptime<br/>
us.<br/>
Sentences&#160;dynamics,<br/>
Note&#160;th<br/>
withatthew&#160;graphical<br/>
he<br/>
the&#160;n&#160;commodel<br/>
par<br/>
same&#160;ed&#160;reduces<br/>
to&#160;the&#160;to<br/>
s<br/>
syntax&#160;a<br/>
ta&#160;set<br/>
nd<br/>
b&#160;ard<br/>
ut&#160;topic<br/>
dif&#160;model&#160;th<br/>
ferent&#160;e&#160;SWB<br/>
cont&#160;mod<br/>
ent&#160;elwould&#160;be&#160;generated&#160;if&#160;the<br/>
algorithm&#160;[18],&#160;Gibbs&#160;sampling&#160;is&#160;a&#160;Markov&#160;chain&#160;Monte<br/>
(9)<br/>
while&#160;i&#160;&lt;&#160;I<br/>
of&#160;email&#160;and&#160;treating&#160;each&#160;email&#160;document&#160;as&#160;if&#160;it&#160;plex.<br/>
only&#160;This<br/>
has&#160;is&#160;an<br/>
one&#160;extension&#160;of<br/>
author.&#160;the<br/>
Hologistic<br/>
weve&#160;normal<br/>
c<br/>
r,&#160;an<br/>
inex&#160;distrib<br/>
pla<br/>
thisin&#160;u-<br/>
word&#160;of<br/>
s&#160;independent<br/>
in&#160;three&#160;diff&#160;topic<br/>
erentmodels.<br/>
ways,&#160;W<br/>
v&#160;ith<br/>
ia&#160;time<br/>
topic&#160;dynamics,<br/>
s,&#160;via&#160;a&#160;spthe<br/>
ec&#160;k<br/>
iath<br/>
l&#160;word&#160;distribution,&#160;or&#160;via&#160;a&#160;back-<br/>
topic&#160;distribution&#160;were&#160;different.&#160;The<br/>
Carlo&#160;algo<br/>
generati&#160;ri<br/>
v&#160;th<br/>
e&#160;m&#160;and&#160;usu<br/>
model&#160;ally<br/>
th&#160;app<br/>
us&#160;lies&#160;wh<br/>
acts&#160;en&#160;th<br/>
lik&#160;ee&#160;con<br/>
it&#160;diti<br/>
isonal<br/>
(10)<br/>
for&#160;each&#160;email&#160;d<br/>
playing&#160;a&#160;game<br/>
ground&#160;word&#160;distribution.&#160;Given&#160;the&#160;graphical&#160;model&#160;above,&#160;it&#160;is&#160;relatively&#160;straightforward&#160;to&#160;derive<br/>
case&#160;(which&#160;is&#160;similar&#160;to&#160;the&#160;LDA&#160;model)&#160;we&#160;are&#160;losing&#160;all&#160;information&#160;about&#160;the&#160;recipients,<br/>
probability&#160;distribution&#160;of&#160;each&#160;variable&#160;can&#160;be&#160;evaluated.<br/>
(11)<br/>
for&#160;each&#160;ωi&#160;∈&#160;d<br/>
of&#160;Gibbs&#160;sampling&#160;e<br/>
“Madlibs”:quation<br/>
the&#160;s&#160;that&#160;allow&#160;join<br/>
semantic&#160;t&#160;sampling&#160;of&#160;the<br/>
component&#160;z<br/>
and&#160;the&#160;connections&#160;between&#160;people&#160;implied&#160;by&#160;the&#160;sender-recipient&#160;relationships.<br/>
provides&#160;a&#160;list&#160;of&#160;topical&#160;words&#160;(shown&#160;in&#160;black)<br/>
Ri&#160;and&#160;x<br/>
ather&#160;th<br/>
i&#160;latent&#160;variables&#160;for&#160;each&#160;word<br/>
an&#160;explicitly&#160;parameterizing&#160;the&#160;distributions&#160;for<br/>
(12)<br/>
estimate&#160;P&#160;(ci,&#160;ui,&#160;zi|ωi),&#160;u&#160;∈&#160;αd;<br/>
token&#160;wi,&#160;for&#160;xi&#160;=&#160;0:<br/>
variables,&#160;Gibbs&#160;sampling&#160;integrates&#160;out&#160;the&#160;parameters<br/>
(13)<br/>
(p,&#160;q,&#160;r)&#160;←&#160;argmax(P&#160;(cp,&#160;uq,&#160;zr|ωi));<br/>
which&#160;are&#160;slotted&#160;into&#160;templates&#160;generated&#160;by&#160;the&#160;syntactic&#160;component&#160;(shown&#160;in&#160;gray).<br/>
and&#160;estimates&#160;the&#160;corresponding&#160;posterior&#160;probability.<br/>
(14)<br/>
/*assign&#160;community&#160;p,user&#160;q,&#160;topic&#160;r&#160;to&#160;ωi*/<br/>
252<br/>
Gibbs&#160;sampling&#160;was&#160;first&#160;introduced&#160;to&#160;estimate&#160;the&#160;Topic-<br/>
(15)<br/>
record&#160;assignment&#160;τ&#160;(cp,&#160;uq,&#160;zr,&#160;ωi);<br/>
N<br/>
CT&#160;D&#160;+&#160;α<br/>
W&#160;T<br/>
+<br/>
d0,<br/>
Word&#160;mo<br/>
td,<br/>
del&#160;in&#160;[7].&#160;In&#160;Gib<br/>
C&#160;b<br/>
w&#160;s<br/>
t,&#160;sampli<br/>
βn<br/>
0&#160;g,&#160;a&#160;Markov&#160;chain&#160;is<br/>
(16)<br/>
i&#160;+&#160;+;<br/>
p&#160;(x<br/>
−i&#160;+&#160;γ<br/>
−i<br/>
−i<br/>
<b>2.2&#160;</b>i&#160;=&#160;0,&#160;zi&#160;=&#160;t<br/>
<b>Infer</b><br/>
|w,&#160;x<br/>
<b>ence&#160;</b>−i,&#160;z−i,&#160;α,&#160;β0,&#160;γ&#160;)&#160;∝<br/>
×&#160;formed<br/>
&#34;<br/>
,&#160;the&#160;transitio<br/>
×&#160;n<br/>
&#34;&#160;between&#160;successive&#160;states&#160;of&#160;which<br/>
Nd,−i&#160;+&#160;3γ<br/>
+&#160;T&#160;α<br/>
+&#160;W&#160;β0<br/>
is&#160;sim<br/>
t!&#160;CT&#160;D<br/>
u<br/>
t!la<br/>
d,ted<br/>
−i<br/>
by&#160;repeated<br/>
w!&#160;CW&#160;T<br/>
ly&#160;d<br/>
w!&#160;ra<br/>
t,&#160;w<br/>
−iing&#160;a&#160;topic&#160;for&#160;each&#160;ob-<br/>
Figure&#160;6:&#160;Gibbs&#160;sampling&#160;for&#160;CUT&#160;models<br/>
served&#160;word&#160;from&#160;its&#160;conditional&#160;probability&#160;on&#160;all&#160;other<br/>
an<br/>
The&#160;d&#160;for&#160;x<br/>
EM&#160;algorithm&#160;can&#160;be&#160;applied&#160;to&#160;the&#160;graphical&#160;model&#160;shown&#160;in&#160;Figure&#160;1,&#160;treating&#160;the<br/>
i&#160;=&#160;1:<br/>
variables.&#160;In&#160;the&#160;Author-Topic&#160;model,&#160;the&#160;algorithm&#160;goes<br/>
4Note&#160;we&#160;denote&#160;user&#160;with&#160;u&#160;in&#160;our&#160;models&#160;instead&#160;of&#160;x&#160;as<br/>
over&#160;all&#160;documents&#160;word&#160;by&#160;word.&#160;For&#160;each&#160;word&#160;ωi,&#160;the<br/>
in&#160;previous&#160;work.<br/>
document&#160;distributions&#160;θ,&#160;the<br/>
N<br/>
topics&#160;and<br/>
CW&#160;D<br/>
classes&#160;+<br/>
φ&#160;β<br/>
,&#160;and&#160;the&#160;transition&#160;probabilities&#160;π&#160;as<br/>
1<br/>
p&#160;(x<br/>
d1,−i&#160;+&#160;γ<br/>
wd,−i<br/>
i&#160;=&#160;1&#160;|w,&#160;x−i,&#160;z−i,&#160;β1,&#160;γ&#160;)&#160;∝<br/>
×&#160;&#34;<br/>
parameters.&#160;However,&#160;EM<br/>
Nd,−<br/>
produces&#160;i&#160;+&#160;3γ<br/>
poor&#160;results<br/>
+&#160;W<br/>
with&#160;β<br/>
topic&#160;models,&#160;which&#160;have&#160;many&#160;pa-<br/>
w!&#160;CW&#160;D<br/>
w!d,−i<br/>
1<br/>
177<br/>
rameters&#160;and&#160;many&#160;local&#160;maxima.&#160;Consequently,&#160;recent&#160;work&#160;has&#160;focused&#160;on&#160;approximate<br/>inference&#160;algorithms&#160;[6,&#160;8].&#160;We&#160;will&#160;use&#160;Markov&#160;chain&#160;Monte&#160;Carlo&#160;(MCMC;&#160;see&#160;[9])&#160;to<br/>perform&#160;full&#160;Bayesian&#160;inference&#160;in&#160;this&#160;model,&#160;sampling&#160;from&#160;a&#160;posterior&#160;distribution&#160;over<br/>assignments&#160;of&#160;words&#160;to&#160;classes&#160;and&#160;topics.<br/>
We&#160;assume&#160;that&#160;the&#160;document-specific&#160;distributions&#160;over&#160;topics,&#160;θ,&#160;are&#160;drawn&#160;from&#160;a<br/>Dirichlet(α)&#160;distribution,&#160;the&#160;topic&#160;distributions&#160;φ(z)&#160;are&#160;drawn&#160;from&#160;a&#160;Dirichlet(β)&#160;dis-<br/>tribution,&#160;the&#160;rows&#160;of&#160;the&#160;transition&#160;matrix&#160;for&#160;the&#160;HMM&#160;are&#160;drawn&#160;from&#160;a&#160;Dirichlet(γ)<br/>distribution,&#160;the&#160;class&#160;distributions&#160;φ(c)&#160;are&#160;drawn&#160;from&#160;a&#160;Dirichlet(δ)&#160;distribution,&#160;and&#160;all<br/>Dirichlet&#160;distributions&#160;are&#160;symmetric.&#160;We&#160;use&#160;Gibbs&#160;sampling&#160;to&#160;draw&#160;iteratively&#160;a&#160;topic<br/>assignment&#160;zi&#160;and&#160;class&#160;assignment&#160;ci&#160;for&#160;each&#160;word&#160;wi&#160;in&#160;the&#160;corpus&#160;(see&#160;[8,&#160;9]).<br/>Given&#160;the&#160;words&#160;w,&#160;the&#160;class&#160;assignments&#160;c,&#160;the&#160;other&#160;topic&#160;assignments&#160;z−i,&#160;and&#160;the<br/>
hyperparameters,&#160;each&#160;zi&#160;is&#160;drawn&#160;from:<br/>
P&#160;(zi|z−i,&#160;c,&#160;w)&#160;∝<br/>
P&#160;(zi|z−i)<br/>
P&#160;(wi|z,&#160;c,&#160;w−i)<br/>
!&#160;n(di)&#160;+&#160;α<br/>
c<br/>
∝<br/>
zi<br/>
(z<br/>
i&#160;!=&#160;1<br/>
i&#160;)<br/>
(<br/>
+β<br/>
n(di)<br/>
wi<br/>
c<br/>
z<br/>
+&#160;α)<br/>
n<br/>
i&#160;=&#160;1<br/>
i<br/>
n(zi)+W&#160;β<br/>
<hr/>
<a name=32></a><img class="yflip" src="./Blei_1-32_1.png"/><br/>
<img class="yflip" src="./Blei_1-32_2.png"/><br/>
<img class="yflip" src="./Blei_1-32_3.png"/><br/>
<img class="yflip" src="./Blei_1-32_4.png"/><br/>
<img class="yflip" src="./Blei_1-32_5.png"/><br/>
<img class="yflip" src="./Blei_1-32_6.png"/><br/>
<img class="yflip" src="./Blei_1-32_7.png"/><br/>
<img class="yflip" src="./Blei_1-32_8.png"/><br/>
<img class="yflip" src="./Blei_1-32_9.png"/><br/>
<img class="yflip" src="./Blei_1-32_10.png"/><br/>
<img class="yflip" src="./Blei_1-32_11.png"/><br/>
<img class="yflip" src="./Blei_1-32_12.png"/><br/>
<img class="yflip" src="./Blei_1-32_13.png"/><br/>
constraints&#160;of&#160;word&#160;alignment,&#160;i.e.,&#160;words&#160;“close-in-source”&#160;are&#160;usually&#160;aligned&#160;to&#160;words&#160;“close-in-<br/>
target”,&#160;under&#160;document-specific&#160;topical&#160;assignment.&#160;To&#160;incorporate&#160;such&#160;constituents,&#160;we&#160;integrate<br/>
the&#160;strengths&#160;of&#160;both&#160;HMM&#160;and&#160;BiTAM,&#160;and&#160;propose&#160;a&#160;Hidden&#160;Markov&#160;Bilingual&#160;Topic-AdMixture<br/>
model,&#160;or&#160;HM-BiTAM,&#160;for&#160;word&#160;alignment&#160;to&#160;leverage&#160;both&#160;locality&#160;constraints&#160;and&#160;topical&#160;context<br/>
underlying&#160;parallel&#160;document-pairs.<br/>In&#160;the&#160;HM-BiTAM&#160;framework,&#160;one&#160;can&#160;estimate&#160;topic-specific&#160;word-to-word&#160;translation&#160;lexicons<br/>
(lexical&#160;mappings),&#160;as&#160;well&#160;as&#160;the&#160;monolingual&#160;topic-specific&#160;word-frequencies&#160;for&#160;both&#160;languages,<br/>
based&#160;on&#160;parallel&#160;document-pairs.&#160;The&#160;resulting&#160;model&#160;offers&#160;a&#160;principled&#160;way&#160;of&#160;inferring&#160;optimal<br/>
translation&#160;from&#160;a&#160;given&#160;source&#160;language&#160;in&#160;a&#160;context-dependent&#160;fashion.&#160;We&#160;report&#160;an&#160;extensive<br/>
empirical&#160;analysis&#160;of&#160;HM-BiTAM,&#160;in&#160;comparison&#160;with&#160;related&#160;methods.&#160;We&#160;show&#160;our&#160;model’s&#160;ef-<br/>
fectiveness&#160;on&#160;the&#160;word-alignment&#160;task;&#160;we&#160;also&#160;demonstrate&#160;two&#160;application&#160;aspects&#160;which&#160;were<br/>
untouched&#160;in&#160;[10]:&#160;the&#160;utility&#160;of&#160;HM-BiTAM&#160;for&#160;bilingual&#160;topic&#160;exploration,&#160;and&#160;its&#160;application&#160;for<br/>
improving&#160;translation&#160;qualities.<br/>
2&#160;Revisit&#160;HMM&#160;for&#160;SMT<br/>An&#160;SMT&#160;system&#160;can&#160;be&#160;formulated&#160;as&#160;a&#160;noisy-channel&#160;model&#160;[2]:<br/>
e∗&#160;=&#160;arg&#160;max&#160;P&#160;(e|f)&#160;=&#160;arg&#160;max&#160;P&#160;(f|e)P&#160;(e),<br/>
(1)<br/>
e<br/>
e<br/>
where&#160;a&#160;translation&#160;corresponds&#160;to&#160;searching&#160;for&#160;the&#160;target&#160;sentence&#160;e∗&#160;which&#160;explains&#160;the&#160;source<br/>
sentence&#160;f&#160;best.&#160;The&#160;key&#160;component&#160;is&#160;P&#160;(f|e),&#160;the&#160;translation&#160;model;&#160;P&#160;(e)&#160;is&#160;monolingual&#160;language<br/>
model.&#160;In&#160;this&#160;paper,&#160;we&#160;generalize&#160;P&#160;(f|e)&#160;with&#160;topic-admixture&#160;models.<br/>An&#160;HMM&#160;implements&#160;the&#160;“proximity-bias”&#160;assumption&#160;—&#160;that&#160;words&#160;“close-in-source”&#160;are&#160;aligned<br/>
LDA&#160;istomo<br/>
words<br/>
introduce&#160;thedula<br/>
“close-in-target”,<br/>
mapping&#160;j&#160;r,<br/>
which<br/>
→&#160;aj,<br/>
general,<br/>
is&#160;effective&#160;for&#160;improving&#160;w<br/>
which&#160;assigns&#160;a&#160;French&#160;word&#160;fuseful<br/>
ord&#160;alignment&#160;accuracies,&#160;especially<br/>
for&#160;linguistically&#160;close&#160;language-pairs&#160;[8].&#160;Following&#160;[8],&#160;to&#160;model&#160;word-to-word&#160;translation,&#160;we<br/>
McCallum,&#160;Wang,&#160;&amp;&#160;Corrada-Emmanuel<br/>
j&#160;in&#160;position&#160;j&#160;to&#160;an&#160;English&#160;word<br/>
ei&#160;in&#160;position&#160;i&#160;=&#160;aj&#160;denoted&#160;as&#160;ea&#160;.&#160;Each&#160;(ordered)&#160;French&#160;word&#160;f<br/>
j<br/>
j&#160;is&#160;an&#160;observation,&#160;and&#160;it&#160;is<br/>
generated&#160;by&#160;an&#160;HMM&#160;state&#160;defined&#160;as&#160;[ea&#160;,&#160;a<br/>
j<br/>
j&#160;],&#160;where&#160;the&#160;alignment&#160;indicator&#160;aj&#160;for&#160;position&#160;j&#160;is<br/>
considered&#160;to&#160;have&#160;a&#160;dependency&#160;on&#160;the&#160;previous&#160;alignment&#160;aj−1.&#160;Thus&#160;a&#160;first-order&#160;HMM&#160;for&#160;an<br/>
alignment&#160;between&#160;e&#160;≡&#160;e1:I&#160;and&#160;f&#160;≡&#160;f1:J&#160;is&#160;defined&#160;as:<br/>
<b>Latent Dirichlet&#160;Allocation</b><br/>
<b>Author&#160;Model</b><br/>
<b>Author-Topic Model</b><br/>
<b>Author-Recipient-Topic Model</b><br/>
!&#160;J<br/>
&#34;<br/>
(LDA)<br/>
(Multi-label Mixture Model)<br/>
(AT)<br/>
(ART)<br/>
<b>Dynamic&#160;Topic&#160;Models</b><br/>
p(f1:J&#160;|e1:I)&#160;=<br/>
p(fj|ea&#160;)p(aj|aj−1),<br/>
(2)<br/>
[Blei, Ng, Jordan, 2003]<br/>
[McCallum 1999]<br/>
[Rosen-Zvi, Griffiths, Steyvers, Smyth 2004]<br/>
[This paper]<br/>
j<br/>
a1:&#160;j=1<br/>
ways,&#160;and&#160;quantitative&#160;results&#160;that&#160;demonstrate&#160;greater<br/>
J<br/>
pre-<br/>
α<br/>
α<br/>
α<br/>
!<br/>
<b>a</b><br/>
<b>a</b><br/>
a<br/>
<b>r</b><br/>
d<br/>
dictivedaccuracy&#160;when&#160;compared&#160;withd&#160;staticd&#160;topic&#160;models.<br/>
topic&#160;zi&#160;and&#160;the&#160;author&#160;xi&#160;responsible&#160;for&#160;this&#160;word&#160;are<br/>
where&#160;p(aj|aj−1)&#160;is&#160;the&#160;state&#160;transition&#160;probability;&#160;J&#160;and&#160;I&#160;are&#160;sentence&#160;lengths&#160;of&#160;the&#160;French&#160;and<br/>
α<br/>
θ<br/>
assigned&#160;based&#160;on&#160;the&#160;posterior&#160;probability&#160;conditioned&#160;on<br/>
English&#160;sentences,&#160;respectively.&#160;The&#160;transition&#160;model&#160;enforces&#160;the&#160;proximity-bias.&#160;An&#160;additional<br/>
&#34;<br/>
z<br/>
<b>2.&#160;Dynamic</b><br/>
pseudo&#160;x<br/>
<b>Topic&#160;Models</b><br/>
θ<br/>
θ<br/>
θ<br/>
word&#160;”NULL”&#160;is&#160;used&#160;at&#160;the&#160;xbeginning&#160;of&#160;English&#160;sentences&#160;for&#160;HMM&#160;to&#160;start&#160;with.&#160;The<br/>
<i>C</i><br/>
all&#160;other&#160;variables:&#160;P&#160;(zi,&#160;xi|ωi,&#160;z−i,&#160;x−i,&#160;w−i,&#160;ad).&#160;zi&#160;and<br/>
(a)<br/>
!<br/>
(a)<br/>
(b)<br/>
(b)<br/>
&#34;<br/>
xi&#160;denote&#160;the&#160;topic&#160;and&#160;author&#160;assigned&#160;to&#160;ωi,&#160;while&#160;z<br/>
&#34;<br/>
1<br/>
'<br/>
HMM&#160;implemented&#160;in&#160;GIZA++&#160;[5]&#160;is&#160;used&#160;as&#160;our&#160;baseline,&#160;which&#160;includes&#160;refinements&#160;2<br/>
such&#160;as<br/>
#<br/>
−i<br/>
While&#160;traditional&#160;time&#160;series&#160;modeling&#160;has&#160;focused&#160;on&#160;con-<br/>
#<br/>
0.2<br/>
z<br/>
z<br/>
z<br/>
and&#160;x−i&#160;are&#160;all&#160;other&#160;assignments&#160;of&#160;topic&#160;and&#160;author&#160;ex-<br/>
!<br/>
&#34;<br/>
tinuous<br/>
special&#160;data,&#160;topic<br/>
treatment!ofmodels<br/>
a&#160;&#34;&#160;are<br/>
jump&#160;to&#160;designed<br/>
a<br/>
for<br/>
NULL&#160;w&#160;cate<br/>
ord.&#160;gorical<br/>
A&#160;graphical&#160;model&#160;representation&#160;for&#160;such&#160;an&#160;HMM<br/>
z<br/>
z<br/>
z<br/>
γ<br/>
ψ<br/>
cluding&#160;current&#160;instance.&#160;w<br/>
A<br/>
is&#160;data.&#160;Our&#160;approach<br/>
illustrated&#160;in<br/>
is&#160;to<br/>
Figure&#160;use<br/>
A,A<br/>
1&#160;state<br/>
(a).<br/>
space&#160;models&#160;on&#160;the&#160;nat-<br/>
−i&#160;represents&#160;other&#160;observed<br/>
0.5<br/>
0.4<br/>
0.1<br/>
w<br/>
w<br/>
w<br/>
network&#160;used&#160;&#160;for&#160;images&#160;words&#160;in&#160;the&#160;document&#160;set&#160;and&#160;a<br/>
ural&#160;parameter&#160;space&#160;of&#160;the&#160;underlying&#160;topic&#160;multinomials,<br/>
$<br/>
network<br/>
%image&#160;(&#160;kernel<br/>
<i>T</i><br/>
α<br/>
d&#160;is&#160;the&#160;observed&#160;author<br/>
<i>z</i>1<br/>
<i>z</i>2<br/>
<i>z</i>3<br/>
<i>z</i><br/>
$<br/>
&amp;<br/>
di<br/>
4<br/>
neural<br/>
images<br/>
support<br/>
set&#160;for&#160;this&#160;document.<br/>
$<br/>
#<br/>
w<br/>
$<br/>
#<br/>
$<br/>
#<br/>
w<br/>
as&#160;well<br/>
w&#160;as&#160;on&#160;the&#160;natural<br/>
$<br/>
#&#160;parameters&#160;for<br/>
w&#160;the&#160;logistic&#160;nor-<br/>
N<br/>
0.8<br/>
N<br/>
N<br/>
image&#160;obtained&#160;with&#160;kernel<br/>
A&#160;βk<br/>
A<br/>
A<br/>
0.7<br/>
T<br/>
A<br/>
T<br/>
T<br/>
networks<br/>
object<br/>
vector<br/>
A&#160;key&#160;issue&#160;in&#160;using&#160;Gibbs&#160;sampling&#160;for&#160;distribution<br/>
Nd<br/>
Nd<br/>
mal&#160;distrib<br/>
Nd&#160;utions&#160;used&#160;for&#160;modeling&#160;the&#160;document-specific<br/>
Nd<br/>
&#34;<br/>
K<br/>
output<br/>
objects<br/>
svm<br/>
β<br/>
φ<br/>
ω<br/>
output&#160;described&#160;with<br/>
appro<br/>
objects&#160;ximation&#160;is&#160;the&#160;evaluation&#160;of&#160;conditional&#160;posterior<br/>
topic&#160;proportions.<br/>
<i>z</i><br/>
...<br/>
&#34;<br/>
...<br/>
...<br/>
<i>x</i><br/>
0<br/>
<i>z</i><br/>
N<br/>
D<br/>
D<br/>
D<br/>
D<br/>
β<br/>
β<br/>
β<br/>
d<br/>
used<br/>
probability.&#160;In&#160;Author-Topic&#160;model,&#160;given&#160;T&#160;topics&#160;and&#160;V<br/>
I<br/>
<i>w</i><br/>
m,n<br/>
1<br/>
<i>w</i>2<br/>
<i>w</i>3<br/>
<i>w</i><br/>
in<br/>
K<br/>
<i>U</i><br/>
<i>D</i>neural&#160;network&#160;trained&#160;with&#160;svm&#160;images<br/>
First,&#160;we&#160;revie<br/>
Im,n<br/>
e&#160;w&#160;the&#160;underlying&#160;statistical&#160;assumptions&#160;of<br/>
4<br/>
m,i<br/>
em,i&#160;with<br/>
trained<br/>
words,&#160;P&#160;(zi,&#160;xi|ωi,&#160;z−i,&#160;x−i,&#160;w−i,&#160;ad)&#160;is&#160;estimated&#160;by:<br/>
a&#160;static&#160;topic&#160;model,&#160;such&#160;as&#160;latent&#160;Dirichlet<br/>
B&#160;=&#160;p(f&#160;|e)&#160;allocation<br/>
obtained<br/>
Figure<br/>
!<br/>
1.&#160;Graphical<br/>
<i>w</i><br/>
representation<br/>
for<br/>
of&#160;a&#160;dynamic&#160;topic<br/>
Bk&#160;model&#160;(for<br/>
Figure&#160;1:&#160;Three&#160;related&#160;models,&#160;and&#160;the&#160;ART&#160;model.&#160;In&#160;all&#160;models,&#160;each&#160;observed&#160;word,<br/>
K<br/>
α<br/>
θm<br/>
zm,n<br/>
on<br/>
!<br/>
<i>w</i><br/>
(LDA)&#160;(Blei&#160;et&#160;al.,&#160;2003).&#160;Let&#160;β<br/>
0.9<br/>
Figure&#160;5:&#160;Mode<br/>
described&#160;ling&#160;community&#160;with&#160;topics<br/>
1:K&#160;be&#160;K&#160;topics,&#160;each&#160;of<br/>
three&#160;time&#160;slices).&#160;Each<br/>
<i>N</i><br/>
topic’s&#160;natural&#160;parameters&#160;βt,k&#160;evolve<br/>
fm,1<br/>
fm,2<br/>
f<br/>
f<br/>
<i>T</i><br/>
<i>d</i><br/>
<i>N</i>...<br/>
which&#160;is&#160;a&#160;distribution&#160;ov<br/>
m,&#160;er<br/>
3<br/>
a&#160;fixedJ<br/>
fm,1<br/>
fm,2<br/>
f<br/>
f<br/>
m,v<br/>
n&#160;ocab<br/>
<i>s</i><br/>
m,3<br/>
J<br/>
1<br/>
ulary.<i>s</i>2In&#160;a&#160;static<br/>
...<br/>
<i>s</i>3<br/>
over<br/>
<i>s</i>4time,&#160;together&#160;with&#160;the<br/>
w,&#160;is&#160;generated&#160;from&#160;a&#160;multinomial&#160;word&#160;distribution,&#160;φ<br/>
<i>D</i><br/>
mean&#160;parameters<br/>
m,n<br/>
α<br/>
P&#160;(z<br/>
<i>T</i><br/>
<i>d</i><br/>
i&#160;=&#160;j,&#160;xi&#160;=&#160;k<br/>
<i>D</i><br/>
|ωi&#160;=&#160;m,&#160;z<br/>
t&#160;of&#160;the&#160;logistic<br/>
−i,&#160;x−i,&#160;w−i,&#160;ad)&#160;∝<br/>
(4)<br/>
z&#160;,&#160;specific&#160;to&#160;a&#160;particular<br/>
topic&#160;model,&#160;each&#160;document&#160;is&#160;assumed&#160;drawn&#160;from&#160;the<br/>
normal&#160;distribution&#160;for&#160;the&#160;topic&#160;proportions.<br/>
topic/author,&#160;z,&#160;however&#160;topics&#160;are&#160;selected&#160;differently&#160;in&#160;each&#160;of&#160;the&#160;models.<br/>
sider&#160;the&#160;conditional&#160;probability&#160;P&#160;(c,&#160;u,&#160;z<br/>
P&#160;(ωi&#160;=&#160;m|xi&#160;=&#160;k)P&#160;(xi&#160;=&#160;k|zi&#160;=&#160;j)&#160;∝<br/>
(5)<br/>
following&#160;generati<br/>
am,1<br/>
a&#160;v<br/>
m,&#160;e<br/>
2<br/>
process:<br/>
|ω),&#160;a&#160;word&#160;ω&#160;as-<br/>
am,3<br/>
aJ<br/>
am,1<br/>
am,2<br/>
a<br/>
a<br/>
m,n<br/>
m,3<br/>
Jm,n<br/>
Nm<br/>
Figure&#160;1:&#160;Graph<br/>
Figure&#160;ical<br/>
1:&#160;models<br/>
The&#160;for&#160;(a)&#160;the&#160;standa<br/>
composite&#160;rd&#160;LDA&#160;to<br/>
Nm&#160;pic<br/>
model.&#160;so<br/>
m&#160;ci<br/>
od<br/>
(a)&#160;aetles(letfht)ree<br/>
an&#160;v<br/>
d&#160;a<br/>
(&#160;ri<br/>
b&#160;a<br/>
)<br/>
Graphical&#160;bl<br/>
th&#160;es<br/>
e&#160;:<br/>
pr&#160;co<br/>
opmm<br/>
ose<br/>
model.udnsitpye,c<br/>
(b)&#160;u<br/>
ia&#160;s<br/>
l&#160;er&#160;and<br/>
Gene&#160;topic.&#160;O<br/>
rating&#160;ur<br/>
In&#160;LDA,&#160;the&#160;topic&#160;is&#160;sampled&#160;from&#160;a&#160;per-document&#160;topic&#160;distribution,<br/>
phrases.<br/>
CW&#160;T<br/>
θ,&#160;which<br/>
mj<br/>
+&#160;β<br/>
CAT<br/>
kj<br/>
+&#160;α<br/>
M<br/>
words&#160;topic&#160;model&#160;with&#160;a&#160;background&#160;distribution&#160;(SWB<br/>
M<br/>
)&#160;(&#160;in<br/>
r&#160;t<br/>
ig&#160;erp<br/>
ht).&#160;retation&#160;of&#160;the&#160;semantic&#160;meaning&#160;of&#160;P&#160;(c,&#160;u,&#160;z|ω)&#160;is<br/>
(6)<br/>
in&#160;turn&#160;is&#160;sampled&#160;from&#160;a&#160;Dirichlet&#160;over<br/>
1.&#160;Choose<br/>
topics.&#160;In&#160;topic<br/>
the&#160;proportions<br/>
Author&#160;θ&#160;from<br/>
Mo&#160;a<br/>
del,&#160;distrib<br/>
the&#160;ution<br/>
re&#160;is&#160;over<br/>
tion&#160;(Aitchison,&#160;1982)&#160;to&#160;time-series&#160;simplex&#160;data&#160;(West<br/>
Σm!&#160;CWT&#160;+&#160;V&#160;β&#160;Σj!&#160;CAT<br/>
the&#160;probability&#160;that&#160;word&#160;ω&#160;is&#160;generated&#160;by&#160;user&#160;u&#160;under<br/>
m!j<br/>
kj!&#160;+&#160;T&#160;α<br/>
the&#160;(K&#160;−&#160;1)-simplex,&#160;such&#160;as&#160;a&#160;Dirichlet.<br/>
and&#160;Harrison,&#160;1997).<br/>
one&#160;topic&#160;associated&#160;with&#160;each&#160;author&#160;(or&#160;category),&#160;and<br/>
Ti,i!<br/>
authors&#160;are<br/>
φ(z)sam<br/>
,&#160;pled<br/>
each&#160;class&#160;c&#160;!=&#160;1&#160;isTi,i!&#160;associated&#160;with&#160;a&#160;distribution&#160;over&#160;words&#160;φ(c),&#160;each&#160;document<br/>
topic&#160;z,&#160;in&#160;community&#160;c.<br/>
where&#160;m&#34;&#160;&#34;=&#160;m&#160;and&#160;j&#34;&#160;&#34;=&#160;j,&#160;α&#160;and&#160;β&#160;are&#160;prior&#160;parameters<br/>
2.&#160;For&#160;each&#160;word:<br/>
In&#160;LDA,&#160;the&#160;document-specific&#160;topic&#160;proportions&#160;θ&#160;are<br/>
uniformly.&#160;In&#160;the&#160;Author-Topic&#160;model,&#160;the&#160;topic<br/>
(a)&#160;is&#160;sam<br/>
HMM&#160;pled<br/>
for&#160;W&#160;from<br/>
ord<br/>
a&#160;p<br/>
Alignmenter-author<br/>
(b)&#160;HM-BiTAM<br/>
Unfortunately,&#160;this&#160;conditional&#160;probability&#160;cannot&#160;be&#160;com-<br/>
are&#160;generated&#160;by&#160;drawing&#160;a&#160;topic&#160;t&#160;from&#160;the&#160;document-topic&#160;distribution&#160;p(z<br/>
for&#160;word&#160;and&#160;topic&#160;Dirichlets,&#160;CW&#160;T<br/>
d&#160;has&#160;a&#160;distribution&#160;over&#160;topics&#160;θ(d),&#160;and<br/>
|θd)&#160;and&#160;then&#160;drawing<br/>
mj<br/>
represents&#160;the&#160;number<br/>
transitions&#160;between&#160;classes&#160;c<br/>
(a)&#160;Choose&#160;a&#160;topic&#160;assignment&#160;Z&#160;∼&#160;Mult(θ).<br/>
drawn&#160;from&#160;a&#160;Dirichlet&#160;distribution.&#160;In&#160;the&#160;dynamic&#160;topic<br/>
puted&#160;directly.&#160;To&#160;get&#160;P&#160;(c,&#160;u,&#160;z<br/>
i<br/>
multinomial&#160;distribution,<br/>
−1&#160;and&#160;ci&#160;follow&#160;a<br/>
Figure&#160;1:&#160;The&#160;graphical&#160;model<br/>
a&#160;wo<br/>
representations&#160;rd<br/>
of&#160;w<br/>
(a)&#160;from&#160;th<br/>
HMM,&#160;e<br/>
andtop<br/>
(b)ic-word<br/>
HM-BiT&#160;distr<br/>
AM,&#160;ibu<br/>
for&#160;tion&#160;p(<br/>
parallel&#160;w<br/>
|ω)&#160;,we&#160;have:<br/>
of&#160;times&#160;that&#160;word&#160;ωi&#160;=&#160;m&#160;is&#160;assigned&#160;to&#160;topic&#160;zi&#160;=&#160;j,<br/>
θ,&#160;and&#160;authors&#160;are&#160;sampled&#160;uniformly&#160;from&#160;the&#160;observed<br/>
|z&#160;=<br/>
corpora.&#160;t,&#160;φt).<br/>
Circles&#160;As&#160;shown&#160;in&#160;Griffiths&#160;and&#160;Steyvers<br/>
(b)&#160;Choose&#160;a&#160;word&#160;W&#160;∼&#160;Mult(β<br/>
model,&#160;we&#160;use&#160;a&#160;logistic&#160;normal&#160;with&#160;mean&#160;α&#160;to&#160;express<br/>
z&#160;).<br/>
represent&#160;random&#160;variables,&#160;hexagons<br/>
(20<br/>
denote&#160;04<br/>
distrib&#160;)&#160;the&#160;top<br/>
ution<br/>
parameters,&#160;ic<br/>
π(si−1)<br/>
and&#160;uncertainty<br/>
assignm<br/>
observ&#160;e<br/>
ed&#160;n<br/>
.vov<br/>
ts&#160;erz<br/>
A&#160;proportions.<br/>
fo<br/>
ariablesr&#160;ea<br/>
are&#160;ch&#160;The<br/>
wor<br/>
shaded.&#160;d&#160;sequential<br/>
to<br/>
document&#160;ke<br/>
is&#160;n&#160;in&#160;structure<br/>
the&#160;cor&#160;be<br/>
pu-<br/>
CAT<br/>
s<br/>
generated&#160;can&#160;b<br/>
viae&#160;effic<br/>
the&#160;iently&#160;sa<br/>
follo&#160;mpled<br/>
wingvia<br/>
procedure:<br/>
kj<br/>
represents&#160;the&#160;number&#160;of&#160;times&#160;that&#160;author&#160;xi&#160;=&#160;k&#160;is<br/>
list&#160;of&#160;the&#160;document’s&#160;authors.&#160;In&#160;the&#160;Author-Recipient-Topic&#160;model,&#160;there&#160;is<br/>
Gibbs&#160;sampling&#160;(tween<br/>
after&#160;models<br/>
margin&#160;is<br/>
a&#160;ag<br/>
liz&#160;ain<br/>
ing&#160;captured<br/>
over&#160;θ&#160;a&#160;with<br/>
nd&#160;φ&#160;a<br/>
).&#160;simple<br/>
Point&#160;dynamic<br/>
estimates&#160;for&#160;the&#160;θ&#160;and&#160;φ&#160;dis&#160;P<br/>
tr&#160;(c,<br/>
ibu&#160;u,<br/>
tio&#160;z<br/>
n&#160;,s&#160;ω)<br/>
assigned&#160;to&#160;topic&#160;j.<br/>
a&#160;separate&#160;topic-distribution&#160;for&#160;each<br/>
This&#160;process<br/>
author-rec<br/>
implicitly<br/>
ipient&#160;pair,&#160;assumes<br/>
and<br/>
that<br/>
the&#160;the<br/>
sele&#160;documents<br/>
ction&#160;of&#160;are<br/>
P&#160;(c,&#160;u,&#160;z|ω)&#160;=<br/>
(3)<br/>
can&#160;be&#160;comp<br/>
2uted&#160;model<br/>
conditioned&#160;on&#160;a&#160;particular&#160;sample,&#160;and&#160;predictive&#160;distributions&#160;can&#160;be&#160;Σ<br/>
The&#160;transformation&#160;from&#160;Eq.&#160;4&#160;to&#160;Eq.&#160;5&#160;drops&#160;the&#160;vari-<br/>
obtained&#160;by<br/>
drawn&#160;<i>exchangeably&#160;</i>from&#160;the&#160;same&#160;set&#160;of&#160;topics.&#160;For&#160;many<br/>
c,u,z&#160;P&#160;(c,&#160;u,&#160;z,&#160;ω)<br/>
ables,&#160;z<br/>
topic-distribution&#160;is&#160;determined&#160;from&#160;the&#160;observed&#160;author,&#160;and&#160;by&#160;uniformly&#160;sam<br/>
1.&#160;-Sample&#160;θ(d)&#160;from&#160;a&#160;Dirichlet(α)&#160;prior<br/>
−i,&#160;x−i,&#160;w−i,&#160;ad,&#160;because&#160;each&#160;instance&#160;of&#160;ωi&#160;is<br/>
averaging&#160;over&#160;multiple&#160;samples.<br/>
collections,&#160;however,&#160;the&#160;order&#160;of&#160;the&#160;documents&#160;reflects<br/>
αt&#160;|&#160;αt<br/>
•&#160;The&#160;posterior&#160;can&#160;be&#160;used&#160;in&#160;creative&#160;ways<br/>
−1&#160;∼&#160;N&#160;(αt−1&#160;,&#160;δ2&#160;I&#160;)&#160;.<br/>
(2)<br/>
Consider&#160;the&#160;denominator&#160;in&#160;Eq.&#160;3,&#160;summing&#160;over&#160;all&#160;c,<br/>
assumed&#160;independent&#160;of&#160;the&#160;other&#160;words&#160;in&#160;a&#160;message.<br/>
pling&#160;a&#160;recipient&#160;from&#160;the&#160;set&#160;of&#160;recipients&#160;an&#160;e<br/>
for&#160;volving<br/>
the&#160;set<br/>
doc&#160;of&#160;topics.<br/>
ument.&#160;In&#160;a&#160;dynamic&#160;topic&#160;model,&#160;we<br/>
We&#160;will<br/>
2.&#160;refe<br/>
F&#160;r&#160;to&#160;F<br/>
or&#160;th&#160;or<br/>
e&#160;simplicity<br/>
pr<br/>
eachopo<br/>
w&#160;sed,&#160;we<br/>
m<br/>
ord&#160;o&#160;do<br/>
d<br/>
w&#160;elnot<br/>
as&#160;model<br/>
the&#160;s&#160;the<br/>
pec&#160;dynamics<br/>
ial&#160;word&#160;of<br/>
s&#160;topic<br/>
u&#160;a<br/>
topic&#160;cor<br/>
nd<br/>
mo-z&#160;makes&#160;the&#160;computation&#160;impractical&#160;in&#160;terms&#160;of&#160;ef-<br/>
del&#160;with&#160;background&#160;distribution<br/>
i&#160;in&#160;document&#160;d<br/>
suppose&#160;that&#160;the&#160;data&#160;is&#160;divided&#160;by&#160;time&#160;slice,&#160;for&#160;example<br/>
(SWB)&#160;(Figure&#160;1(relation,<br/>
b)).<br/>
as<br/>
SWBwas<br/>
ha&#160;done<br/>
s&#160;a&#160;s&#160;for<br/>
im&#160;static<br/>
ilar&#160;gemodels<br/>
neral&#160;by<br/>
str&#160;Blei<br/>
uctu&#160;and<br/>
re&#160;Laf<br/>
fici<br/>
to&#160;thferty<br/>
ency.&#160;In&#160;addition,&#160;as&#160;shown&#160;in&#160;[7],&#160;the&#160;summing&#160;doesn’t<br/>
e&#160;LDA&#160;model&#160;(Figure&#160;1(a))&#160;but&#160;with<br/>
<b>4.2&#160;Semantic&#160;community&#160;discovery</b><br/>
by&#160;year.&#160;We&#160;model&#160;the&#160;documents&#160;of&#160;each&#160;slice&#160;with&#160;a&#160;K-<br/>
(2006).<br/>
factorize,&#160;which&#160;makes&#160;the&#160;manipulation&#160;of&#160;denominator<br/>
additional&#160;mach<br/>
(a)&#160;inery&#160;to<br/>
Dra&#160;h<br/>
wanzdile&#160;specia<br/>
from&#160;l&#160;w<br/>
θ(d)<br/>
ords&#160;and&#160;background&#160;words.&#160;In&#160;particular,&#160;associated&#160;with<br/>
By&#160;applying&#160;the&#160;Gibbs&#160;sampling,&#160;we&#160;can&#160;discover&#160;the&#160;se-<br/>
component&#160;topic&#160;model,&#160;where&#160;the&#160;topics&#160;associated&#160;with<br/>
difficult.&#160;In&#160;the&#160;following&#160;section,&#160;we&#160;will&#160;show&#160;how&#160;an<br/>
each&#160;word&#160;token&#160;is&#160;a&#160;latent&#160;random&#160;variable&#160;x,&#160;taking&#160;value&#160;x&#160;=&#160;0&#160;if&#160;the&#160;word&#160;w&#160;is&#160;generated&#160;via<br/>
mantic&#160;communities&#160;by&#160;using&#160;the&#160;CUT&#160;models.&#160;Consider<br/>
slice&#160;t&#160;evolve&#160;from&#160;the&#160;topics&#160;associated&#160;with&#160;slice&#160;t&#160;−&#160;1.<br/>
By&#160;chaining&#160;together&#160;topics&#160;and&#160;topic&#160;proportion&#160;distribu-<br/>
(b)&#160;Draw&#160;ci&#160;from&#160;π(ci−1)<br/>
approximate&#160;approach&#160;of&#160;Gibbs&#160;sampling&#160;will&#160;provide&#160;so-<br/>
its&#160;generative&#160;process&#160;for&#160;each&#160;document<br/>
•&#160;E.g.,&#160;IR,&#160;collaborative&#160;filtering,&#160;document&#160;similarity,<br/>
the&#160;topic&#160;route,&#160;v<br/>
d,&#160;a&#160;set&#160;of&#160;authors,&#160;a<br/>
tions,<br/>
alue&#160;we<br/>
x&#160;ha<br/>
=&#160;ve<br/>
1&#160;sequentially<br/>
if&#160;the&#160;wor&#160;tied<br/>
d&#160;is&#160;agcollection<br/>
enerated&#160;of<br/>
a&#160;topic<br/>
s&#160;a&#160;s&#160;mod-<br/>
pecial&#160;word&#160;(for&#160;that&#160;document)&#160;and<br/>
the&#160;conditional&#160;probability&#160;P&#160;(c,&#160;u,&#160;z|ω),&#160;where&#160;three&#160;vari-<br/>
d,&#160;is&#160;observed.&#160;To&#160;generate<br/>
For&#160;a&#160;K-component&#160;model&#160;with&#160;V&#160;terms,&#160;let&#160;β<br/>
lutions&#160;to&#160;such&#160;problems.&#160;A&#160;faster&#160;algorithm&#160;EnF-Gibbs<br/>
valuet,k&#160;denote<br/>
x&#160;=&#160;2&#160;if&#160;thels.<br/>
e&#160;The<br/>
word&#160;generati<br/>
is&#160;genveer&#160;process<br/>
ated&#160;fr&#160;for<br/>
om&#160;slice<br/>
a&#160;b&#160;t<br/>
a&#160;of<br/>
ck&#160;a<br/>
g&#160;sequential<br/>
round&#160;discorpus<br/>
tribution&#160;specific&#160;for&#160;the&#160;corpus.&#160;The<br/>
ables&#160;in&#160;the&#160;model,&#160;community,&#160;user4&#160;and&#160;topic,&#160;are&#160;asso-<br/>
each&#160;word,&#160;an&#160;author&#160;x&#160;is&#160;chosen&#160;uniformly&#160;from&#160;this&#160;set,&#160;then&#160;a&#160;topic<br/>
(c)&#160;If&#160;c<br/>
φ(zi),&#160;else&#160;draw&#160;w&#160;from&#160;φ(ci)<br/>
the&#160;V&#160;-vector&#160;of&#160;natural&#160;parameters<br/>
z&#160;is&#160;selected&#160;from&#160;a<br/>
for&#160;topic&#160;k&#160;in&#160;slice&#160;t.<br/>
i&#160;=&#160;1,&#160;then&#160;draw&#160;wi&#160;from&#160;sampling&#160;will&#160;also&#160;be&#160;introd<br/>
i&#160;uced.<br/>
variable&#160;x&#160;acts&#160;asisathus<br/>
sw&#160;as<br/>
itc&#160;follo<br/>
h:&#160;ws:<br/>
ciated&#160;by&#160;a&#160;word&#160;ω.&#160;The&#160;semantic&#160;meaning&#160;of&#160;P&#160;(c,&#160;u,&#160;z<br/>
if&#160;x&#160;=&#160;0,&#160;the&#160;previously&#160;described&#160;standard&#160;topic&#160;mechanism&#160;is&#160;used<br/>
|ω)<br/>
topic&#160;distribution&#160;θ<br/>
visualizing&#160;interdisciplinary&#160;documents<br/>
x&#160;that&#160;is&#160;specific&#160;to&#160;the&#160;author,<br/>
The<br/>
and&#160;usual&#160;representation<br/>
then&#160;a&#160;word&#160;wof&#160;a<br/>
is&#160;multinomial&#160;distrib<br/>
generated<br/>
ution<br/>
from&#160;a&#160;is&#160;by<br/>
is&#160;the&#160;probability&#160;that&#160;ω&#160;belongs&#160;to&#160;user&#160;u&#160;under&#160;topic&#160;z,<br/>
to&#160;generate&#160;the&#160;word,&#160;whereas&#160;if&#160;x&#160;=&#160;1&#160;or&#160;x&#160;=&#160;2,&#160;words&#160;are&#160;sampled&#160;from&#160;a&#160;document-specific<br/>
its&#160;mean&#160;parameterization.&#160;If&#160;we&#160;denote&#160;the&#160;mean&#160;param-<br/>
topic-specific&#160;multinomial&#160;distribution&#160;φ<br/>
of&#160;the<br/>
Figure&#160;se<br/>
<b>4.&#160;SEMANTIC&#160;COMMUNITY&#160;DISCOVERY:</b><br/>
z&#160;.&#160;However,&#160;as&#160;described&#160;previously,&#160;none&#160;multinomial&#160;Ψ<br/>
1(b)&#160;or&#160;a1.c<br/>
pro&#160;oDra<br/>
rp&#160;w<br/>
us&#160;topics<br/>
sp<br/>
vides&#160;ec&#160;β<br/>
in&#160;community&#160;c.&#160;By&#160;estimation&#160;of&#160;P&#160;(c,&#160;u,&#160;z|ω),&#160;we&#160;can&#160;la-<br/>
ific<br/>
an&#160;multinom<br/>
intuiti&#160;ia<br/>
v&#160;le&#160;Ω&#160;(with&#160;symmetric&#160;Diric<br/>
representation&#160;hlet<br/>
of&#160;prio<br/>
hors&#160;p<br/>
w&#160;arame<br/>
phr&#160;trized<br/>
asesbyare&#160;generated&#160;by&#160;the&#160;com-<br/>
eter&#160;of&#160;a&#160;V&#160;-dimensional&#160;multinomial&#160;by&#160;π,&#160;the&#160;ith&#160;com-<br/>
t&#160;|&#160;βt−1&#160;∼&#160;N&#160;(βt−1,&#160;σ2I&#160;).<br/>
models&#160;is&#160;suitable&#160;for&#160;modeling&#160;message&#160;data.<br/>
β1&#160;and&#160;β2)&#160;respectively.&#160;x&#160;is&#160;sampled&#160;from&#160;a&#160;document-specific<b>TH</b><br/>
mu&#160;<b>E&#160;ALG</b><br/>
ltinomial&#160;<b>O</b><br/>
λ,<b>RI</b><br/>
w&#160;<b>T</b><br/>
h&#160;<b>H</b><br/>
ich&#160;<b>MS</b><br/>
bel&#160;a&#160;community&#160;with&#160;semantic&#160;tags&#160;(topics)&#160;in&#160;addition&#160;to<br/>
in&#160;turn&#160;has<br/>
ponent&#160;of&#160;the&#160;<i>natural&#160;parameter&#160;</i>is&#160;given&#160;by&#160;the&#160;mapping<br/>
2.&#160;Draw&#160;αt&#160;|&#160;αt−1&#160;∼&#160;N&#160;(αt−1,&#160;δ2I).<br/>
posite&#160;model.&#160;The&#160;figure&#160;shows&#160;a&#160;three&#160;class&#160;HMM.&#160;Two&#160;classes&#160;are&#160;simple<br/>
the&#160;affiliated&#160;us<br/>
multinomial&#160;ers.&#160;The&#160;problem&#160;of&#160;semantic&#160;community<br/>
β<br/>
a&#160;symmetric&#160;Diric&#160;3.<br/>
hle&#160;F<br/>
t&#160;or<br/>
pr&#160;each<br/>
ior,&#160;document:<br/>
γ.&#160;One&#160;could&#160;also&#160;use&#160;a&#160;hierarc&#160;In<br/>
hic&#160;t<br/>
a&#160;h<br/>
l&#160;is<br/>
Basect<br/>
yes&#160;io<br/>
ia&#160;n<br/>
n&#160;,a&#160;w<br/>
p&#160;e<br/>
pr&#160;fi<br/>
o&#160;rs<br/>
ac&#160;th&#160;in<br/>
to&#160;tro<br/>
in&#160;d<br/>
tr&#160;u<br/>
o&#160;ce<br/>
du&#160;t<br/>
c&#160;h<br/>
e&#160;e&#160;Gibbs&#160;sampling<br/>
i&#160;=&#160;log(πi/πV&#160;).&#160;In&#160;typical&#160;language&#160;modeling&#160;applica-<br/>
An&#160;email&#160;message&#160;has&#160;one&#160;sender&#160;and&#160;in&#160;general&#160;more&#160;than&#160;one&#160;recipients.&#160;We&#160;could<br/>
discovery&#160;is&#160;thus&#160;reduced&#160;to&#160;the&#160;estimation&#160;of&#160;P&#160;(c,&#160;u,&#160;z|ω).<br/>
tions,&#160;Dirichlet&#160;distributions&#160;are&#160;used&#160;to&#160;model<br/>
ano&#160;uncertain<br/>
ther&#160;leve<br/>
distrib<br/>
ty<br/>
l&#160;of&#160;uncer<br/>
utions&#160;ov&#160;(a)<br/>
tain<br/>
er&#160;Dra<br/>
ty<br/>
w&#160;w<br/>
ab&#160;ηo&#160;∼<br/>
ut<br/>
ords.Nth(eαDirichlet&#160;priors&#160;(e.g&#160;a.,lgsoeri<br/>
e&#160;th<br/>
B&#160;m.<br/>
lei,&#160;T<br/>
Nh<br/>
gen<br/>
,&#160;a&#160;w<br/>
n&#160;e<br/>
d&#160;a<br/>
J&#160;d<br/>
o&#160;d<br/>
r&#160;res<br/>
dan&#160;s<br/>
,&#160;t<br/>
2h<br/>
0&#160;e0&#160;p<br/>
3&#160;ro<br/>
)&#160;blem<br/>
—we&#160;of&#160;semantic&#160;com-<br/>
The&#160;third&#160;is&#160;a&#160;topic&#160;model,&#160;containing&#160;three&#160;topics.&#160;Transitions<br/>
t,&#160;a2I&#160;)<br/>
treat&#160;both&#160;the&#160;sender&#160;and&#160;the&#160;recipients&#160;as&#160;“authors”&#160;of&#160;the&#160;message,&#160;and&#160;then&#160;employ&#160;the<br/>
about&#160;the&#160;distributions&#160;over&#160;words.&#160;However<br/>
h&#160;,<br/>
a&#160;the<br/>
ve&#160;Dirichlet<br/>
not&#160;investigated&#160;this&#160;option,&#160;primarily&#160;for&#160;computatio&#160;m<br/>
n&#160;u<br/>
al&#160;nrit<br/>
e&#160;y<br/>
as&#160;d<br/>
o&#160;i<br/>
nsco<br/>
s.&#160;v<br/>
I&#160;ery<br/>
n&#160;allby<br/>
oua<br/>
r&#160;da<br/>
e&#160;p<br/>
x&#160;t<br/>
p&#160;i<br/>
en<br/>
r&#160;g<br/>
imG<br/>
e&#160;i<br/>
nbb<br/>
ts,&#160;s&#160;s<br/>
w&#160;a<br/>
e&#160;mpling&#160;framework<br/>
(b)&#160;For&#160;each&#160;word:<br/>
AT&#160;model,&#160;but&#160;this&#160;does&#160;not&#160;distinguish&#160;the&#160;author<br/>
between&#160;classes&#160;are&#160;shown&#160;with&#160;arrows,&#160;annotated&#160;with&#160;transition&#160;probabilities.&#160;The&#160;top-<br/>
is&#160;not<br/>
and&#160;amenable<br/>
the&#160;re<br/>
to<br/>
cipie&#160;sequential<br/>
nts&#160;of<br/>
modeling.<br/>
the&#160;mes&#160;Instead,<br/>
se<br/>
sage,t&#160;α&#160;we<br/>
=&#160;0<br/>
whic&#160;chain<br/>
.<br/>
h1,&#160;β0&#160;=&#160;β2&#160;=&#160;0.01,&#160;β1&#160;=&#160;0.0001&#160;and&#160;γ&#160;=&#160;0.3—all&#160;wto<br/>
ea&#160;o<br/>
k&#160;u<br/>
s&#160;r<br/>
y&#160;mo<br/>
mm&#160;d<br/>
e&#160;el<br/>
tr&#160;s.<br/>
ic&#160;p&#160;Fi<br/>
rion<br/>
r&#160;a<br/>
s&#160;l<br/>
.&#160;ly,&#160;we&#160;combine&#160;two&#160;powerful&#160;ideas:<br/>
i.&#160;Draw&#160;Z&#160;∼&#160;Mult(π(η)).<br/>
(1)<br/>
/*&#160;Initialization&#160;*/<br/>
the&#160;natural&#160;parameters&#160;of&#160;each&#160;topic&#160;β<br/>
Gibbs&#160;sampling&#160;and&#160;entropy&#160;filtering&#160;to&#160;improve&#160;efficiency<br/>
t,k&#160;in&#160;a&#160;state&#160;space<br/>
is&#160;undesirable&#160;in&#160;many&#160;real-world&#160;situations.&#160;A&#160;manager&#160;may&#160;send&#160;email&#160;to&#160;a&#160;seicsThe<br/>
cretary<br/>
in&#160;conditio<br/>
and<br/>
the&#160;nal&#160;probability<br/>
semantic&#160;of&#160;a&#160;wo<br/>
class&#160;rd&#160;w&#160;giv<br/>
also&#160;en&#160;a<br/>
ha&#160;do<br/>
v&#160;c<br/>
e&#160;ument&#160;d&#160;can&#160;be&#160;written<br/>
probabilities,&#160;as:<br/>
used&#160;to&#160;choose&#160;a&#160;topic&#160;when&#160;(2)<br/>
the&#160;for&#160;each&#160;ema<br/>
HMM&#160;il&#160;d<br/>
model&#160;that&#160;evolves&#160;with&#160;Gaussian&#160;noise;&#160;the&#160;simplest&#160;ver-<br/>
ii.&#160;Draw&#160;Wt,d,n&#160;∼&#160;Mult(π(βt,z)).<br/>
and&#160;performance,&#160;yielding&#160;a&#160;new&#160;algorithm:&#160;EnF-Gibbs<br/>
vice&#160;versa,&#160;but&#160;the&#160;nature&#160;of&#160;the&#160;requests&#160;and&#160;language&#160;used&#160;may&#160;be&#160;quite&#160;different.&#160;Even<br/>
(3)<br/>
for&#160;each&#160;word&#160;ω<br/>
sion&#160;of&#160;such&#160;a&#160;model&#160;is<br/>
sampling.<br/>
i&#160;in&#160;d<br/>
transitions&#160;to&#160;the&#160;T<br/>
semantic&#160;class.&#160;Phrases&#160;are&#160;generated&#160;by&#160;following&#160;a&#160;path&#160;through&#160;the<br/>
more&#160;dramatically,&#160;consider&#160;the&#160;large&#160;quantity&#160;of&#160;junk&#160;email&#160;that&#160;we&#160;receive;&#160;modeling&#160;the<br/>
Note&#160;that&#160;π&#160;maps<br/>
!<br/>
the&#160;<a href="Blei_1s.html#1">multinomial&#160;natural&#160;parameters&#160;to&#160;the</a><br/>
(4)<br/>
assign&#160;ωi&#160;to&#160;random&#160;community,&#160;topic&#160;and&#160;user;<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic</a><br/>
<a href="Blei_1s.html#1">=</a><br/>
<a href="Blei_1s.html#1">Mo&#160;1&#160;)</a><br/>
<a href="Blei_1s.html#1">dels&#160;</a>(<br/>
+<br/>
=&#160;2<br/>
β<br/>
p(w|d)&#160;=&#160;p(x&#160;=&#160;0|d)<br/>
p(w|z&#160;=&#160;t)p(z&#160;<a href="Blei_1s.html#1">=&#160;t|d)&#160;+&#160;p(x</a><br/>
model,&#160;choosing&#160;a&#160;word&#160;from&#160;<a href="Blei_1s.html#1">the</a><br/>
<a href="Blei_1s.html#1"><b>4</b></a><br/>
<a href="Blei_1s.html#1">distrib<b>.1</b>|d&#160;</a><b>G</b><br/>
p!&#160;<b>i</b><br/>
<a href="Blei_1s.html#1">ution&#160;</a><b>b</b>w<b>bs</b><br/>
|d)&#160;<b>samp</b><br/>
p(&#160;<b>l</b>x<b>ing</b>|d)p!!(w)<br/>
(5)<br/>
/*&#160;user&#160;in&#160;the&#160;list&#160;observed&#160;from&#160;d&#160;*/<br/>
t,k&#160;|&#160;βt<br/>
associated&#160;with&#160;each&#160;syntactic&#160;class,&#160;and&#160;a<br/>
−1,k&#160;∼&#160;N&#160;(βt−1,k&#160;,&#160;σ2&#160;I&#160;)&#160;.<br/>
(1)<br/>
mean&#160;parameters,&#160;π(βk,t)w&#160;=<br/>
<a href="Blei_1s.html#1">exp(βk,t,w)</a><br/>
<a href="Blei_1s.html#1">.</a><br/>
<a href="Blei_1s.html#1">P</a><br/>
topics&#160;of&#160;these&#160;messages&#160;as&#160;undistinguished&#160;from&#160;the&#160;topics&#160;we&#160;write&#160;about&#160;as&#160;authors&#160;would<br/>
exp(β<br/>
w<br/>
k,t,w&#160;)<br/>
t=1<br/>
Gibbs&#160;sampling&#160;is&#160;an&#160;algorithm&#160;to&#160;approximate&#160;the&#160;joint<br/>
(6)<br/>
/*&#160;Markov&#160;chain&#160;convergence&#160;*/<br/>
be&#160;extremely&#160;confounding&#160;and&#160;undesirable&#160;since&#160;the&#160;Our<br/>
y<br/>
approach<br/>
do&#160;not&#160;is&#160;thus<br/>
reflect&#160;to&#160;model<br/>
our<br/>
sequences<br/>
expertise&#160;of<br/>
or&#160;compositional<br/>
roles<br/>
topic<br/>
.<br/>
follo<br/>
The<br/>
wed&#160;graphical<br/>
by&#160;a&#160;model<br/>
w<br/>
for<br/>
ord&#160;this&#160;generati<br/>
from&#160;ve&#160;process<br/>
the<br/>
is&#160;shown<br/>
distrib&#160;in<br/>
ution&#160;associated&#160;with&#160;that&#160;topic&#160;for&#160;the&#160;seman-<br/>
distribution&#160;of&#160;multiple&#160;variables&#160;by&#160;drawing&#160;a&#160;sequence<br/>
(7)<br/>
i&#160;←&#160;0;<br/>
random&#160;variables&#160;by&#160;chaining&#160;Gaussian&#160;distrib<br/>
whe&#160;utions<br/>
re&#160;p!(&#160;in<br/>
w|&#160;a<br/>
d)&#160;is&#160;Figure<br/>
the&#160;sp&#160;1.<br/>
ec&#160;When<br/>
ial&#160;w&#160;the<br/>
ord&#160;horizontal<br/>
distribu&#160;arro<br/>
tion&#160;ws<br/>
for&#160;are<br/>
do&#160;remo<br/>
cumveed,<br/>
nt&#160;break-<br/>
d,&#160;and&#160;p!!(w)&#160;is&#160;the&#160;background&#160;word<br/>
Alternatively&#160;we&#160;could&#160;still&#160;employ&#160;the&#160;AT&#160;model&#160;by&#160;ignoring&#160;the&#160;recipient&#160;inform<br/>
tic<br/>
ation<br/>
of&#160;samples.&#160;As&#160;a&#160;special&#160;case&#160;of&#160;the&#160;Metropolis-Hastings<br/>
(8)<br/>
I&#160;←&#160;desired&#160;number&#160;of&#160;iterations;<br/>
dynamic&#160;model&#160;and&#160;mapping&#160;the&#160;emitted&#160;values<br/>
distr&#160;to<br/>
ib&#160;the<br/>
utio<br/>
class.&#160;sim-<br/>
n&#160;for&#160;thing<br/>
e&#160;c&#160;the<br/>
orptime<br/>
us.<br/>
Sentences&#160;dynamics,<br/>
Note&#160;th<br/>
withatthew&#160;graphical<br/>
he<br/>
the&#160;n&#160;commodel<br/>
par<br/>
same&#160;ed&#160;reduces<br/>
to&#160;the&#160;to<br/>
s<br/>
syntax&#160;a<br/>
ta&#160;set<br/>
nd<br/>
b&#160;ard<br/>
ut&#160;topic<br/>
dif&#160;model&#160;th<br/>
ferent&#160;e&#160;SWB<br/>
cont&#160;mod<br/>
ent&#160;elwould&#160;be&#160;generated&#160;if&#160;the<br/>
algorithm&#160;[18],&#160;Gibbs&#160;sampling&#160;is&#160;a&#160;Markov&#160;chain&#160;Monte<br/>
(9)<br/>
while&#160;i&#160;&lt;&#160;I<br/>
of&#160;email&#160;and&#160;treating&#160;each&#160;email&#160;document&#160;as&#160;if&#160;it&#160;plex.<br/>
only&#160;This<br/>
has&#160;is&#160;an<br/>
one&#160;extension&#160;of<br/>
author.&#160;the<br/>
Hologistic<br/>
weve&#160;normal<br/>
c<br/>
r,&#160;an<br/>
inex&#160;distrib<br/>
pla<br/>
thisin&#160;u-<br/>
word&#160;of<br/>
s&#160;independent<br/>
in&#160;three&#160;diff&#160;topic<br/>
erentmodels.<br/>
ways,&#160;W<br/>
v&#160;ith<br/>
ia&#160;time<br/>
topic&#160;dynamics,<br/>
s,&#160;via&#160;a&#160;spthe<br/>
ec&#160;k<br/>
iath<br/>
l&#160;word&#160;distribution,&#160;or&#160;via&#160;a&#160;back-<br/>
topic&#160;distribution&#160;were&#160;different.&#160;The<br/>
Carlo&#160;algo<br/>
generati&#160;ri<br/>
v&#160;th<br/>
e&#160;m&#160;and&#160;usu<br/>
model&#160;ally<br/>
th&#160;app<br/>
us&#160;lies&#160;wh<br/>
acts&#160;en&#160;th<br/>
lik&#160;ee&#160;con<br/>
it&#160;diti<br/>
isonal<br/>
(10)<br/>
for&#160;each&#160;email&#160;d<br/>
playing&#160;a&#160;game<br/>
ground&#160;word&#160;distribution.&#160;Given&#160;the&#160;graphical&#160;model&#160;above,&#160;it&#160;is&#160;relatively&#160;straightforward&#160;to&#160;derive<br/>
case&#160;(which&#160;is&#160;similar&#160;to&#160;the&#160;LDA&#160;model)&#160;we&#160;are&#160;losing&#160;all&#160;information&#160;about&#160;the&#160;recipients,<br/>
probability&#160;distribution&#160;of&#160;each&#160;variable&#160;can&#160;be&#160;evaluated.<br/>
(11)<br/>
for&#160;each&#160;ωi&#160;∈&#160;d<br/>
of&#160;Gibbs&#160;sampling&#160;e<br/>
“Madlibs”:quation<br/>
the&#160;s&#160;that&#160;allow&#160;join<br/>
semantic&#160;t&#160;sampling&#160;of&#160;the<br/>
component&#160;z<br/>
and&#160;the&#160;connections&#160;between&#160;people&#160;implied&#160;by&#160;the&#160;sender-recipient&#160;relationships.<br/>
provides&#160;a&#160;list&#160;of&#160;topical&#160;words&#160;(shown&#160;in&#160;black)<br/>
Ri&#160;and&#160;x<br/>
ather&#160;th<br/>
i&#160;latent&#160;variables&#160;for&#160;each&#160;word<br/>
an&#160;explicitly&#160;parameterizing&#160;the&#160;distributions&#160;for<br/>
(12)<br/>
estimate&#160;P&#160;(ci,&#160;ui,&#160;zi|ωi),&#160;u&#160;∈&#160;αd;<br/>
token&#160;wi,&#160;for&#160;xi&#160;=&#160;0:<br/>
variables,&#160;Gibbs&#160;sampling&#160;integrates&#160;out&#160;the&#160;parameters<br/>
(13)<br/>
(p,&#160;q,&#160;r)&#160;←&#160;argmax(P&#160;(cp,&#160;uq,&#160;zr|ωi));<br/>
which&#160;are&#160;slotted&#160;into&#160;templates&#160;generated&#160;by&#160;the&#160;syntactic&#160;component&#160;(shown&#160;in&#160;gray).<br/>
and&#160;estimates&#160;the&#160;corresponding&#160;posterior&#160;probability.<br/>
(14)<br/>
/*assign&#160;community&#160;p,user&#160;q,&#160;topic&#160;r&#160;to&#160;ωi*/<br/>
252<br/>
Gibbs&#160;sampling&#160;was&#160;first&#160;introduced&#160;to&#160;estimate&#160;the&#160;Topic-<br/>
(15)<br/>
record&#160;assignment&#160;τ&#160;(cp,&#160;uq,&#160;zr,&#160;ωi);<br/>
N<br/>
CT&#160;D&#160;+&#160;α<br/>
W&#160;T<br/>
+<br/>
d0,<br/>
Word&#160;mo<br/>
td,<br/>
del&#160;in&#160;[7].&#160;In&#160;Gib<br/>
C&#160;b<br/>
w&#160;s<br/>
t,&#160;sampli<br/>
βn<br/>
0&#160;g,&#160;a&#160;Markov&#160;chain&#160;is<br/>
(16)<br/>
i&#160;+&#160;+;<br/>
p&#160;(x<br/>
−i&#160;+&#160;γ<br/>
−i<br/>
−i<br/>
<b>2.2&#160;</b>i&#160;=&#160;0,&#160;zi&#160;=&#160;t<br/>
<b>Infer</b><br/>
|w,&#160;x<br/>
<b>ence&#160;</b>−i,&#160;z−i,&#160;α,&#160;β0,&#160;γ&#160;)&#160;∝<br/>
×&#160;formed<br/>
&#34;<br/>
,&#160;the&#160;transitio<br/>
×&#160;n<br/>
&#34;&#160;between&#160;successive&#160;states&#160;of&#160;which<br/>
Nd,−i&#160;+&#160;3γ<br/>
+&#160;T&#160;α<br/>
+&#160;W&#160;β0<br/>
is&#160;sim<br/>
t!&#160;CT&#160;D<br/>
u<br/>
t!la<br/>
d,ted<br/>
−i<br/>
by&#160;repeated<br/>
w!&#160;CW&#160;T<br/>
ly&#160;d<br/>
w!&#160;ra<br/>
t,&#160;w<br/>
−iing&#160;a&#160;topic&#160;for&#160;each&#160;ob-<br/>
Figure&#160;6:&#160;Gibbs&#160;sampling&#160;for&#160;CUT&#160;models<br/>
served&#160;word&#160;from&#160;its&#160;conditional&#160;probability&#160;on&#160;all&#160;other<br/>
an<br/>
The&#160;d&#160;for&#160;x<br/>
EM&#160;algorithm&#160;can&#160;be&#160;applied&#160;to&#160;the&#160;graphical&#160;model&#160;shown&#160;in&#160;Figure&#160;1,&#160;treating&#160;the<br/>
i&#160;=&#160;1:<br/>
variables.&#160;In&#160;the&#160;Author-Topic&#160;model,&#160;the&#160;algorithm&#160;goes<br/>
4Note&#160;we&#160;denote&#160;user&#160;with&#160;u&#160;in&#160;our&#160;models&#160;instead&#160;of&#160;x&#160;as<br/>
over&#160;all&#160;documents&#160;word&#160;by&#160;word.&#160;For&#160;each&#160;word&#160;ωi,&#160;the<br/>
in&#160;previous&#160;work.<br/>
document&#160;distributions&#160;θ,&#160;the<br/>
N<br/>
topics&#160;and<br/>
CW&#160;D<br/>
classes&#160;+<br/>
φ&#160;β<br/>
,&#160;and&#160;the&#160;transition&#160;probabilities&#160;π&#160;as<br/>
1<br/>
p&#160;(x<br/>
d1,−i&#160;+&#160;γ<br/>
wd,−i<br/>
i&#160;=&#160;1&#160;|w,&#160;x−i,&#160;z−i,&#160;β1,&#160;γ&#160;)&#160;∝<br/>
×&#160;&#34;<br/>
parameters.&#160;However,&#160;EM<br/>
Nd,−<br/>
produces&#160;i&#160;+&#160;3γ<br/>
poor&#160;results<br/>
+&#160;W<br/>
with&#160;β<br/>
topic&#160;models,&#160;which&#160;have&#160;many&#160;pa-<br/>
w!&#160;CW&#160;D<br/>
w!d,−i<br/>
1<br/>
177<br/>
rameters&#160;and&#160;many&#160;local&#160;maxima.&#160;Consequently,&#160;recent&#160;work&#160;has&#160;focused&#160;on&#160;approximate<br/>inference&#160;algorithms&#160;[6,&#160;8].&#160;We&#160;will&#160;use&#160;Markov&#160;chain&#160;Monte&#160;Carlo&#160;(MCMC;&#160;see&#160;[9])&#160;to<br/>perform&#160;full&#160;Bayesian&#160;inference&#160;in&#160;this&#160;model,&#160;sampling&#160;from&#160;a&#160;posterior&#160;distribution&#160;over<br/>assignments&#160;of&#160;words&#160;to&#160;classes&#160;and&#160;topics.<br/>
We&#160;assume&#160;that&#160;the&#160;document-specific&#160;distributions&#160;over&#160;topics,&#160;θ,&#160;are&#160;drawn&#160;from&#160;a<br/>Dirichlet(α)&#160;distribution,&#160;the&#160;topic&#160;distributions&#160;φ(z)&#160;are&#160;drawn&#160;from&#160;a&#160;Dirichlet(β)&#160;dis-<br/>tribution,&#160;the&#160;rows&#160;of&#160;the&#160;transition&#160;matrix&#160;for&#160;the&#160;HMM&#160;are&#160;drawn&#160;from&#160;a&#160;Dirichlet(γ)<br/>distribution,&#160;the&#160;class&#160;distributions&#160;φ(c)&#160;are&#160;drawn&#160;from&#160;a&#160;Dirichlet(δ)&#160;distribution,&#160;and&#160;all<br/>Dirichlet&#160;distributions&#160;are&#160;symmetric.&#160;We&#160;use&#160;Gibbs&#160;sampling&#160;to&#160;draw&#160;iteratively&#160;a&#160;topic<br/>assignment&#160;zi&#160;and&#160;class&#160;assignment&#160;ci&#160;for&#160;each&#160;word&#160;wi&#160;in&#160;the&#160;corpus&#160;(see&#160;[8,&#160;9]).<br/>Given&#160;the&#160;words&#160;w,&#160;the&#160;class&#160;assignments&#160;c,&#160;the&#160;other&#160;topic&#160;assignments&#160;z−i,&#160;and&#160;the<br/>
hyperparameters,&#160;each&#160;zi&#160;is&#160;drawn&#160;from:<br/>
P&#160;(zi|z−i,&#160;c,&#160;w)&#160;∝<br/>
P&#160;(zi|z−i)<br/>
P&#160;(wi|z,&#160;c,&#160;w−i)<br/>
!&#160;n(di)&#160;+&#160;α<br/>
c<br/>
∝<br/>
zi<br/>
(z<br/>
i&#160;!=&#160;1<br/>
i&#160;)<br/>
(<br/>
+β<br/>
n(di)<br/>
wi<br/>
c<br/>
z<br/>
+&#160;α)<br/>
n<br/>
i&#160;=&#160;1<br/>
i<br/>
n(zi)+W&#160;β<br/>
<hr/>
<a name=33></a>Approximate&#160;posterior&#160;inference<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=34></a>Posterior&#160;distribution&#160;for&#160;LDA<br/>
•&#160;For&#160;now,&#160;assume&#160;the&#160;topics&#160;β1:K&#160;are&#160;fixed.<br/>
The&#160;per-document&#160;posterior&#160;is<br/>
Q<br/>
p(θ&#160;|&#160;α)<br/>
N<br/>
p(z<br/>
n=1<br/>
n&#160;|&#160;θ)p(wn&#160;|&#160;zn,&#160;β1:K&#160;)<br/>
R<br/>
Q<br/>
P<br/>
p(θ<br/>
N<br/>
K<br/>
p(z<br/>
θ<br/>
|&#160;α)&#160;n=1<br/>
z=1<br/>
n&#160;|&#160;θ)p(wn&#160;|&#160;zn,&#160;β1:K&#160;)<br/>
•&#160;This&#160;is&#160;intractable&#160;to&#160;compute<br/>
•&#160;It&#160;is&#160;a&#160;“multiple&#160;hypergeometric&#160;function”&#160;(see&#160;Dickey,&#160;1983)<br/>
•&#160;Can&#160;be&#160;seen&#160;as&#160;sum&#160;of&#160;NK&#160;(tractable)&#160;Dirichlet&#160;integral&#160;terms<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=35></a>Posterior&#160;distribution&#160;for&#160;LDA<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k<br/>
η<br/>
D<br/>
K<br/>
We&#160;appeal&#160;to&#160;approximate&#160;posterior&#160;inference&#160;of&#160;the&#160;posterior,<br/>
Q<br/>
p(θ&#160;|&#160;α)<br/>
N<br/>
p(z<br/>
n=1<br/>
n&#160;|&#160;θ)p(wn&#160;|&#160;zn,&#160;β1:K&#160;)<br/>
R<br/>
Q<br/>
P<br/>
p(θ<br/>
N<br/>
K<br/>
p(z<br/>
θ<br/>
|&#160;α)&#160;n=1<br/>
z=1<br/>
n&#160;|&#160;θ)p(wn&#160;|&#160;zn,&#160;β1:K&#160;)<br/>
•&#160;Gibbs&#160;sampling<br/>•&#160;Variational&#160;methods<br/>•&#160;Particle&#160;filtering<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=36></a>Gibbs&#160;sampling<br/>
•&#160;Define&#160;a&#160;Markov&#160;chain&#160;whose&#160;stationary&#160;distribution&#160;is&#160;the<br/>
posterior&#160;of&#160;interest<br/>
•&#160;Collect&#160;independent&#160;samples&#160;from&#160;that&#160;stationary&#160;distribution;<br/>
approximate&#160;the&#160;posterior&#160;with&#160;them<br/>
•&#160;In&#160;Gibbs&#160;sampling,&#160;the&#160;space&#160;of&#160;the&#160;MC&#160;is&#160;the&#160;space&#160;of&#160;possible<br/>
configurations&#160;of&#160;the&#160;hidden&#160;variables.<br/>
•&#160;The&#160;chain&#160;is&#160;run&#160;by&#160;iteratively&#160;sampling&#160;from&#160;the&#160;conditional<br/>
distribution&#160;of&#160;each&#160;hidden&#160;variable&#160;given&#160;observations&#160;and&#160;the<br/>current&#160;state&#160;of&#160;the&#160;other&#160;hidden&#160;variables<br/>
•&#160;Once&#160;a&#160;chain&#160;has&#160;“burned&#160;in,”&#160;collect&#160;samples&#160;at&#160;a&#160;lag&#160;to<br/>
approximate&#160;the&#160;posterior.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=37></a>Gibbs&#160;sampling&#160;for&#160;LDA<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k<br/>
η<br/>
D<br/>
K<br/>
Define&#160;n(z1:N&#160;)&#160;to&#160;be&#160;the&#160;counts&#160;vector.&#160;A&#160;simple&#160;Gibbs&#160;sampler&#160;is<br/>
θ&#160;|&#160;w1:N,&#160;z1:N&#160;∼&#160;Dir(α&#160;+&#160;n(z1:N))<br/>
zi&#160;|&#160;z−i&#160;,&#160;w1:N&#160;∼&#160;Mult(π(z−i&#160;,&#160;wi&#160;))<br/>
where<br/>
π(z−i,&#160;wi)&#160;∝&#160;(α&#160;+&#160;n(z1:N))p(wi&#160;|&#160;β1:K&#160;)<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=38></a>Gibbs&#160;sampling&#160;for&#160;LDA<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k<br/>
η<br/>
D<br/>
K<br/>
•&#160;The&#160;topic&#160;proportions&#160;θ&#160;can&#160;be&#160;integrated&#160;out.<br/>
•&#160;A&#160;collapsed&#160;Gibbs&#160;sampler&#160;draws&#160;fromQ<br/>
p(z<br/>
K<br/>
i&#160;|&#160;z−i&#160;,&#160;w1:N&#160;)&#160;∝&#160;p(wi&#160;|&#160;β1:K&#160;)<br/>
Γ(n<br/>
k=1<br/>
k&#160;(z−i&#160;)),<br/>
where&#160;nk&#160;(z−i&#160;)&#160;is&#160;the&#160;number&#160;of&#160;times&#160;we’ve&#160;seen&#160;topic&#160;k&#160;in&#160;the<br/>collection&#160;of&#160;topic&#160;assignments&#160;z−i&#160;.<br/>
•&#160;Integrating&#160;out&#160;variables&#160;leads&#160;to&#160;a&#160;faster&#160;mixing&#160;chain.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=39></a>Variational&#160;inference&#160;(in&#160;general)<br/>
•&#160;Variational&#160;methods&#160;are&#160;a&#160;deterministic&#160;alternative&#160;to&#160;MCMC.<br/>
•&#160;Let&#160;x1:N&#160;be&#160;observations&#160;and&#160;z1:M&#160;be&#160;latent&#160;variables<br/>
•&#160;Our&#160;goal&#160;is&#160;to&#160;compute&#160;the&#160;posterior&#160;distribution<br/>
p(z1:M&#160;,&#160;x1:N&#160;)<br/>
p(z1:M&#160;|&#160;x1:N)&#160;=&#160;R&#160;p(z1:M,x1:N)dz1:M<br/>
•&#160;For&#160;many&#160;interesting&#160;distributions,&#160;the&#160;marginal&#160;likelihood&#160;of&#160;the<br/>
observations&#160;is&#160;difficult&#160;to&#160;efficiently&#160;compute<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=40></a>Variational&#160;inference<br/>
•&#160;Use&#160;Jensen’s&#160;inequality&#160;to&#160;bound&#160;the&#160;log&#160;prob&#160;of&#160;the&#160;observations:<br/>
Z<br/>
log&#160;p(x1:N&#160;)&#160;=&#160;log<br/>
p(z1:M&#160;,&#160;x1:N&#160;)dz1:M<br/>
Z<br/>
qν(z1:M&#160;)<br/>
=<br/>
log<br/>
p(z1:M&#160;,&#160;x1:N&#160;)<br/>
dz1:M<br/>
qν(z1:M&#160;)<br/>
≥&#160;Eq&#160;[log&#160;p(z<br/>
[log&#160;q<br/>
ν<br/>
1:M&#160;,&#160;x1:N&#160;)]&#160;−&#160;Eqν<br/>
ν&#160;(z1:M&#160;)]<br/>
•&#160;We&#160;have&#160;introduced&#160;a&#160;distribution&#160;of&#160;the&#160;latent&#160;variables&#160;with&#160;free<br/>
variational&#160;parameters&#160;ν.<br/>
•&#160;We&#160;optimize&#160;those&#160;parameters&#160;to&#160;tighten&#160;this&#160;bound.<br/>
•&#160;This&#160;is&#160;the&#160;same&#160;as&#160;finding&#160;the&#160;member&#160;of&#160;the&#160;family&#160;qν&#160;that&#160;is<br/>
closest&#160;in&#160;KL&#160;divergence&#160;to&#160;p(z1:M&#160;|&#160;x1:N).<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=41></a>Mean-field&#160;variational&#160;inference<br/>
•&#160;Complexity&#160;of&#160;optimization&#160;is&#160;determined&#160;by&#160;the&#160;factorization&#160;of&#160;qν<br/>
•&#160;In&#160;mean&#160;field&#160;variational&#160;inference&#160;we&#160;choose&#160;qν&#160;to&#160;be&#160;fully&#160;factored<br/>
M<br/>
Y<br/>
qν(z1:M&#160;)&#160;=<br/>
qν&#160;(z<br/>
m<br/>
m).<br/>
m=1<br/>
•&#160;The&#160;latent&#160;variables&#160;are&#160;independent.<br/>
•&#160;Each&#160;is&#160;governed&#160;by&#160;its&#160;own&#160;variational&#160;parameter&#160;νm.<br/>
•&#160;In&#160;the&#160;true&#160;posterior&#160;they&#160;can&#160;exhibit&#160;dependence<br/>
(often,&#160;this&#160;is&#160;what&#160;makes&#160;exact&#160;inference&#160;difficult).<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=42></a>MFVI&#160;and&#160;conditional&#160;exponential&#160;families<br/>
•&#160;Suppose&#160;the&#160;distribution&#160;of&#160;each&#160;latent&#160;variable&#160;conditional&#160;on&#160;the<br/>
observations&#160;and&#160;other&#160;latent&#160;variables&#160;is&#160;in&#160;the&#160;exponential&#160;family:<br/>
p(zm&#160;|&#160;z−m,&#160;x)&#160;=&#160;hm(zm)&#160;exp{gm(z−m,&#160;x)T&#160;zm&#160;−&#160;am(gi&#160;(z−m,&#160;x))}<br/>
•&#160;Assume&#160;qν&#160;is&#160;fully&#160;factorized,&#160;and&#160;each&#160;factor&#160;is&#160;in&#160;the&#160;same<br/>
exponential&#160;family:<br/>
qν&#160;(z<br/>
m<br/>
m)&#160;=&#160;hm(zm)&#160;exp{νT<br/>
m&#160;zm&#160;−&#160;am(νm)}<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=43></a>MFVI&#160;and&#160;conditional&#160;exponential&#160;families<br/>
•&#160;Variational&#160;inference&#160;is&#160;the&#160;following&#160;coordinate&#160;ascent&#160;algorithm<br/>
νm&#160;=&#160;Eq&#160;[g<br/>
ν<br/>
m(Z−m,&#160;x)]<br/>
•&#160;Notice&#160;the&#160;relationship&#160;to&#160;Gibbs&#160;sampling.<br/>
•&#160;(You&#160;will&#160;hear&#160;much&#160;more&#160;about&#160;this&#160;from&#160;Minka&#160;and&#160;Winn.)<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=44></a>Variational&#160;inference<br/>
•&#160;Alternative&#160;to&#160;MCMC;&#160;replace&#160;sampling&#160;with&#160;optimization.<br/>
•&#160;Deterministic&#160;approximation&#160;to&#160;posterior&#160;distribution.<br/>
•&#160;Uses&#160;established&#160;optimization&#160;methods<br/>
(block&#160;coordinate&#160;ascent;&#160;Newton-Raphson;&#160;interior-point).<br/>
•&#160;Faster,&#160;more&#160;scalable&#160;than&#160;MCMC&#160;for&#160;large&#160;problems.<br/>
•&#160;Biased,&#160;whereas&#160;MCMC&#160;is&#160;not.<br/>
•&#160;Emerging&#160;as&#160;a&#160;useful&#160;framework&#160;for&#160;fully&#160;Bayesian&#160;and&#160;empirical<br/>
Bayesian&#160;inference&#160;problems.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=45></a>Variational&#160;Inference&#160;for&#160;LDA<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k<br/>
η<br/>
D<br/>
K<br/>
•&#160;The&#160;mean&#160;field&#160;variational&#160;distribution&#160;is<br/>
Q<br/>
q(θ,&#160;z<br/>
N<br/>
1:N&#160;|&#160;γ,&#160;φ1:N&#160;)&#160;=&#160;q(θ&#160;|&#160;γ)<br/>
q(z<br/>
n=1<br/>
n&#160;|&#160;φ)<br/>
•&#160;This&#160;is&#160;a&#160;family&#160;of&#160;distributions&#160;over&#160;the&#160;latent&#160;variables,&#160;where&#160;all<br/>
variables&#160;are&#160;independent&#160;and&#160;governed&#160;by&#160;their&#160;own&#160;parameters.<br/>
•&#160;In&#160;the&#160;true&#160;posterior,&#160;the&#160;latent&#160;variables&#160;are&#160;not&#160;independent.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=46></a>Variational&#160;Inference&#160;for&#160;LDA<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k<br/>
η<br/>
D<br/>
K<br/>
The&#160;variational&#160;paramters&#160;are:<br/>
γ<br/>
Dirichlet&#160;parameters<br/>
φ<br/>
Multinomial&#160;parameters&#160;for&#160;K-dim&#160;variables<br/>
1:N<br/>
There&#160;is&#160;a&#160;separate&#160;variational&#160;Dirichlet&#160;distribution&#160;for&#160;each&#160;document;<br/>there&#160;is&#160;a&#160;separate&#160;multinomial&#160;distribution&#160;for&#160;each&#160;word&#160;in&#160;each&#160;docu-<br/>ment.&#160;(Contrast&#160;this&#160;to&#160;the&#160;model.)<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=47></a>Variational&#160;Inference&#160;for&#160;LDA<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k<br/>
η<br/>
D<br/>
K<br/>
Coordinate&#160;ascent&#160;on&#160;the&#160;variational&#160;objective,<br/>
P<br/>
γ&#160;=&#160;α&#160;+<br/>
N<br/>
φ<br/>
n=1<br/>
n<br/>
φn&#160;∝&#160;exp{E[log&#160;θ]&#160;+&#160;log&#160;β.,w&#160;},<br/>
n<br/>
where<br/>
E<br/>
P<br/>
[log&#160;θi&#160;]&#160;=&#160;Ψ(γi&#160;)&#160;−&#160;Ψ(<br/>
γ<br/>
j<br/>
j&#160;).<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=48></a>Estimating&#160;the&#160;topics<br/>
Maximum&#160;likelihood:&#160;Expectation-Maximization<br/>
•&#160;E-step:&#160;Use&#160;variational&#160;or&#160;MCMC&#160;to&#160;approximate&#160;the&#160;per-document<br/>
posterior<br/>
•&#160;M-step:&#160;Find&#160;MLE&#160;of&#160;β1:K&#160;from&#160;expected&#160;counts<br/>
Bayesian&#160;topics<br/>
•&#160;Put&#160;a&#160;Dirichlet&#160;prior&#160;on&#160;the&#160;topics&#160;(usually&#160;exchangeable)<br/>
Note/Warning:&#160;This&#160;controls&#160;the&#160;sparsity&#160;of&#160;the&#160;topics<br/>
•&#160;Collapsed&#160;Gibbs&#160;sampling&#160;is&#160;still&#160;possible—we&#160;only&#160;need&#160;to&#160;keep<br/>
track&#160;of&#160;the&#160;topic&#160;assignments.<br/>
•&#160;Variational:&#160;Use&#160;a&#160;variational&#160;Dirichlet&#160;for&#160;each&#160;topic<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=49></a>Inference&#160;comparison<br/>
•&#160;Conventional&#160;wisdom&#160;says&#160;that:<br/>
•&#160;Gibbs&#160;is&#160;easiest&#160;to&#160;implement<br/>•&#160;Variational&#160;can&#160;be&#160;faster,&#160;especially&#160;when&#160;dealing&#160;with<br/>
nonconjugate&#160;priors&#160;(more&#160;on&#160;that&#160;later)<br/>
•&#160;There&#160;are&#160;other&#160;options:<br/>
•&#160;Collapsed&#160;variational&#160;inference<br/>•&#160;Parallelized&#160;inference&#160;for&#160;large&#160;corpora<br/>•&#160;Particle&#160;filters&#160;for&#160;on-line&#160;inference<br/>
•&#160;An&#160;ICML&#160;paper&#160;examining&#160;these&#160;issues&#160;is&#160;Asuncion&#160;et&#160;al.&#160;(2009).<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=50></a>Jonathan&#160;Chang’s&#160;R&#160;implementation<br/>
result&#160;&lt;-<br/>
lda.collapsed.gibbs.sampler(cora.documents,<br/>
K,<br/>
##&#160;Num&#160;clusters<br/>
cora.vocab,&#160;##&#160;vocabulary<br/>100,<br/>
##&#160;num&#160;iterations<br/>
0.1,&#160;##&#160;topic&#160;dirichlet<br/>0.1)&#160;##&#160;prop&#160;dirichlet<br/>
See&#160;http://www.pleasescoopme.com/<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=51></a>Jonathan&#160;Chang’s&#160;R&#160;implementation<br/>
1<br/>
2<br/>
3<br/>
4<br/>
5<br/>
research.reasoning.grant.science.supported<br/>
genetic.search.optimization.evolutionary.function<br/>
belief.model.theory.distribution.markov<br/>
models.networks.bayesian.data.hidden<br/>
learning.search.crossover.algorithm.complexity<br/>
design.logic.search.learning.systems<br/>
learning.networks.neural.system.reinforcement<br/>
<b>document</b><br/>
planning.visual.model.memory.system<br/>
1<br/>
network.time.networks.algorithm.data<br/>
2<br/>
decision.learning.tree.trees.classification<br/>
3<br/>
4<br/>
6<br/>
7<br/>
8<br/>
9<br/>
10<br/>
5<br/>
topic<br/>
research.reasoning.grant.science.supported<br/>
6<br/>
7<br/>
genetic.search.optimization.evolutionary.function<br/>
8<br/>
belief.model.theory.distribution.markov<br/>
9<br/>
models.networks.bayesian.data.hidden<br/>
10<br/>
learning.search.crossover.algorithm.complexity<br/>
design.logic.search.learning.systems<br/>
learning.networks.neural.system.reinforcement<br/>
planning.visual.model.memory.system<br/>
network.time.networks.algorithm.data<br/>
decision.learning.tree.trees.classification<br/>
0.0<br/>
0.2<br/>
0.4<br/>
0.6<br/>
0.8<br/>
1.0<br/>
0.0<br/>
0.2<br/>
0.4<br/>
0.6<br/>
0.8<br/>
1.0<br/>
0.0<br/>
0.2<br/>
0.4<br/>
0.6<br/>
0.8<br/>
1.0<br/>
0.0<br/>
0.2<br/>
0.4<br/>
0.6<br/>
0.8<br/>
1.0<br/>
0.0<br/>
0.2<br/>
0.4<br/>
0.6<br/>
0.8<br/>
1.0<br/>
proportion<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=52></a>Supervised&#160;and&#160;relational&#160;topic&#160;models<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=53></a>Supervised&#160;topic&#160;models<br/>
•&#160;But&#160;LDA&#160;is&#160;an&#160;unsupervised&#160;model.&#160;How&#160;can&#160;we&#160;build&#160;a&#160;topic&#160;model<br/>
that&#160;is&#160;good&#160;at&#160;the&#160;task&#160;we&#160;care&#160;about?<br/>
•&#160;Many&#160;data&#160;are&#160;paired&#160;with&#160;response&#160;variables.<br/>
•&#160;User&#160;reviews&#160;paired&#160;with&#160;a&#160;number&#160;of&#160;stars<br/>•&#160;Web&#160;pages&#160;paired&#160;with&#160;a&#160;number&#160;of&#160;“diggs”<br/>•&#160;Documents&#160;paired&#160;with&#160;links&#160;to&#160;other&#160;documents<br/>•&#160;Images&#160;paired&#160;with&#160;a&#160;category<br/>
•&#160;Supervised&#160;topic&#160;models&#160;are&#160;topic&#160;models&#160;of&#160;documents&#160;and<br/>
responses,&#160;fit&#160;to&#160;find&#160;topics&#160;predictive&#160;of&#160;the&#160;response.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=54></a>Supervised&#160;LDA<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k&#160;K<br/>
Y<br/>
2<br/>
d<br/>
D<br/>
η,&#160;σ<br/>
1&#160;Draw&#160;topic&#160;proportions&#160;θ&#160;|&#160;α&#160;∼&#160;Dir(α).<br/>
2&#160;For&#160;each&#160;word<br/>
•&#160;Draw&#160;topic&#160;assignment&#160;zn&#160;|&#160;θ&#160;∼&#160;Mult(θ).<br/>•&#160;Draw&#160;word&#160;wn&#160;|&#160;zn,&#160;β1:K&#160;∼&#160;Mult(βz&#160;).<br/>
n<br/>
<br/>
3&#160;Draw&#160;response&#160;variable&#160;y&#160;|&#160;z1:N&#160;,&#160;η,&#160;σ2&#160;∼&#160;N&#160;η&gt;¯<br/>
z,&#160;σ2&#160;,&#160;where<br/>
P<br/>
¯<br/>
z&#160;=&#160;(1/N)<br/>
N<br/>
z<br/>
n=1&#160;n.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=55></a>Supervised&#160;LDA<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k&#160;K<br/>
Y<br/>
2<br/>
d<br/>
D<br/>
η,&#160;σ<br/>
•&#160;The&#160;response&#160;variable&#160;y&#160;is&#160;drawn&#160;after&#160;the&#160;document&#160;because&#160;it<br/>
depends&#160;on&#160;z1:N&#160;,&#160;an&#160;assumption&#160;of&#160;partial&#160;exchangeability.<br/>
•&#160;Consequently,&#160;y&#160;is&#160;necessarily&#160;conditioned&#160;on&#160;the&#160;words.<br/>
•&#160;In&#160;a&#160;sense,&#160;this&#160;blends&#160;generative&#160;and&#160;discriminative&#160;modeling.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=56></a>Supervised&#160;LDA<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k&#160;K<br/>
Y<br/>
2<br/>
d<br/>
D<br/>
η,&#160;σ<br/>
•&#160;Given&#160;a&#160;set&#160;of&#160;document-response&#160;pairs,&#160;fit&#160;the&#160;model&#160;parameters&#160;by<br/>
maximum&#160;likelihood.<br/>
•&#160;Given&#160;a&#160;new&#160;document,&#160;compute&#160;a&#160;prediction&#160;of&#160;its&#160;response.<br/>
•&#160;Both&#160;of&#160;these&#160;activities&#160;hinge&#160;on&#160;variational&#160;inference.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=57></a>Variational&#160;inference&#160;in&#160;sLDA<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k&#160;K<br/>
Y<br/>
2<br/>
d<br/>
D<br/>
η,&#160;σ<br/>
•&#160;Our&#160;goal&#160;is&#160;to&#160;compute&#160;the&#160;posterior&#160;distribution<br/>
p(θ,&#160;z1:N&#160;,&#160;w1:N&#160;)<br/>
p(θ,&#160;z1:N&#160;|&#160;w1:N)&#160;=&#160;P<br/>
R<br/>
,<br/>
p(θ,&#160;z<br/>
z<br/>
1:N&#160;,&#160;w1:N&#160;)<br/>
1:N<br/>
θ<br/>
•&#160;We&#160;approximate&#160;by&#160;minimizing&#160;the&#160;KL&#160;divergence&#160;to&#160;a&#160;simpler<br/>
family&#160;of&#160;distributions,<br/>
q∗<br/>
K<br/>
ν&#160;=&#160;arg&#160;min<br/>
L(q||p)<br/>
q∈Q<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=58></a>Variational&#160;inference&#160;in&#160;sLDA<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k&#160;K<br/>
Y<br/>
2<br/>
d<br/>
D<br/>
η,&#160;σ<br/>
Equivalently,&#160;maximize&#160;the&#160;Jensen’s&#160;bound<br/>
log&#160;p(w1:N&#160;,&#160;y&#160;)&#160;≥<br/>
E<br/>
P<br/>
P<br/>
[log&#160;p(θ&#160;|&#160;α)]&#160;+<br/>
N<br/>
E[log&#160;p(Z<br/>
N<br/>
E[log&#160;p(w<br/>
n=1<br/>
n&#160;|&#160;θ)]&#160;+<br/>
n=1<br/>
n&#160;|&#160;Zn,&#160;β1:K&#160;)]<br/>
+E[log&#160;p(y&#160;|&#160;Z1:N,&#160;η,&#160;σ2)]&#160;+&#160;H(q)<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=59></a>Variational&#160;inference&#160;in&#160;sLDA<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k&#160;K<br/>
Y<br/>
2<br/>
d<br/>
D<br/>
η,&#160;σ<br/>
The&#160;distinguishing&#160;term&#160;is<br/>
&#160;<br/>
<br/>
<br/>
<br/>
y&#160;2<br/>
¯<br/>
Z&#160;+&#160;η&gt;E&#160;¯<br/>
Z&#160;¯<br/>
Z&#160;&gt;&#160;η<br/>
E<br/>
1<br/>
−&#160;2yη&gt;E<br/>
[log&#160;p(y&#160;|&#160;Z1:N)]&#160;=&#160;−&#160;log&#160;2πσ2&#160;−<br/>
2<br/>
2σ2<br/>
We&#160;use&#160;the&#160;fully-factorized&#160;variational&#160;distribution<br/>
Q<br/>
q(θ,&#160;z<br/>
N<br/>
1:N&#160;|&#160;γ,&#160;φ1:N&#160;)&#160;=&#160;q(θ&#160;|&#160;γ)<br/>
q(z<br/>
n=1<br/>
n&#160;|&#160;φn),<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=60></a>Variational&#160;inference&#160;in&#160;sLDA<br/>
α<br/>
θd<br/>
Zd,n<br/>
Wd,n<br/>
β<br/>
N<br/>
k&#160;K<br/>
Y<br/>
2<br/>
d<br/>
D<br/>
η,&#160;σ<br/>
•&#160;The&#160;expectations&#160;are<br/>
&#160;<br/>
N<br/>
X<br/>
E&#160;¯<br/>
1<br/>
Z<br/>
=<br/>
¯<br/>
φ&#160;:=<br/>
φn<br/>
N&#160;n=1<br/>
<br/>
<br/>
<br/>
<br/>
E&#160;¯<br/>
1<br/>
P<br/>
P<br/>
P<br/>
Z&#160;¯<br/>
Z&#160;&gt;<br/>
=<br/>
N<br/>
φ<br/>
N<br/>
nφ&gt;<br/>
diag{φn}&#160;.<br/>
N2<br/>
n=1<br/>
m6=n<br/>
m&#160;+<br/>
n=1<br/>
•&#160;Leads&#160;to&#160;an&#160;easy&#160;coordinate&#160;ascent&#160;algorithm.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=61></a>Maximum&#160;likelihood&#160;estimation<br/>
•&#160;The&#160;M-step&#160;is&#160;an&#160;MLE&#160;under&#160;expected&#160;sufficient&#160;statistics.<br/>
•&#160;Define<br/>
•&#160;y&#160;=&#160;y1:D&#160;is&#160;the&#160;response&#160;vector<br/>•&#160;A&#160;is&#160;the&#160;D&#160;×&#160;K&#160;matrix&#160;whose&#160;rows&#160;are&#160;¯<br/>
Z&#160;&gt;.<br/>
d<br/>
•&#160;MLE&#160;of&#160;the&#160;coefficients&#160;solve&#160;the&#160;expected&#160;normal&#160;equations<br/>
<br/>
<br/>
&#160;<br/>
−1<br/>
E&#160;A&gt;A&#160;η&#160;=&#160;E[A]&gt;y<br/>
⇒<br/>
ˆ<br/>
η<br/>
E<br/>
E<br/>
new&#160;←<br/>
A&gt;A<br/>
[A]&gt;y<br/>
•&#160;The&#160;MLE&#160;of&#160;the&#160;variance&#160;is<br/>
&#160;<br/>
−1<br/>
ˆ<br/>
σ2<br/>
E<br/>
E<br/>
new&#160;←&#160;(1/D&#160;){y&#160;&gt;y&#160;−&#160;y&#160;&gt;E[A]<br/>
A&gt;A<br/>
[A]&gt;y&#160;}<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=62></a>Prediction<br/>
•&#160;We&#160;have&#160;fit&#160;SLDA&#160;parameters&#160;to&#160;a&#160;corpus,&#160;using&#160;variational&#160;EM.<br/>
•&#160;We&#160;have&#160;a&#160;new&#160;document&#160;w1:N&#160;with&#160;unknown&#160;response&#160;value.<br/>
•&#160;First,&#160;run&#160;variational&#160;inference&#160;in&#160;the&#160;unsupervised&#160;LDA&#160;model,&#160;to<br/>
obtain&#160;γ&#160;and&#160;φ1:N&#160;for&#160;the&#160;new&#160;document.<br/>(LDA&#160;⇔&#160;integrating&#160;unobserved&#160;Y&#160;out&#160;of&#160;SLDA.)<br/>
•&#160;Predict&#160;y&#160;using&#160;SLDA&#160;expected&#160;value:<br/>
<br/>
<br/>
&#160;<br/>
E&#160;Y&#160;|&#160;w<br/>
¯<br/>
1:N&#160;,&#160;α,&#160;β1:K&#160;,&#160;η,&#160;σ2<br/>
≈&#160;η&gt;Eq&#160;Z&#160;=&#160;η&gt;&#160;¯<br/>
φ.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=63></a>Example:&#160;Movie&#160;reviews<br/>
least<br/>
bad<br/>
more<br/>
awful<br/>
his<br/>
both<br/>
problem<br/>
guys<br/>
has<br/>
featuring&#160;their<br/>
motion<br/>
unfortunately<br/>
watchable<br/>
than<br/>
routine<br/>
character<br/>
simple<br/>
supposed<br/>
its<br/>
films<br/>
dry<br/>
many<br/>
perfect<br/>
worse<br/>
not<br/>
director<br/>
offered<br/>
while<br/>
fascinating<br/>
flat<br/>
one<br/>
will<br/>
charlie<br/>
performance<br/>
power<br/>
dull<br/>
movie<br/>
characters&#160;paris<br/>
between<br/>
complex<br/>
●<br/>
●<br/>
●<br/>
●●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
−30<br/>
−20<br/>
−10<br/>
0<br/>
have<br/>
not<br/>
one<br/>
however<br/>
10<br/>
20<br/>
like<br/>
about<br/>
from<br/>
cinematography<br/>
you<br/>
movie&#160;there<br/>
screenplay<br/>
was<br/>
all<br/>
which<br/>
performances<br/>
just<br/>
would<br/>
who<br/>
pictures<br/>
some&#160;they<br/>
much<br/>
effective<br/>
out<br/>
its<br/>
what<br/>
picture<br/>
•&#160;10-topic&#160;sLDA&#160;model&#160;on&#160;movie&#160;reviews&#160;(Pang&#160;and&#160;Lee,&#160;2005).<br/>
•&#160;Response:&#160;number&#160;of&#160;stars&#160;associated&#160;with&#160;each&#160;review<br/>
•&#160;Each&#160;component&#160;of&#160;coefficient&#160;vector&#160;η&#160;is&#160;associated&#160;with&#160;a&#160;topic.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=64></a>Predictive&#160;R2<br/>
(SLDA&#160;is&#160;red.)<br/>
●<br/>
●<br/>
0.5<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
0.4<br/>
0.3<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
Predictive R2<br/>
0.2<br/>
●<br/>
●<br/>
0.1<br/>
0.0<br/>
5<br/>
10<br/>
15<br/>
20<br/>
25<br/>
30<br/>
35<br/>
40<br/>
45<br/>
50<br/>
Number of topics<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=65></a>Held&#160;out&#160;likelihood<br/>
(SLDA&#160;is&#160;red.)<br/>
●<br/>
−6.37<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
−6.38<br/>
●<br/>
●<br/>
●<br/>
●<br/>
−6.39<br/>
●<br/>
●<br/>
●<br/>
●<br/>
−6.40<br/>
●<br/>
Per−word held out log likelihood<br/>
●<br/>
−6.41<br/>
●<br/>
−6.42<br/>
5<br/>
10<br/>
15<br/>
20<br/>
25<br/>
30<br/>
35<br/>
40<br/>
45<br/>
50<br/>
Number of topics<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=66></a>Predictive&#160;R2&#160;on&#160;Digg<br/>
(SLDA&#160;is&#160;red.)<br/>
0.12<br/>
0.10<br/>
●<br/>
0.08<br/>
●<br/>
●&#160;●<br/>
0.06<br/>
Predictive R2<br/>
0.04<br/>
●<br/>
●<br/>
●<br/>
0.02<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
0.00<br/>
2<br/>
4<br/>
10<br/>
20<br/>
30<br/>
Number of topics<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=67></a>Held&#160;out&#160;likelihood&#160;on&#160;Digg<br/>
(SLDA&#160;is&#160;red.)<br/>
−8.0<br/>
−8.1<br/>
−8.2<br/>
●&#160;●<br/>
●&#160;●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
●<br/>
−8.3<br/>
●<br/>
●<br/>
−8.4<br/>
●<br/>●<br/>
−8.5<br/>
Per−word held out log likelihood<br/>
−8.6<br/>
2<br/>
4<br/>
10<br/>
20<br/>
30<br/>
Number of topics<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=68></a>Diverse&#160;response&#160;types&#160;with&#160;GLMs<br/>
•&#160;Want&#160;to&#160;work&#160;with&#160;response&#160;variables&#160;that&#160;don’t&#160;live&#160;in&#160;the&#160;reals.<br/>
•&#160;binary&#160;/&#160;multiclass&#160;classification<br/>•&#160;count&#160;data<br/>•&#160;waiting&#160;time<br/>
•&#160;Model&#160;the&#160;response&#160;response&#160;with&#160;a&#160;generalized&#160;linear&#160;model<br/>
<br/>
<br/>
ζy&#160;−&#160;A(ζ)<br/>
p(y&#160;|&#160;ζ,&#160;δ)&#160;=&#160;h(y,&#160;δ)&#160;exp<br/>
,<br/>
δ<br/>
where&#160;ζ&#160;=&#160;η&gt;¯<br/>
z.<br/>
•&#160;Complicates&#160;inference,&#160;but&#160;allows&#160;for&#160;flexible&#160;modeling.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=69></a><img src="./Blei_1-69_1.jpg"/><br/>
<img src="./Blei_1-69_2.jpg"/><br/>
<img src="./Blei_1-69_3.jpg"/><br/>
<img src="./Blei_1-69_4.jpg"/><br/>
<img src="./Blei_1-69_5.jpg"/><br/>
<img src="./Blei_1-69_6.jpg"/><br/>
<img src="./Blei_1-69_7.jpg"/><br/>
<img src="./Blei_1-69_8.jpg"/><br/>
<img src="./Blei_1-69_9.jpg"/><br/>
<img src="./Blei_1-69_10.jpg"/><br/>
<img src="./Blei_1-69_11.jpg"/><br/>
<img src="./Blei_1-69_12.jpg"/><br/>
<img src="./Blei_1-69_13.jpg"/><br/>
<img src="./Blei_1-69_14.jpg"/><br/>
<img src="./Blei_1-69_15.jpg"/><br/>
<img src="./Blei_1-69_16.jpg"/><br/>
<img src="./Blei_1-69_17.jpg"/><br/>
<img src="./Blei_1-69_18.jpg"/><br/>
<img src="./Blei_1-69_19.jpg"/><br/>
<img src="./Blei_1-69_20.jpg"/><br/>
<img src="./Blei_1-69_21.jpg"/><br/>
<img src="./Blei_1-69_22.jpg"/><br/>
<img src="./Blei_1-69_23.jpg"/><br/>
<img src="./Blei_1-69_24.jpg"/><br/>
<img src="./Blei_1-69_25.jpg"/><br/>
<img src="./Blei_1-69_26.jpg"/><br/>
<img src="./Blei_1-69_27.jpg"/><br/>
<img src="./Blei_1-69_28.jpg"/><br/>
<img src="./Blei_1-69_29.jpg"/><br/>
<img src="./Blei_1-69_30.jpg"/><br/>
<img src="./Blei_1-69_31.jpg"/><br/>
<img src="./Blei_1-69_32.jpg"/><br/>
<img src="./Blei_1-69_33.jpg"/><br/>
<img src="./Blei_1-69_34.jpg"/><br/>
<img src="./Blei_1-69_35.jpg"/><br/>
<img src="./Blei_1-69_36.jpg"/><br/>
<img src="./Blei_1-69_37.jpg"/><br/>
<img src="./Blei_1-69_38.jpg"/><br/>
<img src="./Blei_1-69_39.jpg"/><br/>
<img src="./Blei_1-69_40.jpg"/><br/>
<img src="./Blei_1-69_41.jpg"/><br/>
<img src="./Blei_1-69_42.jpg"/><br/>
<img src="./Blei_1-69_43.jpg"/><br/>
<img src="./Blei_1-69_44.jpg"/><br/>
<img src="./Blei_1-69_45.jpg"/><br/>
<img src="./Blei_1-69_46.jpg"/><br/>
<img src="./Blei_1-69_47.jpg"/><br/>
<img src="./Blei_1-69_48.jpg"/><br/>
<img src="./Blei_1-69_49.jpg"/><br/>
<img src="./Blei_1-69_50.jpg"/><br/>
<img src="./Blei_1-69_51.jpg"/><br/>
<img src="./Blei_1-69_52.jpg"/><br/>
<img src="./Blei_1-69_53.jpg"/><br/>
<img src="./Blei_1-69_54.jpg"/><br/>
<img src="./Blei_1-69_55.jpg"/><br/>
<img src="./Blei_1-69_56.jpg"/><br/>
<img src="./Blei_1-69_57.jpg"/><br/>
<img src="./Blei_1-69_58.jpg"/><br/>
<img src="./Blei_1-69_59.jpg"/><br/>
<img src="./Blei_1-69_60.jpg"/><br/>
<img src="./Blei_1-69_61.jpg"/><br/>
<img src="./Blei_1-69_62.jpg"/><br/>
<img src="./Blei_1-69_63.jpg"/><br/>
<img src="./Blei_1-69_64.jpg"/><br/>
CVPR<br/>
CVPR<br/>
#318<br/>
#318<br/>
<b>CVPR&#160;2009&#160;Submission&#160;#318.&#160;CONFIDENTIAL&#160;REVIEW&#160;COPY.&#160;DO&#160;NOT&#160;DISTRIBUTE.</b><br/>
CVPR<br/>
CVPR<br/>
<b>756</b><br/>
<b>Correct&#160;classification&#160;</b><br/>
<b>Incorrect&#160;classification&#160;(correct&#160;class)&#160;</b><br/>
<b>810</b><br/>
#318<br/>
<b>with predic</b>CVPR<br/>
#318<br/>
<b>ted annotations&#160;</b><br/>
<b>with predicted annotations&#160;</b><br/>
CVPR<br/>
<b>757</b><br/>
<b>811</b><br/>
<b>CVPR&#160;2009&#160;Submission&#160;#318.&#160;CONFIDENTIAL&#160;REVIEW&#160;COPY.&#160;DO&#160;NOT&#160;DISTRIBUTE.</b><br/>
#318<br/>
&#160;<br/>
#318<br/>
<b>758</b><br/>
<b>812</b><br/>
&#160;&#160;&#160;<br/>
<b>CVPR</b><br/>
&#160;<br/>
<b>2009&#160;Submission&#160;#318.</b><br/>
&#160;<br/>
<b>CONFIDENTIAL&#160;REVIEW&#160;COPY.&#160;DO&#160;NOT&#160;DISTRIBUTE.</b><br/>
<b>759</b><br/>
<b>813</b><br/>
<i>highway&#160;&#160;</i>&#160;<br/>
<i>coast&#160;(highway)&#160;</i><br/>
<b>760</b><br/>
&#160;<br/>
<i>&#160;</i><br/>
<b>814</b><br/>
Example:&#160;Multi-class<br/>
<b>756</b><br/>
<b>Correct&#160;classification&#160;</b><br/>
<b>Incorrect&#160;classification&#160;(correct&#160;class)&#160;</b><br/>
<b>810</b><br/>
CVPR<br/>
<b>761</b><br/>
classification<br/>
car, sign, road&#160;<br/>
car, sand beach, tree&#160;<br/>
CVPR<br/>
<b>757</b><br/>
<b>with predicted annotations&#160;</b><br/>
<b>with predicted annotations&#160;</b><br/>
<b>756</b><br/>
<b>815</b><br/>
<b>811</b><br/>
<b>Correct&#160;classification&#160;</b><br/>
<b>Incorrect&#160;classification&#160;(correct&#160;class)&#160;</b><br/>
<b>810</b><br/>
CVPR<br/>
#318<br/>
<b>762</b><br/>
&#160;<br/>
CVPR&#160;<br/>
&#160;<br/>
#318<br/>
<b>758</b><br/>
<b>757</b><br/>
<b>816</b><br/>
<b>with predicted annotations&#160;</b><br/>
<b>with predicted annotations&#160;</b><br/>
<b>812</b><br/>
<b>811</b><br/>
#318<br/>
<b>763</b><br/>
<b>CVPR&#160;2009&#160;Submission&#160;#318.&#160;CONFIDENTIAL&#160;REVIEW&#160;COPY</b><br/>
&#160;&#160;&#160;&#160;<b>.&#160;DO&#160;NOT&#160;DISTRIBUTE.&#160;</b>&#160;<br/>
&#160;<br/>
<b>759</b><br/>
#318<br/>
<b>758</b><br/>
&#160;<br/>
<b>817</b><br/>
<b>813</b><br/>
&#160;&#160;&#160;<br/>
&#160;<br/>
<i>highway&#160;&#160;</i>&#160;<br/>
&#160;<br/>
<i>coast&#160;(highway)&#160;</i><br/>
<b>812</b><br/>
<b>CVPR&#160;2009&#160;Submission&#160;#318.&#160;CONFIDENTIAL&#160;REVIEW&#160;COPY.&#160;DO&#160;NOT&#160;DISTRIBUTE.</b><br/>
&#160;&#160;&#160;<br/>
&#160;<br/>
&#160;<br/>
<b>764</b><br/>
<b>760</b><br/>
<i>insi&#160;</i><b>759</b><br/>
<b>818</b><br/>
<i>de&#160;city&#160;&#160;</i>&#160;<br/>
&#160;<br/>
<i>street&#160;(inside&#160;city)&#160;</i><br/>
<i>&#160;</i><br/>
<b>814</b><br/>
<b>813</b><br/>
<i>highway&#160;&#160;</i>&#160;<br/>
<i>coast&#160;(highway)&#160;</i><br/>
<b>765</b><br/>
<b>819</b><br/>
<b>756</b><br/>
<b>761</b><br/>
<b>760&#160;</b>&#160;<br/>
car, sign, road&#160;<br/>
&#160;<br/>
car, sand beach, tree&#160;<br/>
<b>815</b><br/>
&#160;<br/>
<i>&#160;</i><br/>
<b>814</b><br/>
<b>Correct&#160;classification&#160;</b><br/>
<b>Incorrect&#160;classification&#160;(correct&#160;class)&#160;</b><br/>
<b>810</b><br/>
<b>766</b><br/>
buildings, car, sidewalk&#160;<br/>
&#160;<br/>
window, tree, building&#160;<br/>
&#160;<br/>
<b>820</b><br/>
<b>540</b><br/>
<b>757</b><br/>
<b>with predicted anno</b><br/>
<b>762</b><br/>
<b>761&#160;tations&#160;</b><br/>
car, sig&#160;<b>wit</b><br/>
n, r&#160;<b>h pr</b><br/>
oad&#160;&#160;<b>edicted anno</b><br/>
<b>594tations&#160;</b><br/>
car&#160;<b>811</b><br/>
, sand beach, tree&#160;<br/>
<b>816</b><br/>
<b>815</b><br/>
<b>767</b><br/>
<b>821</b><br/>
<b>541</b><br/>
<b>758</b><br/>
image classification on the LabelMe dataset<br/>
<b>763</b><br/>
<b>762</b><br/>
image classification on the UIUC!Sport dataset<br/>
&#160;<br/>
&#160;<br/>
occluded&#160;<br/>
&#160;<br/>
<b>595</b><br/>
<b>812</b><br/>
<b>817</b><br/>
<b>816</b><br/>
0.78<br/>
<b>768</b><br/>
&#160;<br/>
&#160;&#160;&#160;<br/>
&#160;<br/>
&#160;&#160;&#160;<br/>
&#160;<br/>
&#160;<br/>
&#160;<br/>
<b>822</b><br/>
<b>542</b><br/>
<b>759</b><br/>
<b>764</b><br/>
<b>763</b><br/>
0.66<br/>
<b>596</b><br/>
<b>813</b><br/>
<b>818</b><br/>
<b>817</b><br/>
<b>769</b><br/>
<i>highway&#160;&#160;</i>&#160;<br/>
&#160;<br/>
<i>inside&#160;city&#160;&#160;</i>&#160;<br/>
<i>c</i>&#160;<i>oast&#160;(highway)&#160;</i><br/>
<i>street&#160;(ins</i><br/>
<b>823&#160;</b><i>ide&#160;city)&#160;</i><br/>
&#160;&#160;&#160;<br/>
&#160;<br/>
&#160;<br/>
<b>543</b><br/>
0.76<br/>
<b>760</b><br/>
<b>765</b><br/>
<b>764</b><br/>
<b>819</b><br/>
<i>tall&#160;buildi&#160;</i>&#160;<br/>
<i>ng</i><br/>
&#160;<br/>
<i>&#160;i</i><br/>
<b>597</b><i>nside&#160;city&#160;(tall&#160;building)&#160;</i><br/>
&#160;<br/>
<b>814</b><br/>
<b>818</b><br/>
<b>770</b><br/>
<i>inside&#160;city&#160;&#160;</i>&#160;<br/>
<i>street&#160;(ins</i><br/>
<b>824&#160;</b><i>ide&#160;city)&#160;</i><br/>
<b>544</b><br/>
0.74<br/>
<b>761</b><br/>
0.64&#160;car, sign, roa<br/>
<b>766</b><br/>
<b>765&#160;</b>d&#160;<br/>
buildings, car, sidewalk&#160;<br/>
c&#160;<br/>
<b>598</b>ar, sand beach, tree&#160;<br/>
wi&#160;<b>815</b><br/>
<b>820</b><br/>
ndow, tree, building&#160;<br/>
<b>819</b><br/>
<b>771</b><br/>
&#160;<br/>
&#160;<br/>
<b>825</b><br/>
<b>545</b><br/>
<b>762</b><br/>
<b>767</b><br/>
<b>766</b><br/>
trees, buildings&#160;&#160;<br/>
&#160;t<br/>
<b>599</b>ree, car, sidewalk&#160;<br/>
occl<br/>
buildings, car, sidewalk&#160;<br/>
wi<br/>
<b>816</b><br/>
<b>821</b><br/>
uded&#160;<br/>
<b>820</b><br/>
ndow, tree, building&#160;<br/>
0.72<br/>
<b>772</b><br/>
<b>826</b><br/>
<b>546</b><br/>
<b>763</b><br/>
<b>768</b><br/>
occlude<br/>
0.62<br/>
d, wi&#160;<b>767</b><br/>
ndow&#160;<br/>
&#160;<br/>
&#160;<br/>
<b>600</b><br/>
occl&#160;<b>817</b><br/>
<b>822</b><br/>
<b>821</b><br/>
uded&#160;<br/>
<b>773</b><br/>
<b>827</b><br/>
<b>547</b><br/>
0.7<br/>
<b>764</b><br/>
<b>769</b><br/>
<b>768&#160;</b>&#160;&#160;&#160;<br/>
&#160;<br/>
<i>&#160;&#160;</i>&#160;<br/>
&#160;<br/>
&#160;<br/>
&#160;<br/>
<b>601</b><br/>
&#160;<br/>
<b>818</b><br/>
<b>823</b><br/>
<b>822</b><br/>
<b>774</b><br/>
<b>828</b><br/>
<b>548</b><br/>
0.6<br/>
average accuracy&#160;0.68<br/>
<b>765</b><br/>
<i>inside&#160;cit</i><br/>
<b>770&#160;</b><i>y&#160;&#160;</i>&#160;<br/>
&#160;&#160;<i>tall&#160;building&#160;</i><br/>
<i>st</i>&#160;<i>reet&#160;(inside&#160;city)&#160;</i><br/>
<i>insi</i><br/>
average accuracy<br/>
<b>769</b><br/>
<i>&#160;&#160;</i>&#160;<br/>
&#160;<br/>
&#160;<br/>
<b>602</b><br/>
<b>819</b><br/>
<i>de&#160;city&#160;(tall&#160;building)&#160;</i><br/>
<b>824</b><br/>
<b>823</b><br/>
<b>775</b><br/>
<i>stree</i>&#160;<i>t&#160;&#160;</i><br/>
<i>&#160;</i><br/>
&#160;<i>highway&#160;(street)&#160;</i><br/>
&#160;<br/>
<b>829</b><br/>
<b>549</b><br/>
<b>766</b><br/>
<b>771</b><br/>
<b>770</b><br/>
<i>tall&#160;building&#160;</i><br/>
<i>insi</i><br/>
<b>603</b><br/>
<b>820</b><br/>
<i>de&#160;city&#160;(tall&#160;building)&#160;</i><br/>
<b>825</b><br/>
<b>824</b><br/>
0.66<br/>
<b>776</b><br/>
buildings, car, sidewalk&#160;<br/>
0.58<br/>
trees, buildings&#160;<br/>
wi<br/>
&#160;&#160;ndow, tree, building&#160;<br/>
tree, car, s<br/>
<b>830&#160;</b>idewalk&#160;<br/>
<b>550</b><br/>
<b>767</b><br/>
<b>772</b><br/>
<b>771</b><br/>
<i>&#160;</i><br/>
&#160;<br/>
<b>604</b><br/>
<b>821</b><br/>
<b>826</b><br/>
<b>825</b><br/>
<b>777</b><br/>
tree, car, sidewalk&#160;<br/>
occluded, window&#160;<br/>
oc<br/>
c&#160;c<br/>
a&#160;l<br/>
r&#160;ude<br/>
, wi&#160;d&#160;<br/>
ndow, tree&#160;<br/>
&#160;<br/>
trees, buildings&#160;<br/>
tree, car, s<br/>
<b>831&#160;</b>idewalk&#160;<br/>
<b>551</b><br/>
0.64<br/>
<b>768</b><br/>
<b>773</b><br/>
<b>772</b><br/>
<b>827</b><br/>
&#160;<br/>
&#160;<br/>
<b>605</b><br/>
<b>822</b><br/>
<b>826</b><br/>
<b>778</b><br/>
0.56<br/>
occluded, window&#160;<br/>
&#160;<br/>
&#160;<br/>
<b>832</b><br/>
<b>552</b><br/>
&#160;&#160;20<br/>
40<br/>
60&#160;<b>769</b><br/>
<b>774</b><br/>
<b>773</b><br/>
80<br/>
100<br/>
120<br/>
topics<br/>
20<br/>
40<br/>
<i>&#160;&#160;</i>&#160;<br/>
60<br/>
80<br/>
100<br/>
120<br/>
&#160;<br/>
topics<br/>
&#160;&#160;&#160;<br/>
&#160;<br/>
<b>606</b><br/>
&#160;<br/>
&#160;<br/>
<b>823</b><br/>
<b>828</b><br/>
<b>827</b><br/>
<b>779</b><br/>
<b>833</b><br/>
<b>553</b><br/>
<b>770</b><br/>
multi!class sLDA with annotations<br/>
multi!class sLDA<br/>
<i>tal</i><br/>
Fei!<i>l&#160;building</i><br/>
<b>775</b><br/>
<b>774&#160;</b><i>&#160;</i><br/>
# of components<br/>
Fei and Perona, 2005&#160;&#160;<br/>
Bosch et al., 2006<br/>
&#160;<br/>
<i>street&#160;&#160;</i><br/>
<i>ins</i><br/>
&#160;<br/>
<b>607&#160;</b><i>ide&#160;city&#160;(tall&#160;building)&#160;</i><br/>
<i>hi</i><br/>
&#160;&#160;&#160;<br/>
&#160;<br/>
&#160;<br/>
<b>824</b><br/>
<b>829</b><br/>
<i>ghway&#160;(street)&#160;</i><br/>
<b>828</b><br/>
<b>780</b><br/>
<b>834</b><br/>
<b>554</b><br/>
<b>771</b><br/>
<b>776</b><br/>
<b>775</b><br/>
<i>fores&#160;t</i><br/>
&#160;<br/>
&#160;<i>mount</i><br/>
<b>608</b><br/>
<i>ain (forest)&#160;</i><br/>
&#160;<br/>
<i>street&#160;&#160;</i><br/>
<i>hi</i><br/>
<b>825</b><br/>
<b>830</b><br/>
<b>829</b><br/>
<i>ghway&#160;(street)&#160;</i><br/>
<b>781</b><br/>
<b>835</b><br/>
Figure&#160;2.&#160;Comparisons&#160;of&#160;average&#160;accuracy&#160;over&#160;all&#160;classes&#160;based&#160;on&#160;random&#160;train/test&#160;subsets.&#160;multi-class&#160;sLDA&#160;with&#160;annotations&#160;and<br/>
<b>555</b><br/>
<b>772</b><br/>
5<br/>
trees, buildings<br/>
<b>777</b><br/>
<b>776&#160;</b>&#160;&#160;&#160;<br/>
tree, car, sidewalk&#160;<br/>
tr&#160;ee, car, sidewalk&#160;<br/>
car<br/>
&#160;<br/>
<b>609</b><br/>
&#160;<br/>
<b>826</b><br/>
, window, tree&#160;<br/>
<b>831</b><br/>
<b>830</b><br/>
<b>782</b><br/>
multi-class&#160;sLDA&#160;(red&#160;curves&#160;in&#160;color)&#160;are&#160;both&#160;our&#160;models.&#160;left.<br/>
oc<br/>
Accurac&#160;c<br/>
y&#160;lude<br/>
tre<br/>
as&#160;ead, wi<br/>
&#160;tr<br/>
ndow<br/>
<b>778</b><br/>
unk, tre<br/>
function&#160;&#160;<br/>
es<br/>
of&#160;,&#160;&#160;the&#160;number&#160;of<br/>
&#160;<br/>
topics&#160;on&#160;the&#160;LabelMe&#160;dataset.<br/>
&#160;<br/>
<b>836</b><br/>
<b>556</b><br/>
<b>773</b><br/>
snowy&#160;mountain, tree&#160;<br/>
&#160;<br/>
<b>777</b><br/>
tree, car, sidewalk&#160;<br/>
car<br/>
<b>610</b><br/>
<b>827</b><br/>
, window, tree&#160;<br/>
<b>832</b><br/>
<b>831</b><br/>
right.&#160;Accuracy&#160;as&#160;a&#160;function&#160;of&#160;the<br/>
<b>783</b><br/>
number&#160;of&#160;topics&#160;on&#160;the&#160;UIUC-Sport&#160;dataset.<br/>
<b>837</b><br/>
<b>557</b><br/>
<b>774</b><br/>
gr<br/>
<b>779</b><br/>
<b>778</b><br/>
ound&#160;grass&#160;<br/>
&#160;<br/>
trunk&#160;<br/>
&#160;<br/>
<b>611</b><br/>
<b>828</b><br/>
<b>833</b><br/>
<b>832</b><br/>
SLDA&#160;<b>784</b><br/>
for&#160;image<br/>
&#160;<br/>
classification<br/>
&#160;<br/>
(with&#160;&#160;Chong&#160;Wang,&#160;&#160;&#160;CVPR&#160;<i>&#160;&#160;</i>&#160;<br/>
2009)&#160;&#160;<br/>
&#160;<br/>
&#160;<br/>
<b>838</b><br/>
<b>558</b><br/>
3.&#160;multi-class&#160;sLDA:&#160;This&#160;is&#160;the<br/>
<b>775</b><br/>
<b>780</b><br/>
multi-class&#160;sLDA&#160;model,<br/>
purely<br/>
<b>779</b><br/>
generative&#160;approach.&#160;On&#160;one&#160;hand,&#160;a&#160;large&#160;number<br/>
<b>612</b><br/>
<b>829</b><br/>
<b>834</b><br/>
<b>833</b><br/>
<b>785</b><br/>
<i>street&#160;&#160;&#160;</i>&#160;<br/>
&#160;<br/>
<i>forest&#160;</i><br/>
<i>hi</i><br/>
&#160;&#160;<i>ghway&#160;(street)&#160;</i><br/>
<i>mountain (</i><br/>
<b>839&#160;</b><i>forest)&#160;</i><br/>
<i>&#160;&#160;</i>&#160;<br/>
&#160;<br/>
&#160;<br/>
<b>559</b><br/>
described&#160;in&#160;this&#160;paper.<br/>
<b>776</b><br/>
<b>781</b><br/>
of&#160;topics<br/>
<b>780</b><br/>
<b>835</b><br/>
increases&#160;the&#160;possibility&#160;of&#160;overfitting;&#160;on&#160;the&#160;other<br/>
<i>coas</i>&#160;<i>t</i><br/>
&#160;<br/>
&#160;<i>ope</i><br/>
<b>613</b><br/>
<i>n country&#160;(coast)&#160;</i><br/>
&#160;<br/>
<b>830</b><br/>
<b>834</b><br/>
<b>786</b><br/>
<i>forest&#160;</i><br/>
<i>mountain (</i><br/>
<b>840&#160;</b><i>forest)&#160;</i><br/>
<b>560</b><br/>
4.&#160;multi-class&#160;sLDA&#160;with<br/>
<b>777</b><br/>
annotations:&#160;This&#160;is&#160;multi-class<br/>
tree, c<br/>
hand,&#160;a<br/>
it&#160;r, side<br/>
pro&#160;wal<br/>
<b>782</b><br/>
<b>781</b><br/>
videsk&#160;&#160;more&#160;latent&#160;features&#160;for&#160;btree&#160;trunk, t<br/>
uilding&#160;therees,&#160;&#160;<br/>
clas-<br/>
c&#160;<br/>
<b>614</b>ar, window, tree&#160;<br/>
s<br/>
<b>831</b><br/>
<b>836</b><br/>
nowy&#160;mountain, tree&#160;<br/>
<b>835</b><br/>
<b>787</b><br/>
&#160;<br/>
&#160;<br/>
<b>841</b><br/>
<b>561</b><br/>
sLDA&#160;with&#160;annotations,<br/>
<b>778</b><br/>
&#160;<br/>
<b>783</b><br/>
sifier.<br/>
<b>782</b><br/>
described&#160;in&#160;this&#160;paper.<br/>
sand beach,&#160;cloud&#160;<br/>
ground&#160;grass&#160;<br/>
&#160;s<br/>
<b>615&#160;</b>ea&#160;water, buildings&#160;<br/>
tr<br/>
tree&#160;trunk, trees,&#160;&#160;<br/>
s<br/>
<b>832</b><br/>
<b>837</b><br/>
unk&#160;<br/>
<b>836</b><br/>
nowy&#160;mountain, tree&#160;<br/>
<b>788</b><br/>
<b>842</b><br/>
<b>562</b><br/>
<b>779</b><br/>
<b>784</b><br/>
<b>783</b><br/>
&#160;<br/>
&#160;<br/>
&#160;<br/>
ground&#160;grass&#160;<br/>
<b>616</b><br/>
tr<br/>
<b>833</b><br/>
<b>838</b><br/>
<b>837</b><br/>
unk&#160;<br/>
<b>789</b><br/>
<b>843</b><br/>
<b>563</b><br/>
Note&#160;all&#160;testing&#160;is&#160;performed&#160;on<br/>
<b>780</b><br/>
<b>785</b><br/>
<b>784&#160;</b><i>&#160;&#160;</i>&#160;<br/>
&#160;<br/>
<i>&#160;&#160;</i>&#160;<br/>
&#160;<br/>
&#160;<br/>
&#160;<br/>
unlabeled&#160;and&#160;unannotated<br/>
&#160;<br/>
<b>617</b><br/>
&#160;<br/>
<b>834</b><br/>
<b>839</b><br/>
<b>838</b><br/>
<b>790</b><br/>
Image&#160;Annotation.&#160;In&#160;the&#160;case&#160;of&#160;multi-class&#160;sLDA&#160;with<br/>
<b>844</b><br/>
<b>564</b><br/>
images.<br/>
<b>781</b><br/>
<i>fores</i><br/>
<b>786&#160;</b><i>t&#160;&#160;</i>&#160;<br/>
&#160;<br/>
<i>coast&#160;</i><br/>
<i>mount</i><br/>
&#160;<br/>
<i>ain (forest)&#160;</i><br/>
<i>ope</i><br/>
<b>785</b><br/>
<i>&#160;&#160;</i>&#160;<br/>
&#160;<br/>
&#160;<br/>
<b>618</b><br/>
<b>835</b><br/>
<i>n country&#160;(coast)&#160;</i><br/>
<b>840</b><br/>
<b>839</b><br/>
<b>791</b><br/>
<i>mount</i><br/>
annotations,<br/>
<a href="Blei_1s.html#1"><i>ai</i></a><br/>
we&#160;&#160;<a href="Blei_1s.html#1"><i>n</i></a><br/>
can&#160;use&#160;the&#160;same&#160;trained&#160;model&#160;for<br/>
&#160;<br/>
image<br/>
&#160;<i>highway&#160;(mountain)&#160;</i><br/>
&#160;<br/>
<b>845</b><br/>
<b>565</b><br/>
The&#160;results&#160;are&#160;illustrated&#160;in&#160;the&#160;<b>782</b><br/>
<a href="Blei_1s.html#1"><b>787</b></a><br/>
D.&#160;Blei<br/>
<b>786</b><br/>
<i>coast&#160;</i><br/>
<i>ope</i><br/>
graphs&#160;of&#160;Figure&#160;2&#160;and<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<b>619</b><br/>
<b>836</b><br/>
<i>n country&#160;(coast)&#160;</i><br/>
<b>841</b><br/>
<b>840</b><br/>
<b>792</b><br/>
tree&#160;trunk, t<br/>
annotation.&#160;r<br/>
We<a href="Blei_1s.html#1">es,&#160;&#160;</a><br/>
<a href="Blei_1s.html#1">emphasize&#160;that&#160;</a>our<br/>
s<br/>
modelsand be<br/>
are&#160;ach,&#160;cloud<br/>
designed&#160;&#160;<br/>
for<br/>
snow<br/>
<i>&#160;</i><br/>
y&#160;mountain, tree&#160;<br/>
sea&#160;water<br/>
<b>846&#160;</b>, buildings&#160;<br/>
<b>566</b><br/>
in&#160;the&#160;confusion&#160;matrices&#160;of&#160;Figure&#160;3.2<b>783</b><br/>
<b>788</b><br/>
<b>787</b><br/>
&#160;<br/>
&#160;<br/>
Our&#160;models—multi-<br/>
<b>620</b><br/>
<b>837</b><br/>
<b>842</b><br/>
<b>841</b><br/>
<b>793</b><br/>
s<br/>
gr<br/>
now&#160;ound&#160;<br/>
y&#160;m<br/>
gr<br/>
ounta<br/>
simultaneous<br/>
sis&#160;<br/>
n,&#160;&#160;<br/>
tr<br/>
classification&#160;and&#160;annotation.&#160;For&#160;image&#160;an-<br/>
t&#160;unk&#160;<br/>
ree, snowy&#160;mountain&#160;<br/>
&#160;<br/>
sand beach,&#160;cloud&#160;<br/>
sea&#160;water<br/>
<b>847</b>, buildings&#160;<br/>
<b>567</b><br/>
class&#160;sLDA&#160;and&#160;multi-class&#160;sLDA<br/>
<b>784</b><br/>
<b>789</b><br/>
<b>788</b><br/>
<b>843</b><br/>
with&#160;annotations—&#160;per-&#160;&#160;<br/>
sea&#160;wa<br/>
notation,&#160;te<br/>
wer, field&#160;<br/>
&#160;<br/>
<b>621</b><br/>
<b>838</b><br/>
<b>842</b><br/>
<b>794</b><br/>
compare&#160;following&#160;two&#160;methods,<br/>
&#160;<br/>
<b>848</b><br/>
<b>568</b><br/>
form&#160;better&#160;than&#160;the&#160;other&#160;approaches.&#160;<b>785</b><br/>
<b>790</b><br/>
<b>789</b><br/>
<b>844</b><br/>
They&#160;reduce&#160;the&#160;error<br/>
<i>&#160;&#160;</i>&#160;<br/>
&#160;<br/>
<i>&#160;&#160;</i>&#160;<br/>
&#160;<br/>
<b>622</b><br/>
&#160;<br/>
&#160;<br/>
<b>839</b><br/>
<b>843</b><br/>
<b>795</b><br/>
<b>849</b><br/>
<b>569</b><br/>
of&#160;Fei-Fei&#160;and&#160;Perona,&#160;2005&#160;by&#160;at<br/>
<b>786</b><br/>
least&#160;10%&#160;on&#160;both&#160;data&#160;&#160;<br/>
<i>coas</i><br/>
<b>791</b><br/>
<b>790&#160;</b><i>t&#160;</i><br/>
1.&#160;Blei&#160;and&#160;Jor&#160;&#160;<br/>
dan,&#160;2003:&#160;This&#160;is&#160;the<br/>
&#160;<br/>
<i>mountain&#160;</i><br/>
<i>ope</i><br/>
corr-LDA&#160;model<br/>
&#160;<br/>
<b>623&#160;</b><i>n country&#160;(coast)&#160;</i><br/>
<i>hi</i><br/>
<i>&#160;&#160;</i>&#160;<br/>
&#160;<br/>
&#160;<br/>
<b>840</b><br/>
<b>845</b><br/>
<i>ghway&#160;(mountain)&#160;</i><br/>
<b>844</b><br/>
<b>796</b><br/>
<b>850</b><br/>
<b>570</b><br/>
sets,&#160;and&#160;even&#160;more&#160;for&#160;Bosch&#160;et&#160;al.,<b>787</b><br/>
<b>792</b><br/>
<b>791</b><br/>
2006.&#160;This&#160;demon-<br/>
<i>open countr&#160;</i>&#160;<br/>
<i>y</i><br/>
<i>&#160;</i><br/>
&#160;<i>c</i><br/>
<b>624&#160;</b><i>oast&#160;(open country)&#160;</i><br/>
<i>&#160;</i><br/>
<i>mountain&#160;</i><br/>
<i>hi</i><br/>
<b>841</b><br/>
<b>846</b><br/>
<b>845</b><br/>
<i>ghway&#160;(mountain)&#160;</i><br/>
<b>797</b><br/>
from&#160;[2],&#160;trained&#160;on&#160;annotated&#160;images.<br/>
<b>851</b><br/>
<b>571</b><br/>
strates&#160;that&#160;multi-class&#160;sLDA&#160;is&#160;a<br/>
<b>788</b><br/>
sand beach,&#160;cloud<br/>
<b>793</b><br/>
<b>792&#160;</b>&#160;<br/>
better&#160;classifier,&#160;and&#160;that<br/>
snowy&#160;mountain,&#160;&#160;<br/>
se<br/>
<i>&#160;&#160;</i>a&#160;water, buildings&#160;<br/>
tree<br/>
<i>&#160;</i><br/>
<b>625</b><br/>
<i>&#160;</i><br/>
<b>842</b><br/>
, snowy&#160;mountain&#160;<br/>
<b>847</b><br/>
<b>846</b><br/>
<b>798</b><br/>
2.&#160;multi-class&#160;sLDA&#160;with&#160;annotations:&#160;This&#160;is&#160;exactly&#160;the<br/>
<b>852</b><br/>
<b>572</b><br/>
joint&#160;modeling&#160;does&#160;not&#160;negatively&#160;af<b>789</b><br/>
cars&#160;<b>794</b><br/>
, field,&#160;&#160;<br/>
sea&#160;water, field&#160;<br/>
&#160;<br/>
<b>793</b><br/>
snowy&#160;mountain,&#160;&#160;<br/>
tree, field, sea&#160;water&#160;<br/>
tree<br/>
fect&#160;classification&#160;ac-<br/>
<b>626</b><br/>
<b>843</b><br/>
, snowy&#160;mountain&#160;<br/>
<b>848</b><br/>
<b>847</b><br/>
<b>799</b><br/>
same&#160;model&#160;trained&#160;for&#160;image&#160;classification&#160;in&#160;the&#160;pre-<br/>
<b>853</b><br/>
<b>573</b><br/>
curacy&#160;when&#160;annotation&#160;information&#160;<b>790</b><br/>
sa<br/>
<b>795</b><br/>
<b>794</b><br/>
nd beach&#160;<br/>
sea&#160;water, field&#160;<br/>
is&#160;available.&#160;In&#160;fact,&#160;it<br/>
<b>627</b><br/>
<b>844</b><br/>
<b>849</b><br/>
<b>848</b><br/>
<b>800</b><br/>
vious<br/>
<i>&#160;</i><br/>
section.&#160;&#160;In&#160;testing<br/>
&#160;<br/>
annotation,&#160;&#160;<br/>
we&#160;observe&#160;only&#160;&#160;<br/>
&#160;<br/>
&#160;<br/>
&#160;<br/>
<b>854</b><br/>
<b>574</b><br/>
usually&#160;increases&#160;the&#160;accuracy.<br/>
<b>791</b><br/>
<b>796</b><br/>
<b>795</b><br/>
<b>628</b><br/>
<b>845</b><br/>
<b>850</b><br/>
<b>849</b><br/>
<b>801</b><br/>
<i>mountain&#160;</i><br/>
<i>open country&#160;</i><br/>
<i>highway&#160;(mountain)&#160;</i><br/>
<i>coast&#160;(op</i><br/>
images.<br/>
<b>855&#160;</b><i>en country)&#160;</i><br/>
Figure&#160;4.&#160;Example&#160;results&#160;from&#160;the&#160;LabelMe&#160;dataset.&#160;For&#160;&#160;each&#160;class,&#160;left&#160;side<br/>
&#160;<br/>
contains&#160;examples&#160;with&#160;correct<br/>
&#160;<br/>
classification&#160;and&#160;predicted&#160;&#160;<br/>
<b>575</b><br/>
Observe&#160;that&#160;the&#160;model&#160;of&#160;[5],<br/>
<b>792</b><br/>
<b>797</b><br/>
<b>796</b><br/>
<b>851</b><br/>
<b>850</b><br/>
unsupervised&#160;LDA&#160;com-<br/>
<i>&#160;</i><br/>
<i>&#160;</i><br/>
<i>&#160;</i><br/>
<b>629</b><br/>
<i>&#160;</i><br/>
<b>846</b><br/>
<b>802</b><br/>
annotations,&#160;while&#160;right&#160;side&#160;contains&#160;wrong&#160;ones&#160;(the&#160;class&#160;label&#160;in&#160;<i>ope</i><br/>
the&#160;<i>n count</i><br/>
bracket&#160;<i>r</i><br/>
is&#160;<i>y&#160;</i><br/>
the&#160;right&#160;one)&#160;with&#160;the&#160;predicted&#160;annotations.&#160;The&#160;italic&#160;<i>coast&#160;(op</i><br/>
<b>856</b><i>en country)&#160;</i><br/>
<b>576</b><br/>
bined&#160;with&#160;KNN,&#160;gives&#160;the&#160;worst&#160;<b>793</b><br/>
performance&#160;of&#160;these<br/>
snowy&#160;mountain,&#160;<br/>
<b>798</b><br/>
<b>797&#160;</b>&#160;<br/>
cars, field,&#160;&#160;<br/>
tr<br/>
<b>630&#160;</b>ee, snowy&#160;mountain&#160;<br/>
tree&#160;<b>847</b><br/>
<b>852</b><br/>
, field, sea&#160;water&#160;<br/>
<b>851</b><br/>
<b>803</b><br/>
words&#160;indicate&#160;the&#160;class&#160;label,<br/>
To<br/>
while<br/>
measure&#160;the&#160;normal<br/>
image<br/>
words&#160;are<br/>
annotation&#160;associated&#160;predicted<br/>
performance,&#160;we&#160;use&#160;<i>&#160;</i><br/>
annotations.<br/>
an<br/>
<i>&#160;</i><br/>
<b>857</b><br/>
<b>577</b><br/>
methods.&#160;This&#160;highlights&#160;the&#160;dif<br/>
<b>794</b><br/>
ference&#160;between&#160;finding<br/>
sea&#160;water, fiel<br/>
<b>799</b><br/>
<b>798&#160;</b>d&#160;<br/>
sand beach&#160;<br/>
evaluation&#160;measure&#160;from&#160;information&#160;retriev&#160;c<br/>
al.&#160;ars, field,&#160;&#160;<br/>
<b>631</b><br/>
Specifi-<br/>
tree&#160;<b>848</b><br/>
<b>853</b><br/>
<b>852</b><br/>
, field, sea&#160;water&#160;<br/>
<b>804</b><br/>
<b>858</b><br/>
<b>578</b><br/>
topics&#160;that&#160;are&#160;predictive,&#160;as&#160;our<br/>
<b>795</b><br/>
<b>800</b><br/>
<b>799</b><br/>
models&#160;do,&#160;and&#160;finding<br/>
sand beach&#160;<br/>
<b>632</b><br/>
<b>849</b><br/>
<b>854</b><br/>
<b>853</b><br/>
<b>805</b><br/>
cally,&#160;we&#160;examine&#160;the&#160;top-N&#160;F-measure3,&#160;denoted&#160;as&#160;F-<br/>
<b>859</b><br/>
<b>579</b><br/>
topics&#160;in&#160;an&#160;unsupervised&#160;way.&#160;The&#160;<b>796</b><br/>
&#160;<br/>
<b>801</b><br/>
<b>800</b><br/>
&#160;<br/>
accuracy&#160;of&#160;unsuper-<br/>
Figure&#160;4.&#160;Example<br/>
&#160;<br/>
results&#160;from&#160;the&#160;LabelMe<br/>
&#160;<br/>
dataset.<br/>
<b>633&#160;</b>For&#160;each&#160;class,&#160;left&#160;side&#160;contains&#160;examples<br/>
[28]&#160;J.&#160;Vogel&#160;and&#160;B.&#160;Schiele.&#160;A&#160;semantic&#160;typicality&#160;measure&#160;for<br/>
[30]&#160;Z.-H.&#160;Zhou&#160;and&#160;M.-L.&#160;Zhang.&#160;Multi-instance&#160;multi-label<br/>
<b>850</b><br/>
<b>855</b><br/>
with&#160;correct&#160;classification&#160;and&#160;predicted<br/>
<b>854</b><br/>
<b>806</b><br/>
measure@N,&#160;where&#160;we&#160;set&#160;N&#160;=&#160;5.&#160;We&#160;find&#160;that&#160;multi-<br/>
<b>860</b><br/>
<b>580</b><br/>
vised&#160;LDA&#160;might&#160;be&#160;increased&#160;by<br/>
<b>797</b><br/>
<i>open countr</i><br/>
<b>802&#160;</b><i>y&#160;</i><br/>
<i>coast&#160;(open country)&#160;</i><br/>
<b>801</b><br/>
annotations,&#160;while&#160;right&#160;side&#160;contains&#160;wrong&#160;ones&#160;(the&#160;class&#160;label&#160;in&#160;the&#160;bracket&#160;is&#160;the&#160;right&#160;one)&#160;with<br/>
using&#160;some&#160;of&#160;natural<br/>
the<br/>
scene<br/>
other<br/>
categorization.&#160;In&#160;DA&#160;Figure&#160;4.&#160;Example<br/>
GM-Symposium,<br/>
results<br/>
2004.&#160;5<br/>
from&#160;the&#160;LabelMe<br/>
learning<br/>
dataset.<br/>
with&#160;<b>634&#160;</b>For&#160;each<br/>
application&#160;to&#160;class,<br/>
scene&#160;left&#160;side&#160;contains<br/>
classification.&#160;In&#160;examples<br/>
NIPS,<br/>
<b>851</b><br/>
the&#160;predicted&#160;annotations.&#160;The&#160;italic<br/>
<b>856</b><br/>
<b>855</b><br/>
with&#160;correct&#160;classification&#160;and&#160;predicted<br/>
<b>807</b><br/>
class&#160;sLDA&#160;with&#160;<i>&#160;</i>annotations&#160;performs&#160;slightly&#160;better&#160;than<br/>
<i>&#160;</i><br/>
<b>861</b><br/>
<b>581</b><br/>
visual&#160;features&#160;suggested&#160;by&#160;[5].<br/>
<b>798</b><br/>
<b>803</b><br/>
<b>802</b><br/>
words&#160;indicate&#160;the&#160;class&#160;label,&#160;while&#160;the&#160;normal&#160;words&#160;are&#160;associated&#160;predicted&#160;annotations.<br/>
Here,&#160;we&#160;restrict&#160;ourselves<br/>
annotations,&#160;while&#160;right&#160;side&#160;contains&#160;wrong<br/>
2006.&#160;5<br/>
ones&#160;(the<br/>
<b>635&#160;</b>class&#160;label&#160;in&#160;the&#160;bracket&#160;is&#160;the&#160;right&#160;one)&#160;with&#160;<b>852</b><br/>
<b>857</b><br/>
the&#160;predicted&#160;annotations.&#160;The&#160;italic<br/>
<b>856</b><br/>
<b>808</b><br/>
[29]&#160;Y.&#160;Wang&#160;and&#160;S.&#160;Gong.<br/>
corr-LD&#160;ca<br/>
A&#160;rso, f<br/>
v&#160;ie<br/>
er&#160;ld,&#160;<br/>
all&#160;<br/>
Conditional&#160;random<br/>
the<br/>
field<br/>
numbers&#160;for<br/>
of&#160;natural<br/>
topics&#160;tested&#160;(about&#160;1%<br/>
tree, field, sea&#160;water&#160;<br/>
<b>862</b><br/>
<b>582</b><br/>
to&#160;SIFT&#160;features&#160;in&#160;order&#160;to<br/>
<b>799</b><br/>
<b>804</b><br/>
<b>803</b><br/>
words&#160;indicate&#160;the&#160;class&#160;label,&#160;while&#160;the&#160;normal&#160;words&#160;are&#160;associated&#160;predicted&#160;annotations.<br/>
compare&#160;models,&#160;rather&#160;than<br/>
<b>636</b><br/>
<b>853</b><br/>
<b>858</b><br/>
<b>857</b><br/>
<b>809</b><br/>
scene&#160;categorization.<br/>
relative&#160;sa<br/>
In&#160;nd be<br/>
impro&#160;a<br/>
BMVCv&#160;c,h&#160;<br/>
2007.&#160;5<br/>
ement).&#160;For&#160;example,&#160;considering&#160;models<br/>
<b>863</b><br/>
<b>583</b><br/>
feature&#160;sets.<br/>
<b>800</b><br/>
<b>805</b><br/>
<b>804</b><br/>
<b>637</b><br/>
<b>854</b><br/>
<b>859</b><br/>
<b>858</b><br/>
with&#160;100&#160;topics,&#160;the&#160;[28]&#160;J.&#160;V<br/>
LabelMe&#160;ogel&#160;and&#160;B.&#160;Schiele.<br/>
F-measures&#160;are&#160;38.&#160;A&#160;semantic<br/>
2%&#160;(corr-&#160;typicality&#160;measure&#160;for<br/>
[30]&#160;Z.-H.&#160;Zhou&#160;and&#160;M.-L.&#160;Zhang.&#160;Multi-instance&#160;multi-label<br/>
<b>584</b><br/>
As&#160;the&#160;number&#160;of&#160;topics&#160;increases,&#160;<b>801</b><br/>
<b>806</b><br/>
<b>805</b><br/>
the&#160;multi-class&#160;sLDA<br/>
<b>638</b><br/>
<b>855</b><br/>
<b>860</b><br/>
Figure&#160;4.&#160;Example&#160;results<br/>
LDA)from<br/>
and&#160;the<br/>
38.LabelMe<br/>
7%<br/>
dataset.<br/>
(multi-class&#160;For<br/>
<b>859</b><br/>
natural&#160;each<br/>
scene<br/>
sLDA&#160;class,<br/>
cate<br/>
with&#160;left&#160;side<br/>
gorization.contains<br/>
In<br/>
annotations);DA<br/>
on&#160;examples&#160;with<br/>
GM-Symposium,&#160;correct<br/>
2004.&#160;5classification&#160;and&#160;predicted<br/>
learning&#160;with&#160;application&#160;to&#160;scene&#160;classification.&#160;In&#160;NIPS,<br/>
[28]&#160;J.&#160;Vogel&#160;and&#160;B.&#160;Schiele.&#160;A&#160;semantic&#160;typicality&#160;measure&#160;for<br/>
[30]&#160;Z.-H.&#160;Zhou&#160;and&#160;M.-L.&#160;Zhang.&#160;Multi-instance&#160;multi-label<br/>
<b>585</b><br/>
models&#160;(with&#160;and&#160;without<br/>
<b>802</b><br/>
annotation)&#160;do&#160;not&#160;annotations,<br/>
overfit<br/>
while<br/>
until<br/>
right&#160;side&#160;contains<br/>
UIUC-Sport,<br/>
wrong<br/>
<b>807</b><br/>
<b>806</b><br/>
they&#160;are&#160;ones<br/>
34.&#160;(the<br/>
7%&#160;class<br/>
(corr&#160;label<br/>
-LDA)&#160;in&#160;the<br/>
8<br/>
and&#160;brack<br/>
35.0%et&#160;is&#160;the<br/>
(multi-&#160;right&#160;one)&#160;with<br/>
<b>639</b><br/>
the&#160;predicted&#160;annotations.<br/>
2006.&#160;The<br/>
5&#160;italic<br/>
<b>856</b><br/>
<b>861</b><br/>
<b>860</b><br/>
natural&#160;scene&#160;categorization.&#160;In&#160;DAGM-Symposium,&#160;2004.&#160;5<br/>
learning&#160;with&#160;application&#160;to&#160;scene&#160;classification.&#160;In&#160;NIPS,<br/>
<b>586</b><br/>
around&#160;100&#160;topics,&#160;while&#160;Fei-Fei&#160;and&#160;<b>803</b><br/>
Perona,&#160;words<br/>
2005&#160;indicate<br/>
begins&#160;the&#160;class&#160;label,&#160;while&#160;the<br/>
<b>808</b><br/>
<b>807&#160;</b>normal&#160;w<br/>
[29]&#160;ords<br/>
Y.&#160;are<br/>
W<br/>
associated<br/>
ang&#160;and&#160;S.<br/>
predicted<br/>
Gong.<br/>
annotations.<br/>
Conditional&#160;random&#160;field&#160;for&#160;natural<br/>
<b>640</b><br/>
<b>857</b><br/>
<b>862</b><br/>
<b>861</b><br/>
class&#160;sLDA&#160;with&#160;annotations).<br/>
2006.&#160;5<br/>
<b>587</b><br/>
to&#160;overfit&#160;at&#160;40&#160;topics.&#160;This&#160;suggests&#160;<b>804</b><br/>
<b>809</b><br/>
<b>808</b><br/>
scene&#160;categorization.&#160;In&#160;BMVC,&#160;2007.&#160;5<br/>
[29]&#160;Y.&#160;Wang&#160;and&#160;S.&#160;Gong.&#160;Conditional&#160;random&#160;field<br/>
that&#160;multi-class&#160;sLDA,<br/>
<b>641&#160;</b>for&#160;natural<br/>
<b>858</b><br/>
<b>863</b><br/>
<b>862</b><br/>
These&#160;results&#160;demonstrate&#160;that&#160;our&#160;models&#160;can&#160;perform<br/>
<b>588</b><br/>
which&#160;combines&#160;aspects&#160;of&#160;both<br/>
<b>805</b><br/>
<b>809</b><br/>
scene&#160;categorization.&#160;In&#160;BMVC,&#160;2007.&#160;5<br/>
generative&#160;and&#160;discrimina-<br/>
<b>642</b><br/>
<b>859</b><br/>
<b>863</b><br/>
classification&#160;and&#160;annotation&#160;with&#160;the&#160;same&#160;latent&#160;space.<br/>
<b>589</b><br/>
tive&#160;classification,&#160;can&#160;handle&#160;more&#160;<b>806</b><br/>
[28]&#160;J.&#160;Vogel&#160;and&#160;B.&#160;Schiele.&#160;A&#160;semantic&#160;typicality&#160;measure&#160;for<br/>
[30]&#160;Z.-H.&#160;Zhou&#160;and&#160;M.-L.&#160;Zhang.&#160;Multi-instance&#160;multi-label<br/>
latent&#160;features&#160;than&#160;a<br/>
<b>643</b><br/>
<b>860</b><br/>
With&#160;a&#160;single&#160;trained&#160;model,&#160;we&#160;find&#160;the&#160;annotation&#160;per-<br/>
8<br/>
<b>590</b><br/>
<b>807</b><br/>
natural&#160;scene&#160;categorization.&#160;In&#160;DAGM-Symposium,&#160;2004.&#160;5<br/>
learning&#160;with&#160;application&#160;to&#160;scene&#160;classification.&#160;In&#160;NIPS,<br/>
<b>644</b><br/>
<b>861</b><br/>
2Other&#160;than&#160;the&#160;topic&#160;models&#160;listed,&#160;we&#160;also&#160;tested&#160;an&#160;SVM-based&#160;ap-<br/>
formance&#160;that&#160;is&#160;competitive&#160;with&#160;the<br/>
2006.<br/>
state-of-the-art,<br/>
5<br/>
and<br/>
8<br/>
<b>591</b><br/>
<b>808</b><br/>
[29]&#160;Y.&#160;Wang&#160;and&#160;S.&#160;Gong.&#160;Conditional&#160;random&#160;field&#160;for&#160;natural<br/>
<b>645</b><br/>
<b>862</b><br/>
proach&#160;using&#160;SIFT&#160;image&#160;features.&#160;The&#160;SVM&#160;yielded&#160;much&#160;worse&#160;perfor-<br/>
classification&#160;performance&#160;that&#160;is&#160;superior.<br/>
<b>592</b><br/>
<b>809</b><br/>
scene&#160;categorization.&#160;In&#160;BMVC,&#160;2007.&#160;5<br/>
<b>646</b><br/>
<b>863</b><br/>
mance&#160;than&#160;the&#160;topic&#160;models&#160;(47%&#160;for&#160;the&#160;LabelMe&#160;data,&#160;and&#160;20%&#160;for&#160;the<br/>
<b>593</b><br/>
UIUC-Sport&#160;data).&#160;These&#160;are&#160;not&#160;marked&#160;on&#160;the&#160;plots.<br/>
3F-measure&#160;is&#160;defined&#160;as&#160;2&#160;∗&#160;precision&#160;∗&#160;recall/(precision&#160;+&#160;recall).<br/>
<b>647</b><br/>
8<br/>
6<br/>
<hr/>
<a name=70></a>Supervised&#160;topic&#160;models<br/>
•&#160;SLDA&#160;enables&#160;model-based&#160;regression&#160;where&#160;the&#160;predictor&#160;“variable”<br/>
is&#160;a&#160;text&#160;document.<br/>
•&#160;It&#160;can&#160;easily&#160;be&#160;used&#160;wherever&#160;LDA&#160;is&#160;used&#160;in&#160;an&#160;unsupervised<br/>
fashion&#160;(e.g.,&#160;images,&#160;genes,&#160;music).<br/>
•&#160;SLDA&#160;is&#160;a&#160;supervised&#160;dimension-reduction&#160;technique,&#160;whereas&#160;LDA<br/>
performs&#160;unsupervised&#160;dimension&#160;reduction.<br/>
•&#160;LDA&#160;+&#160;regression&#160;compared&#160;to&#160;sLDA&#160;is&#160;like&#160;principal&#160;components<br/>
regression&#160;compared&#160;to&#160;partial&#160;least&#160;squares.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=71></a>Relational&#160;topic&#160;models<br/>
966<br/>
902<br/>
1673<br/>
1253<br/>
1140<br/>
1432<br/>
1590<br/>
1481<br/>
964<br/>
981<br/>
<b>...</b><br/>
120<br/>
1060<br/>
<b>...</b><br/>
831<br/>
2259<br/>
837<br/>
474<br/>
...<br/>
436<br/>
722<br/>
965<br/>
264<br/>
1743<br/>
442<br/>
...<br/>
375<br/>
660<br/>
1335<br/>
640<br/>
<b>Utilizing prior concepts for&#160;</b><br/>
109<br/>
<b>learning</b><br/>
1959<br/>
885<br/>
The inductive learning problem&#160;<br/>
254<br/>
2272<br/>
635<br/>
<b>Irrelevant features and the&#160;</b><br/>
1489<br/>
consists of learning a concept&#160;<br/>
172&#160;256<br/>
<b>subset selection problem</b><br/>
given examples and&#160;<br/>
801<br/>
2192<br/>
381<br/>
1285<br/>
651<br/>
89<br/>
We address the problem of&#160;<br/>
547<br/>
nonexamples of the concept.&#160;To&#160;<br/>
2033<br/>
683<br/>
534<br/>
632<br/>
finding a subset of features that&#160;<br/>
177<br/>
perform this learning task,&#160;<br/>
1270<br/>
634<br/>
1592<br/>
allows a supervised induction&#160;<br/>
524<br/>
686<br/>
inductive learning algorithms bias&#160;<br/>
1020<br/>
119<br/>
algorithm to induce small high-<br/>
208<br/>
their learning method...<br/>
1642<br/>
accuracy concepts...<br/>
1176<br/>
1317<br/>
1698<br/>
1568<br/>
430<br/>
236<br/>
539<br/>
994<br/>
<b>...</b><br/>
1284<br/>
2593<br/>
223<br/>
313<br/>
1426<br/>
1165<br/>
1304<br/>
992<br/>
1792<br/>
2557<br/>
541<br/>
1188<br/>
2343<br/>
1377<br/>
2487<br/>
2197<br/>
1617<br/>
2137<br/>
<b>Learning with many irrelevant&#160;</b><br/>
<b>An evolutionary approach to&#160;</b><br/>
1001<br/>
1637<br/>
...<br/>
1674<br/>
911<br/>
52<br/>
1123<br/>
1483<br/>
1569<br/>
<b>features</b><br/>
<b>learning in robots</b><br/>
1039<br/>
In many domains, an appropriate&#160;<br/>
<b>Evaluation and selection of&#160;</b><br/>
Evolutionary learning methods&#160;<br/>
1695<br/>
1354<br/>
603<br/>
inductive bias is the MIN-<br/>
<b>biases in machine learning</b><br/>
have been found to be useful in&#160;<br/>
1680<br/>
1207<br/>
FEATURES bias, which prefers&#160;<br/>
In this introduction, we define the&#160;<br/>
several areas in the development&#160;<br/>
288<br/>
1040<br/>
consistent hypotheses definable&#160;<br/>
term bias as it is used in machine&#160;<br/>
of intelligent robots. In the&#160;<br/>
1355<br/>
1047<br/>
1465<br/>
136<br/>
over as few features as&#160;<br/>
learning systems. We motivate&#160;<br/>
approach described here,&#160;<br/>
75<br/>
1089<br/>
478<br/>
1010<br/>
1420<br/>
possible...<br/>
the importance of automated&#160;<br/>
evolutionary...<br/>
1348<br/>
methods for evaluating...<br/>
479<br/>
585<br/>
806<br/>
2122<br/>
227<br/>
1651<br/>
1345<br/>
92<br/>
1061<br/>
692<br/>
<b>Using a genetic algorithm to&#160;</b><br/>
<b>...</b><br/>
396<br/>
218<br/>
178<br/>
2299<br/>
960<br/>
378<br/>
<b>learn strategies for collision&#160;</b><br/>
1854<br/>
1578<br/>
2291<br/>
<b>...</b><br/>
1344<br/>
286<br/>
<b>avoidance and local&#160;</b><br/>
418<br/>
1539<br/>
1963<br/>
649<br/>
449<br/>
1138<br/>
303<br/>
335<br/>
<b>navigation</b><br/>
1855<br/>
...<br/>
2042<br/>
2290<br/>
<b>Improving tactical plans with&#160;</b><br/>
Navigation through obstacles&#160;<br/>
1290<br/>
1678<br/>
147<br/>
2300<br/>
1627<br/>
1275<br/>
...<br/>
<b>genetic algorithms</b><br/>
such as mine fields is an&#160;<br/>
2195<br/>
1121<br/>
2636<br/>
2091<br/>
1027<br/>
1238<br/>
The problem of learning decision&#160;<br/>
important capability for&#160;<br/>
2447<br/>
rules for sequential tasks is&#160;<br/>
autonomous underwater vehicles.&#160;<br/>
1644<br/>
344<br/>
2583<br/>
2012<br/>
addressed, focusing on the&#160;<br/>
One way to produce robust&#160;<br/>
2438<br/>
426<br/>
problem of learning tactical plans&#160;<br/>
behavior...<br/>
from a simple flight simulator&#160;<br/>
1244<br/>
where a plane must avoid a&#160;<br/>
2617<br/>
missile...<br/>
2213<br/>
1234<br/>
1944<br/>
•&#160;Many&#160;data&#160;sets&#160;contain&#160;connected&#160;observations.<br/>
•&#160;For&#160;example:<br/>
•&#160;Citation&#160;networks&#160;of&#160;documents<br/>•&#160;Hyperlinked&#160;networks&#160;of&#160;web-pages.<br/>•&#160;Friend-connected&#160;social&#160;network&#160;profiles<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=72></a>Relational&#160;topic&#160;models<br/>
966<br/>
902<br/>
1673<br/>
1253<br/>
1140<br/>
1432<br/>
1590<br/>
1481<br/>
964<br/>
981<br/>
<b>...</b><br/>
120<br/>
1060<br/>
<b>...</b><br/>
831<br/>
2259<br/>
837<br/>
474<br/>
...<br/>
436<br/>
722<br/>
965<br/>
264<br/>
1743<br/>
442<br/>
...<br/>
375<br/>
660<br/>
1335<br/>
640<br/>
<b>Utilizing prior concepts for&#160;</b><br/>
109<br/>
<b>learning</b><br/>
1959<br/>
885<br/>
The inductive learning problem&#160;<br/>
254<br/>
2272<br/>
635<br/>
<b>Irrelevant features and the&#160;</b><br/>
1489<br/>
consists of learning a concept&#160;<br/>
172&#160;256<br/>
<b>subset selection problem</b><br/>
given examples and&#160;<br/>
801<br/>
2192<br/>
381<br/>
1285<br/>
651<br/>
89<br/>
We address the problem of&#160;<br/>
547<br/>
nonexamples of the concept.&#160;To&#160;<br/>
2033<br/>
683<br/>
534<br/>
632<br/>
finding a subset of features that&#160;<br/>
177<br/>
perform this learning task,&#160;<br/>
1270<br/>
634<br/>
1592<br/>
allows a supervised induction&#160;<br/>
524<br/>
686<br/>
inductive learning algorithms bias&#160;<br/>
1020<br/>
119<br/>
algorithm to induce small high-<br/>
208<br/>
their learning method...<br/>
1642<br/>
accuracy concepts...<br/>
1176<br/>
1317<br/>
1698<br/>
1568<br/>
430<br/>
236<br/>
539<br/>
994<br/>
<b>...</b><br/>
1284<br/>
2593<br/>
223<br/>
313<br/>
1426<br/>
1165<br/>
1304<br/>
992<br/>
1792<br/>
2557<br/>
541<br/>
1188<br/>
2343<br/>
1377<br/>
2487<br/>
2197<br/>
1617<br/>
2137<br/>
<b>Learning with many irrelevant&#160;</b><br/>
<b>An evolutionary approach to&#160;</b><br/>
1001<br/>
1637<br/>
...<br/>
1674<br/>
911<br/>
52<br/>
1123<br/>
1483<br/>
1569<br/>
<b>features</b><br/>
<b>learning in robots</b><br/>
1039<br/>
In many domains, an appropriate&#160;<br/>
<b>Evaluation and selection of&#160;</b><br/>
Evolutionary learning methods&#160;<br/>
1695<br/>
1354<br/>
603<br/>
inductive bias is the MIN-<br/>
<b>biases in machine learning</b><br/>
have been found to be useful in&#160;<br/>
1680<br/>
1207<br/>
FEATURES bias, which prefers&#160;<br/>
In this introduction, we define the&#160;<br/>
several areas in the development&#160;<br/>
288<br/>
1040<br/>
consistent hypotheses definable&#160;<br/>
term bias as it is used in machine&#160;<br/>
of intelligent robots. In the&#160;<br/>
1355<br/>
1047<br/>
1465<br/>
136<br/>
over as few features as&#160;<br/>
learning systems. We motivate&#160;<br/>
approach described here,&#160;<br/>
75<br/>
1089<br/>
478<br/>
1010<br/>
1420<br/>
possible...<br/>
the importance of automated&#160;<br/>
evolutionary...<br/>
1348<br/>
methods for evaluating...<br/>
479<br/>
585<br/>
806<br/>
2122<br/>
227<br/>
1651<br/>
1345<br/>
92<br/>
1061<br/>
692<br/>
<b>Using a genetic algorithm to&#160;</b><br/>
<b>...</b><br/>
396<br/>
218<br/>
178<br/>
2299<br/>
960<br/>
378<br/>
<b>learn strategies for collision&#160;</b><br/>
1854<br/>
1578<br/>
2291<br/>
<b>...</b><br/>
1344<br/>
286<br/>
<b>avoidance and local&#160;</b><br/>
418<br/>
1539<br/>
1963<br/>
649<br/>
449<br/>
1138<br/>
303<br/>
335<br/>
<b>navigation</b><br/>
1855<br/>
...<br/>
2042<br/>
2290<br/>
<b>Improving tactical plans with&#160;</b><br/>
Navigation through obstacles&#160;<br/>
1290<br/>
1678<br/>
147<br/>
2300<br/>
1627<br/>
1275<br/>
...<br/>
<b>genetic algorithms</b><br/>
such as mine fields is an&#160;<br/>
2195<br/>
1121<br/>
2636<br/>
2091<br/>
1027<br/>
1238<br/>
The problem of learning decision&#160;<br/>
important capability for&#160;<br/>
2447<br/>
rules for sequential tasks is&#160;<br/>
autonomous underwater vehicles.&#160;<br/>
1644<br/>
344<br/>
2583<br/>
2012<br/>
addressed, focusing on the&#160;<br/>
One way to produce robust&#160;<br/>
2438<br/>
426<br/>
problem of learning tactical plans&#160;<br/>
behavior...<br/>
from a simple flight simulator&#160;<br/>
1244<br/>
where a plane must avoid a&#160;<br/>
2617<br/>
missile...<br/>
2213<br/>
1234<br/>
1944<br/>
•&#160;Research&#160;has&#160;focused&#160;on&#160;finding&#160;communities&#160;and&#160;patterns&#160;in&#160;the<br/>
link-structure&#160;of&#160;these&#160;networks&#160;(Kemp&#160;et&#160;al.&#160;2004,&#160;Hoff&#160;et&#160;al.,<br/>2002,&#160;Hofman&#160;and&#160;Wiggins&#160;2007,&#160;Airoldi&#160;et&#160;al.&#160;2008).<br/>
•&#160;By&#160;adapting&#160;supervised&#160;topic&#160;modeling,&#160;we&#160;can&#160;build&#160;a&#160;good&#160;model<br/>
of&#160;content&#160;and&#160;structure.<br/>
•&#160;RTMs&#160;find&#160;related&#160;hidden&#160;structure&#160;in&#160;both&#160;types&#160;of&#160;data.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=73></a>Relational&#160;topic&#160;models<br/>
α<br/>
θ<br/>
θ<br/>
d<br/>
η<br/>
d'<br/>
z<br/>
y<br/>
z<br/>
d,n<br/>
d,d'<br/>
d',n<br/>
w<br/>
β<br/>
w<br/>
d,n<br/>
k<br/>
d',n<br/>
N<br/>
N<br/>
d<br/>
K<br/>
d'<br/>
•&#160;Binary&#160;response&#160;variable&#160;with&#160;each&#160;pair&#160;of&#160;documents<br/>
•&#160;Adapt&#160;variational&#160;EM&#160;algorithm&#160;for&#160;sLDA&#160;with&#160;binary&#160;GLM&#160;response<br/>
model&#160;(with&#160;different&#160;link&#160;probability&#160;functions).<br/>
•&#160;Allows&#160;predictions&#160;that&#160;are&#160;out&#160;of&#160;reach&#160;for&#160;traditional&#160;models.<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=74></a>Predictive&#160;performance&#160;of&#160;one&#160;type&#160;given&#160;the&#160;other<br/>
RTM,&#160;!&#34;<br/>
Mixed!Membership<br/>
RTM,&#160;!e<br/>
Unigram/Bernoulli<br/>
<b>Cora</b><br/>
LDA + Regression &#160; &#160; &#160;&#160;<br/>
<b>Cora</b><br/>
3450<br/>
13000<br/>
!<br/>
!<br/>
3500<br/>!<br/>
13500<br/>!<br/>
<b>Link Log Likelihood</b><br/>
3550<br/>
<b>Word Log Likelihood</b><br/>
!<br/>
14000<br/>!<br/>
3600<br/>!<br/>
5<br/>
10<br/>
15<br/>
20<br/>
25<br/>
5<br/>
10<br/>
15<br/>
20<br/>
25<br/>
<b>Number of topics</b><br/>
<b>Number of topics</b><br/>
Cora&#160;corpus&#160;(McCallum&#160;et&#160;al.,&#160;2000)<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=75></a>Predictive&#160;performance&#160;of&#160;one&#160;type&#160;given&#160;the&#160;other<br/>
RTM,&#160;!&#34;<br/>
Mixed!Membership<br/>
RTM,&#160;!e<br/>
Unigram/Bernoulli<br/>
<b>WebKB</b><br/>
LDA + Regression &#160; &#160; &#160;&#160;<br/>
<b>WebKB</b><br/>
1130<br/>
3200<br/>
!<br/>
!<br/>
1135<br/>
3250<br/>
!<br/>
!<br/>
1140<br/>
<b>Link Log Likelihood</b><br/>
3300<br/>
!<br/>
!<br/>
<b>Word Log Likelihood</b><br/>
1145<br/>!<br/>
3350<br/>!<br/>
5<br/>
10<br/>
15<br/>
20<br/>
25<br/>
5<br/>
10<br/>
15<br/>
20<br/>
25<br/>
<b>Number of topics</b><br/>
<b>Number of topics</b><br/>
WebKB&#160;corpus&#160;(Craven&#160;et&#160;al.,&#160;1998)<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=76></a>Predictive&#160;performance&#160;of&#160;one&#160;type&#160;given&#160;the&#160;other<br/>
RTM,&#160;!&#34;<br/>
Mixed!Membership<br/>
RTM,&#160;!e<br/>
Unigram/Bernoulli<br/>
<b>PNAS</b><br/>
LDA + Regression &#160; &#160; &#160;&#160;<br/>
<b>PNAS</b><br/>
4450<br/>!<br/>
2940<br/>
4500<br/>
!<br/>
!<br/>
4550<br/>!<br/>
2950<br/>!<br/>
4600<br/>!<br/>
<b>Link Log Likelihood</b><br/>
2960<br/>
4650<br/>
!<br/>
!<br/>
<b>Word Log Likelihood</b><br/>
4700<br/>!<br/>
2970<br/>!<br/>
4750<br/>!<br/>
5<br/>
10<br/>
15<br/>
20<br/>
25<br/>
5<br/>
10<br/>
15<br/>
20<br/>
25<br/>
<b>Number of topics</b><br/>
<b>Number of topics</b><br/>
PNAS&#160;corpus&#160;(courtesy&#160;of&#160;JSTOR)<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=77></a>16<br/>
J.&#160;CHANG&#160;AND&#160;D.&#160;BLEI<br/>
Table&#160;2<br/>
Top&#160;eight&#160;link&#160;predictions&#160;made&#160;by&#160;RTM&#160;(ψe)&#160;and&#160;LDA&#160;+&#160;Regression&#160;for&#160;two&#160;documents<br/>
(italicized)&#160;from&#160;Cora.&#160;The&#160;models&#160;were&#160;fit&#160;with&#160;10&#160;topics.&#160;Boldfaced&#160;titles&#160;indicate&#160;actual<br/>
Predicting<br/>
documents&#160;links<br/>
cited&#160;by&#160;from<br/>
or&#160;citing&#160;do<br/>
each&#160;cuments<br/>
document.&#160;Over&#160;the&#160;whole&#160;corpus,&#160;RTM&#160;improves<br/>
precision&#160;over&#160;LDA&#160;+&#160;Regression&#160;by&#160;80%&#160;when&#160;evaluated&#160;on&#160;the&#160;first&#160;20&#160;documents<br/>
retrieved.<br/>
Markov&#160;chain&#160;Monte&#160;Carlo&#160;convergence&#160;diagnostics:&#160;A&#160;comparative&#160;review<br/>
Minorization&#160;conditions&#160;and&#160;convergence&#160;rates&#160;for&#160;Markov&#160;chain&#160;Monte&#160;Carlo<br/>
Rates&#160;of&#160;convergence&#160;of&#160;the&#160;Hastings&#160;and&#160;Metropolis&#160;algorithms<br/>
R<br/>TM<br/>
Possible&#160;biases&#160;induced&#160;by&#160;MCMC&#160;convergence&#160;diagnostics<br/>
Bounding&#160;convergence&#160;time&#160;of&#160;the&#160;Gibbs&#160;sampler&#160;in&#160;Bayesian&#160;image&#160;restoration<br/>
(<br/>
Self&#160;regenerative&#160;Markov&#160;chain&#160;Monte&#160;Carlo<br/>
ψe)<br/>
Auxiliary&#160;variable&#160;methods&#160;for&#160;Markov&#160;chain&#160;Monte&#160;Carlo&#160;with&#160;applications<br/>
Rate&#160;of&#160;Convergence&#160;of&#160;the&#160;Gibbs&#160;Sampler&#160;by&#160;Gaussian&#160;Approximation<br/>
Diagnosing&#160;convergence&#160;of&#160;Markov&#160;chain&#160;Monte&#160;Carlo&#160;algorithms<br/>
Exact&#160;Bound&#160;for&#160;the&#160;Convergence&#160;of&#160;Metropolis&#160;Chains<br/>
LD<br/>
Self&#160;regenerative&#160;Markov&#160;chain&#160;Monte&#160;Carlo<br/>
A<br/>
Minorization&#160;conditions&#160;and&#160;convergence&#160;rates&#160;for&#160;Markov&#160;chain&#160;Monte&#160;Carlo<br/>
+<br/>
Gibbs-markov&#160;models<br/>
Regress<br/>
Auxiliary&#160;variable&#160;methods&#160;for&#160;Markov&#160;chain&#160;Monte&#160;Carlo&#160;with&#160;applications<br/>
Markov&#160;Chain&#160;Monte&#160;Carlo&#160;Model&#160;Determination&#160;for&#160;Hierarchical&#160;and&#160;Graphical&#160;Models<br/>
Mediating&#160;instrumental&#160;variables<br/>
ion<br/>
A&#160;qualitative&#160;framework&#160;for&#160;probabilistic&#160;inference<br/>
Adaptation&#160;for&#160;Self&#160;Regenerative&#160;MCMC<br/>
Competitive&#160;environments&#160;evolve&#160;better&#160;solutions&#160;for&#160;complex&#160;tasks<br/>
Coevolving&#160;High&#160;Level&#160;Representations<br/>
Given&#160;a&#160;new&#160;document,&#160;which&#160;documents&#160;is&#160;it&#160;likely&#160;to&#160;link&#160;to?<br/>
A&#160;Survey&#160;of&#160;Evolutionary&#160;Strategies<br/>
R<br/>TM<br/>
Genetic&#160;Algorithms&#160;in&#160;Search,&#160;Optimization&#160;and&#160;Machine&#160;Learning<br/>
Strongly&#160;typed&#160;genetic&#160;programming&#160;in&#160;evolving&#160;cooperation&#160;strategies<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
(<br/>
Solving&#160;combinatorial&#160;problems&#160;usi<a href="Blei_1s.html#1">ng&#160;evolutionary&#160;</a>algorithms<br/>
ψe)<br/>
A&#160;promising&#160;genetic&#160;algorithm&#160;approach&#160;to&#160;job-shop&#160;scheduling.&#160;.&#160;.<br/>
Evolutionary&#160;Module&#160;Acquisition<br/>
An&#160;Empirical&#160;Investigation&#160;of&#160;Multi-Parent&#160;Recombination&#160;Operators.&#160;.&#160;.<br/>
LD<br/>
A&#160;New&#160;Algorithm&#160;for&#160;DNA&#160;Sequence&#160;Assembly<br/>
A<br/>
Identification&#160;of&#160;protein&#160;coding&#160;regions&#160;in&#160;genomic&#160;DNA<br/>
+<br/>
Solving&#160;combinatorial&#160;problems&#160;using&#160;evolutionary&#160;algorithms<br/>
Regress<br/>
A&#160;promising&#160;genetic&#160;algorithm&#160;approach&#160;to&#160;job-shop&#160;scheduling.&#160;.&#160;.<br/>
A&#160;genetic&#160;algorithm&#160;for&#160;passive&#160;management<br/>
The&#160;Performance&#160;of&#160;a&#160;Genetic&#160;Algorithm&#160;on&#160;a&#160;Chaotic&#160;Objective&#160;Function<br/>
ion<br/>
Adaptive&#160;global&#160;optimization&#160;with&#160;local&#160;search<br/>
Mutation&#160;rates&#160;as&#160;adaptations<br/>
Table&#160;2&#160;illustrates&#160;suggested&#160;citations&#160;using&#160;RTM&#160;(ψe)&#160;and&#160;LDA&#160;+&#160;Regres-<br/>
sion&#160;as&#160;predictive&#160;models.&#160;These&#160;suggestions&#160;were&#160;computed&#160;from&#160;a&#160;model&#160;fit<br/>on&#160;one&#160;of&#160;the&#160;folds&#160;of&#160;the&#160;Cora&#160;data.&#160;The&#160;top&#160;results&#160;illustrate&#160;suggested&#160;links<br/>for&#160;“Markov&#160;chain&#160;Monte&#160;Carlo&#160;convergence&#160;diagnostics:&#160;A&#160;comparative&#160;re-<br/>
<hr/>
<a name=78></a>16<br/>
J.&#160;CHANG&#160;AND&#160;D.&#160;BLEI<br/>
Table&#160;2<br/>
Top&#160;eight&#160;link&#160;predictions&#160;made&#160;by&#160;RTM&#160;(ψe)&#160;and&#160;LDA&#160;+&#160;Regression&#160;for&#160;two&#160;documents<br/>
(italicized)&#160;from&#160;Cora.&#160;The&#160;models&#160;were&#160;fit&#160;with&#160;10&#160;topics.&#160;Boldfaced&#160;titles&#160;indicate&#160;actual<br/>
documents&#160;cited&#160;by&#160;or&#160;citing&#160;each&#160;document.&#160;Over&#160;the&#160;whole&#160;corpus,&#160;RTM&#160;improves<br/>
precision&#160;over&#160;LDA&#160;+&#160;Regression&#160;by&#160;80%&#160;when&#160;evaluated&#160;on&#160;the&#160;first&#160;20&#160;documents<br/>
retrieved.<br/>
Markov&#160;chain&#160;Monte&#160;Carlo&#160;convergence&#160;diagnostics:&#160;A&#160;comparative&#160;review<br/>
Minorization&#160;conditions&#160;and&#160;convergence&#160;rates&#160;for&#160;Markov&#160;chain&#160;Monte&#160;Carlo<br/>
Rates&#160;of&#160;convergence&#160;of&#160;the&#160;Hastings&#160;and&#160;Metropolis&#160;algorithms<br/>
R<br/>TM<br/>
Possible&#160;biases&#160;induced&#160;by&#160;MCMC&#160;convergence&#160;diagnostics<br/>
Bounding&#160;convergence&#160;time&#160;of&#160;the&#160;Gibbs&#160;sampler&#160;in&#160;Bayesian&#160;image&#160;restoration<br/>
(<br/>
Self&#160;regenerative&#160;Markov&#160;chain&#160;Monte&#160;Carlo<br/>
ψe)<br/>
Auxiliary&#160;variable&#160;methods&#160;for&#160;Markov&#160;chain&#160;Monte&#160;Carlo&#160;with&#160;applications<br/>
Rate&#160;of&#160;Convergence&#160;of&#160;the&#160;Gibbs&#160;Sampler&#160;by&#160;Gaussian&#160;Approximation<br/>
Diagnosing&#160;convergence&#160;of&#160;Markov&#160;chain&#160;Monte&#160;Carlo&#160;algorithms<br/>
Exact&#160;Bound&#160;for&#160;the&#160;Convergence&#160;of&#160;Metropolis&#160;Chains<br/>
LD<br/>
Self&#160;regenerative&#160;Markov&#160;chain&#160;Monte&#160;Carlo<br/>
A<br/>
Minorization&#160;conditions&#160;and&#160;convergence&#160;rates&#160;for&#160;Markov&#160;chain&#160;Monte&#160;Carlo<br/>
+<br/>
Gibbs-markov&#160;models<br/>
Regress<br/>
Auxiliary&#160;variable&#160;methods&#160;for&#160;Markov&#160;chain&#160;Monte&#160;Carlo&#160;with&#160;applications<br/>
Markov&#160;Chain&#160;Monte&#160;Carlo&#160;Model&#160;Determination&#160;for&#160;Hierarchical&#160;and&#160;Graphical&#160;Models<br/>
Mediating&#160;instrumental&#160;variables<br/>
ion<br/>
A&#160;qualitative&#160;framework&#160;for&#160;probabilistic&#160;inference<br/>
Predicting&#160;links&#160;from&#160;do<br/>
Adaptation&#160;cuments<br/>
for&#160;Self&#160;Regenerative&#160;MCMC<br/>
Competitive&#160;environments&#160;evolve&#160;better&#160;solutions&#160;for&#160;complex&#160;tasks<br/>
Coevolving&#160;High&#160;Level&#160;Representations<br/>
A&#160;Survey&#160;of&#160;Evolutionary&#160;Strategies<br/>
R<br/>TM<br/>
Genetic&#160;Algorithms&#160;in&#160;Search,&#160;Optimization&#160;and&#160;Machine&#160;Learning<br/>
Strongly&#160;typed&#160;genetic&#160;programming&#160;in&#160;evolving&#160;cooperation&#160;strategies<br/>
(<br/>
Solving&#160;combinatorial&#160;problems&#160;using&#160;evolutionary&#160;algorithms<br/>
ψe)<br/>
A&#160;promising&#160;genetic&#160;algorithm&#160;approach&#160;to&#160;job-shop&#160;scheduling.&#160;.&#160;.<br/>
Evolutionary&#160;Module&#160;Acquisition<br/>
An&#160;Empirical&#160;Investigation&#160;of&#160;Multi-Parent&#160;Recombination&#160;Operators.&#160;.&#160;.<br/>
LD<br/>
A&#160;New&#160;Algorithm&#160;for&#160;DNA&#160;Sequence&#160;Assembly<br/>
A<br/>
Identification&#160;of&#160;protein&#160;coding&#160;regions&#160;in&#160;genomic&#160;DNA<br/>
+<br/>
Solving&#160;combinatorial&#160;problems&#160;using&#160;evolutionary&#160;algorithms<br/>
Regress<br/>
A&#160;promising&#160;genetic&#160;algorithm&#160;approach&#160;to&#160;job-shop&#160;scheduling.&#160;.&#160;.<br/>
A&#160;genetic&#160;algorithm&#160;for&#160;passive&#160;management<br/>
The&#160;Performance&#160;of&#160;a&#160;Genetic&#160;Algorithm&#160;on&#160;a&#160;Chaotic&#160;Objective&#160;Function<br/>
ion<br/>
Adaptive&#160;global&#160;optimization&#160;with&#160;local&#160;search<br/>
Mutation&#160;rates&#160;as&#160;adaptations<br/>
Table&#160;2&#160;illus<br/>
Given&#160;a&#160;trate<br/>
new&#160;s&#160;sugges<br/>
do<br/>
ted<br/>
cument,&#160;citations<br/>
which<br/>
using<br/>
do<br/>
RTM<br/>
cuments<br/>
(<br/>
is&#160;ψe<br/>
it&#160;)&#160;and<br/>
likely&#160;LD<br/>
to&#160;A&#160;+<br/>
link&#160;Regres<br/>
to?<br/>
-<br/>
sion&#160;as&#160;predictive&#160;models.&#160;These&#160;suggestions&#160;were&#160;computed&#160;from&#160;a&#160;model&#160;fit<br/>on&#160;one&#160;of&#160;the&#160;folds&#160;of&#160;the&#160;Cora&#160;data.&#160;The&#160;top&#160;results&#160;illustrate&#160;suggested&#160;links<br/>for&#160;“Markov&#160;chain&#160;Monte&#160;Carlo&#160;con<br/>
D.<br/>
v<br/>
Blei&#160;<a href="Blei_1s.html#1">ergenc</a><br/>
<a href="Blei_1s.html#1">To</a><br/>
<a href="Blei_1s.html#1">e</a><br/>
<a href="Blei_1s.html#1">pic</a><br/>
<a href="Blei_1s.html#1">diagnos</a><br/>
<a href="Blei_1s.html#1">Models</a><br/>
tics:&#160;A&#160;comparative&#160;re-<br/>
<hr/>
<a name=79></a>18<br/>
J.&#160;CHANG&#160;AND&#160;D.&#160;BLEI<br/>
18<br/>
J.&#160;CHANG&#160;AND&#160;D.&#160;BLEI<br/>
18<br/>
J.&#160;CHANG&#160;AND&#160;D.&#160;BLEI<br/>
Topic 1<br/>
Topic 1<br/>
18<br/>
J.&#160;CHANG&#160;AND&#160;D.&#160;BLEI<br/>
Topic 1<br/>
Topic 1<br/>
Topic 1<br/>
Topic 1&#160;Topic 2<br/>
Topic 2<br/>
Spatially<br/>
18<br/>
consistent<br/>
J.&#160;CHANG<br/>
topics<br/>
AND&#160;D.&#160;BLEI<br/>
Topic 1<br/>
Topic 1<br/>
Topic 2<br/>
Topic 2<br/>
Topic 2<br/>
Topic 2&#160;Topic 3<br/>
Topic 3<br/>
Topic 1<br/>
Topic 1<br/>
Topic 2<br/>
Topic 2<br/>
Topic 3<br/>
Topic 3<br/>
Topic 3<br/>
Topic 3&#160;Topic 4<br/>
Topic 4<br/>
Topic 2<br/>
Topic 2<br/>
Topic 3<br/>
Topic 3<br/>
Topic 4<br/>
Topic 4<br/>
Topic 4<br/>
Topic 4&#160;Topic 5<br/>
Topic 5<br/>
Fig&#160;5.&#160;A&#160;comparison&#160;between&#160;RTM&#160;(left)&#160;and&#160;LDA&#160;(right)&#160;of&#160;topic&#160;distributions&#160;on&#160;local<br/>news&#160;data.&#160;Each&#160;color/row&#160;depicts&#160;a&#160;single&#160;topic.&#160;Each&#160;state’s&#160;color&#160;intensity&#160;indicates&#160;the<br/>
•&#160;For&#160;exploratory&#160;tasks,&#160;RTMs&#160;can&#160;be&#160;used&#160;to&#160;“guide”&#160;the&#160;topics<br/>
magnitude&#160;of&#160;that&#160;topic’s&#160;component.&#160;The&#160;corresponding&#160;words&#160;associated&#160;with&#160;each&#160;topic<br/>are&#160;given&#160;in&#160;Table&#160;3.&#160;Whereas&#160;LDA&#160;finds&#160;geographically&#160;diffuse&#160;topics,&#160;RTM,&#160;by&#160;modeling<br/>spatial&#160;connectivity,&#160;finds&#160;coherent&#160;regions.<br/>
•&#160;Documents&#160;are&#160;geographically-tagged&#160;news&#160;articles&#160;from&#160;Yahoo!<br/>
Links&#160;are&#160;the&#160;adjacency&#160;matrix&#160;of&#160;states<br/>
Topic 3<br/>
Topic 3<br/>
Topic 4<br/>
Topic 4<br/>
Topic 5<br/>
Topic 5<br/>
Topic 5<br/>
Topic 5<br/>
Fig&#160;5.&#160;A&#160;comparison&#160;between&#160;RTM&#160;(left)&#160;and&#160;LDA&#160;(right)&#160;of&#160;topic&#160;distributions&#160;on&#160;local<br/>
Fig&#160;5.&#160;A&#160;comparison&#160;between&#160;RTM&#160;(left)&#160;and&#160;LDA&#160;(right)&#160;of&#160;topic&#160;distributions&#160;on&#160;local<br/>
•&#160;RTM&#160;finds&#160;spatially&#160;consistent&#160;topics.<br/>
news&#160;data.&#160;Each&#160;color/row&#160;depicts&#160;a&#160;single&#160;topic.&#160;Each&#160;state’s&#160;color&#160;intensity&#160;indicates&#160;the<br/>
news&#160;data.&#160;Each&#160;color/row&#160;depicts&#160;a&#160;single&#160;<a href="Blei_1s.html#1">topic.&#160;Each&#160;state’s&#160;col</a>or&#160;intensity&#160;indicates&#160;the<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
magnitude&#160;of&#160;that&#160;topic’s&#160;component.&#160;The&#160;corresponding&#160;words&#160;associated&#160;with&#160;each&#160;topic<br/>
magnitude&#160;of&#160;that&#160;topic’s&#160;component.&#160;The&#160;corresponding&#160;words&#160;associated&#160;with&#160;each&#160;topic<br/>
are&#160;given&#160;in&#160;Table&#160;3.&#160;Whereas&#160;LDA&#160;finds&#160;geographically&#160;diffuse&#160;topics,&#160;RTM,&#160;by&#160;modeling<br/>
are&#160;given&#160;in&#160;Table&#160;3.&#160;Whereas&#160;LDA&#160;finds&#160;geographically&#160;diffuse&#160;topics,&#160;RTM,&#160;by&#160;modeling<br/>
spatial&#160;connectivity,&#160;finds&#160;coherent&#160;regions.<br/>
spatial&#160;connectivity,&#160;finds&#160;coherent&#160;regions.<br/>
Topic 4<br/>
Topic 4<br/>
Topic 5<br/>
Topic 5<br/>
Fig&#160;5.&#160;A&#160;comparison&#160;between&#160;RTM&#160;(left)&#160;and&#160;LDA&#160;(right)&#160;of&#160;topic&#160;distributions&#160;on&#160;local<br/>news&#160;data.&#160;Each&#160;color/row&#160;depicts&#160;a&#160;single&#160;topic.&#160;Each&#160;state’s&#160;color&#160;intensity&#160;indicates&#160;the<br/>magnitude&#160;of&#160;that&#160;topic’s&#160;component.&#160;The&#160;corresponding&#160;words&#160;associated&#160;with&#160;each&#160;topic<br/>are&#160;given&#160;in&#160;Table&#160;3.&#160;Whereas&#160;LDA&#160;finds&#160;geographically&#160;diffuse&#160;topics,&#160;RTM,&#160;by&#160;modeling<br/>spatial&#160;connectivity,&#160;finds&#160;coherent&#160;regions.<br/>
Topic 5<br/>
Topic 5<br/>
Fig&#160;5.&#160;A&#160;comparison&#160;between&#160;RTM&#160;(left)&#160;and&#160;LDA&#160;(right)&#160;of&#160;topic&#160;distributions&#160;on&#160;local<br/>news&#160;data.&#160;Each&#160;color/row&#160;depicts&#160;a&#160;single&#160;topic.&#160;Each&#160;state’s&#160;color&#160;intensity&#160;indicates&#160;the<br/>magnitude&#160;of&#160;that&#160;topic’s&#160;component.&#160;The&#160;corresponding&#160;words&#160;associated&#160;with&#160;each&#160;topic<br/>are&#160;given&#160;in&#160;Table&#160;3.&#160;Whereas&#160;LDA&#160;finds&#160;geographically&#160;diffuse&#160;topics,&#160;RTM,&#160;by&#160;modeling<br/>spatial&#160;connectivity,&#160;finds&#160;coherent&#160;regions.<br/>
<hr/>
<a name=80></a>Relational&#160;Topic&#160;Models<br/>
•&#160;Relational&#160;topic&#160;modeling&#160;allows&#160;us&#160;to&#160;analyze&#160;connected<br/>
documents,&#160;or&#160;other&#160;data&#160;for&#160;which&#160;the&#160;mixed-membership<br/>assumptions&#160;are&#160;appropriate.<br/>
•&#160;Traditional&#160;models&#160;cannot&#160;predict&#160;with&#160;new&#160;and&#160;unlinked&#160;data.<br/>
•&#160;RTMs&#160;allow&#160;for&#160;such&#160;predictions<br/>
•&#160;links&#160;given&#160;the&#160;new&#160;words&#160;of&#160;a&#160;document<br/>•&#160;words&#160;given&#160;the&#160;links&#160;of&#160;a&#160;new&#160;document<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
<a name=81></a><img src="./Blei_1-81_1.png"/><br/>
<img src="./Blei_1-81_2.png"/><br/>
<img src="./Blei_1-81_3.png"/><br/>
<img src="./Blei_1-81_4.png"/><br/>
<img src="./Blei_1-81_5.png"/><br/>
Used&#160;in&#160;exploratory&#160;tools&#160;of&#160;document&#160;collections<br/>
D.&#160;Blei<br/>
<a href="Blei_1s.html#1">Topic&#160;Models</a><br/>
<hr/>
</body>
</html>
