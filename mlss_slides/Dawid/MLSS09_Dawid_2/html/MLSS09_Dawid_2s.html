<!DOCTYPE html><html>
<head>
<title></title>
<style type="text/css">
<!--
.xflip {
    -moz-transform: scaleX(-1);
    -webkit-transform: scaleX(-1);
    -o-transform: scaleX(-1);
    transform: scaleX(-1);
    filter: fliph;
}
.yflip {
    -moz-transform: scaleY(-1);
    -webkit-transform: scaleY(-1);
    -o-transform: scaleY(-1);
    transform: scaleY(-1);
    filter: flipv;
}
.xyflip {
    -moz-transform: scaleX(-1) scaleY(-1);
    -webkit-transform: scaleX(-1) scaleY(-1);
    -o-transform: scaleX(-1) scaleY(-1);
    transform: scaleX(-1) scaleY(-1);
    filter: fliph + flipv;
}
-->
</style>
</head>
<body>
<a name=1></a>Statistical Causality<br/>
Philip Dawid<br/>
Statistical Laboratory<br/>
University of Cambridge<br/>
<hr/>
<a name=2></a>Statistical Causality<br/>
1.&#160;&#160;The Problems of Causal Inference<br/>
2.&#160;&#160;Formal Frameworks for Statistical Causality<br/>
3.&#160;&#160;Graphical Representations and Applications<br/>
4.&#160;&#160;Causal Discovery<br/>
<hr/>
<a name=3></a>3. Graphical Representations and&#160;<br/>
Applications<br/>
<hr/>
<a name=4></a>Graphical Representation<br/>
•&#160;&#160;Certain collections of CI properties can be&#160;<br/>
described and manipulated using a DAG&#160;<br/>representation<br/>
–&#160;<i>very far from complete</i><br/>
•&#160;&#160;Each CI property&#160;<i>is represented by&#160;</i>a&#160;<br/>
graphical separation property&#160;<br/>
–&#160;<i>d-separation</i><br/>
–&#160;<i>moralization</i><br/>
<hr/>
<a name=5></a><img src="./MLSS09_Dawid_2-5_1.png"/><br/>
<img src="./MLSS09_Dawid_2-5_2.png"/><br/>
Moralization: 1<br/>
<hr/>
<a name=6></a><img src="./MLSS09_Dawid_2-6_1.png"/><br/>
<img src="./MLSS09_Dawid_2-6_2.png"/><br/>
<img src="./MLSS09_Dawid_2-6_3.png"/><br/>
Moralization: 1<br/>
<hr/>
<a name=7></a><img src="./MLSS09_Dawid_2-7_1.png"/><br/>
<img src="./MLSS09_Dawid_2-7_2.png"/><br/>
<img src="./MLSS09_Dawid_2-7_3.png"/><br/>
Moralization: 2<br/>
<hr/>
<a name=8></a><img src="./MLSS09_Dawid_2-8_1.png"/><br/>
<img src="./MLSS09_Dawid_2-8_2.png"/><br/>
<img src="./MLSS09_Dawid_2-8_3.png"/><br/>
Moralization: 3<br/>
<hr/>
<a name=9></a><img src="./MLSS09_Dawid_2-9_1.png"/><br/>
Extended Conditional Independence<br/>
Distribution of&#160;<i>Y&#160;</i>|&#160;<i>T&#160;</i>the same in observational and&#160;<br/>experimental regimes:<br/>
<i>Y&#160;</i>| (<i>F&#160;</i>,&#160;<i>T</i>) &#160;does not depend on value of&#160;<i>F</i><br/>
<i>T&#160;</i><br/>
<i>T</i><br/>
Can express and manipulate using notation and&#160;<br/>theory of conditional independence:<br/>
(even though&#160;<i>F&#160;</i>is not random)&#160;<br/>
<i>T&#160;</i><br/>
<hr/>
<a name=10></a><img src="./MLSS09_Dawid_2-10_1.png"/><br/>
Augmented&#160;DAG<br/>
–&#160;with random variables and&#160;intervention variables<br/>
–&#160;<i>probabilistic (not functional) relationships</i><br/>
<i>F</i><br/>
<i>T</i><br/>
<i>Y</i><br/>
0/1/∅<br/>
<i>T</i><br/>
0/1<br/>
<i>T&#160;</i>|&#160;(<i>F&#160;</i>=&#160;∅)&#160;∼&#160;<i>P</i><br/>
<i>Y&#160;</i>|&#160;<i>T</i><br/>
<i>T&#160;</i><br/>
<i>T</i><br/>
&#160;<br/>
&#160;<br/>
&#160;<br/>
Absence&#160;of arrow&#160;<i>F&#160;</i>→&#160;<i>Y&#160;</i>expresses<br/>
<i>T</i><br/>
<hr/>
<a name=11></a><img src="./MLSS09_Dawid_2-11_1.png"/><br/>
<img src="./MLSS09_Dawid_2-11_2.png"/><br/>
Sufficient Covariate&#160;<br/>
“(un)confounder”<br/>
<i>U</i><br/>
<i>F</i><br/>
<i>T</i><br/>
<i>Y</i><br/>
<i>T</i><br/>
•&#160;&#160;Treatment assignment ignorable&#160;given&#160;<i>U</i><br/>
–&#160;(generally)&#160;<i>not&#160;</i>marginally ignorable<br/>
•&#160;&#160;If&#160;<i>U&#160;</i>is observed, can fit model (e.g. regression)&#160;<br/>
for dependence of&#160;<i>Y&#160;</i>on (<i>T,U</i>)<br/>
–&#160;causally meaningful &#160;<br/>
<hr/>
<a name=12></a><img src="./MLSS09_Dawid_2-12_1.png"/><br/>
<img src="./MLSS09_Dawid_2-12_2.png"/><br/>
<img src="./MLSS09_Dawid_2-12_3.png"/><br/>
<img src="./MLSS09_Dawid_2-12_4.png"/><br/>
<img src="./MLSS09_Dawid_2-12_5.png"/><br/>
<img src="./MLSS09_Dawid_2-12_6.png"/><br/>
<img src="./MLSS09_Dawid_2-12_7.png"/><br/>
<img src="./MLSS09_Dawid_2-12_8.png"/><br/>
<img src="./MLSS09_Dawid_2-12_9.png"/><br/>
<img src="./MLSS09_Dawid_2-12_10.png"/><br/>
<img src="./MLSS09_Dawid_2-12_11.png"/><br/>
<img src="./MLSS09_Dawid_2-12_12.png"/><br/>
<img src="./MLSS09_Dawid_2-12_13.png"/><br/>
<img src="./MLSS09_Dawid_2-12_14.png"/><br/>
<img src="./MLSS09_Dawid_2-12_15.png"/><br/>
<img src="./MLSS09_Dawid_2-12_16.png"/><br/>
<img src="./MLSS09_Dawid_2-12_17.png"/><br/>
<img src="./MLSS09_Dawid_2-12_18.png"/><br/>
<img src="./MLSS09_Dawid_2-12_19.png"/><br/>
Sufficient covariate&#160;<br/>
“(un)confounder”<br/>
Can estimate ACE:<br/>
(“back-door”&#160;formula)<br/>
Similarly, whole interventional distribution:<br/>
<hr/>
<a name=13></a><img src="./MLSS09_Dawid_2-13_1.png"/><br/>
<img src="./MLSS09_Dawid_2-13_2.png"/><br/>
<img src="./MLSS09_Dawid_2-13_3.png"/><br/>
Non-confounding<br/>
<i>U</i><br/>
<i>b</i><br/>
<i>a</i><br/>
<i>F</i><br/>
<i>T</i><br/>
<i>Y</i><br/>
<i>T</i><br/>
Treatment assignment ignorable&#160;given&#160;<i>U</i><br/>
Ignorable&#160;marginally&#160;if either&#160;<i>a&#160;</i>or&#160;<i>b&#160;</i>is absent:<br/>
<i>a</i><br/>
<i>b</i><br/>
“randomization”<br/>
“irrelevance”<br/>
–then need not even observe&#160;<i>U</i><br/>
<hr/>
<a name=14></a>Pearlian&#160;DAG<br/>
•&#160;&#160;Envisage intervention on every variable in the&#160;<br/>
system<br/>
•&#160;&#160;Augmented DAG model<br/>
–&#160;but with intervention indicators implicit<br/>
•&#160;&#160;Every arrow has a causal interpretation<br/>
<hr/>
<a name=15></a>Pearlian&#160;DAG<br/>
<i>A</i><br/>
<i>B</i><br/>
<i>C</i><br/>
<i>D</i><br/>
<i>E</i><br/>
<hr/>
<a name=16></a>Intervention DAG<br/>
<i>F</i><br/>
<i>A</i><br/>
<i>B</i><br/>
<i>F</i><br/>
<i>A</i><br/>
<i>B</i><br/>
<i>F</i><br/>
<i>C</i><br/>
<i>D</i><br/>
<i>F</i><br/>
<i>C</i><br/>
<i>D</i><br/>
<i>F</i><br/>
<i>E</i><br/>
<i>E</i><br/>
<hr/>
<a name=17></a><img src="./MLSS09_Dawid_2-17_1.png"/><br/>
<img src="./MLSS09_Dawid_2-17_2.png"/><br/>
<img src="./MLSS09_Dawid_2-17_3.png"/><br/>
Intervention DAG<br/>
<i>F</i><br/>
<i>A</i><br/>
<i>B</i><br/>
<i>F</i><br/>
<i>A</i><br/>
<i>B</i><br/>
<i>F</i><br/>
<i>C</i><br/>
<i>D</i><br/>
<i>F</i><br/>
<i>C</i><br/>
<i>D</i><br/>
<i>F</i><br/>
<i>E</i><br/>
<i>E</i><br/>
•&#160;&#160;<i>e.g.</i>,<br/>
•&#160;&#160;When&#160;<i>E&#160;</i>is not manipulated, its conditional&#160;<br/>
distribution, given its parents&#160;<i>C</i>,&#160;<i>D&#160;</i>is unaffected by&#160;<br/>the values of&#160;<i>A</i>,&#160;<i>B&#160;</i>and by whether or not any of the&#160;<br/>other variables is manipulated<br/>
–&#160;modular component<br/>
<hr/>
<a name=18></a><img src="./MLSS09_Dawid_2-18_1.png"/><br/>
<img src="./MLSS09_Dawid_2-18_2.png"/><br/>
<img src="./MLSS09_Dawid_2-18_3.png"/><br/>
<img src="./MLSS09_Dawid_2-18_4.png"/><br/>
<img src="./MLSS09_Dawid_2-18_5.png"/><br/>
<img src="./MLSS09_Dawid_2-18_6.png"/><br/>
<img src="./MLSS09_Dawid_2-18_7.png"/><br/>
<img src="./MLSS09_Dawid_2-18_8.png"/><br/>
<img src="./MLSS09_Dawid_2-18_9.png"/><br/>
<img src="./MLSS09_Dawid_2-18_10.png"/><br/>
<img src="./MLSS09_Dawid_2-18_11.png"/><br/>
<img src="./MLSS09_Dawid_2-18_12.png"/><br/>
<img src="./MLSS09_Dawid_2-18_13.png"/><br/>
More complex DAGs<br/>
<i>U</i><br/>
<i>L</i><br/>
(influence diagram)<br/>
<i>Y</i><br/>
By&#160;<i>d</i>-separation:<br/>
<i>A</i><br/>
<i>A</i><br/>
1<br/>
2<br/>
<br/>
&#160;= treatment strategy<br/>
(would fail if&#160;<i>e.g.&#160;U&#160;</i>→&#160;<i>Y</i>)<br/>
<hr/>
<a name=19></a><img src="./MLSS09_Dawid_2-19_1.png"/><br/>
<img src="./MLSS09_Dawid_2-19_2.png"/><br/>
<img src="./MLSS09_Dawid_2-19_3.png"/><br/>
Instrumental Variable<br/>
<i>W</i><br/>
<i>FX</i><br/>
<i>X</i><br/>
<i>Y</i><br/>
Linear model: &#160;E(<i>Y&#160;</i>|&#160;<i>X=x</i>,&#160;<i>W, F&#160;= x&#160;</i>) =&#160;<i>f</i>(<i>W)&#160;</i>+&#160;β&#160;<i>x</i><br/>
<i>X&#160;</i><br/>
&#160;<br/>
&#160;<br/>
So E(<i>Y&#160;</i>|&#160;<i>F&#160;= x</i>) = E{<i>f</i>(<i>W)&#160;</i>|&#160;<i>F&#160;= x</i>} +&#160;β&#160;<i>x</i><br/>
<i>X&#160;</i><br/>
<i>X&#160;</i><br/>
&#160;<br/>
&#160;<br/>
=&#160;α&#160;+&#160;β&#160;<i>x</i>&#160;&#160;&#160;<br/>
&#160;β&#160;is&#160;causal&#160;regression coefficient<br/>
&#160;<br/>
–&#160;but not estimable from observational data:<br/>
E(<i>Y&#160;</i>|&#160;<i>X</i>=<i>x</i>) = E{<i>f</i>(<i>W)&#160;</i>|&#160;<i>X&#160;=&#160;&#160;x</i>} +&#160;β&#160;<i>x</i><br/>
&#160;<br/>
&#160;<br/>
<hr/>
<a name=20></a><img src="./MLSS09_Dawid_2-20_1.png"/><br/>
<img src="./MLSS09_Dawid_2-20_2.png"/><br/>
<img src="./MLSS09_Dawid_2-20_3.png"/><br/>
<img src="./MLSS09_Dawid_2-20_4.png"/><br/>
<img src="./MLSS09_Dawid_2-20_5.png"/><br/>
<img src="./MLSS09_Dawid_2-20_6.png"/><br/>
<img src="./MLSS09_Dawid_2-20_7.png"/><br/>
<img src="./MLSS09_Dawid_2-20_8.png"/><br/>
<img src="./MLSS09_Dawid_2-20_9.png"/><br/>
<img src="./MLSS09_Dawid_2-20_10.png"/><br/>
Instrumental Variable<br/>
<i>W</i><br/>
<i>FX</i><br/>
<i>X</i><br/>
<i>Y</i><br/>
<i>Z</i><br/>
–so can now identify&#160;β<br/>
<hr/>
<a name=21></a>Discrete case<br/>
<i>W</i><br/>
<i>X</i>,&#160;<i>Y</i>,&#160;<i>Z&#160;</i>binary<br/>
<i>FX</i><br/>
<i>X</i><br/>
<i>Y</i><br/>
<i>Z</i><br/>
Can develop&#160;inequalities&#160;for ACE<br/>
E(<i>Y&#160;</i>|&#160;<i>F&#160;</i>= 1) –&#160;E(<i>Y&#160;</i>|&#160;<i>F&#160;</i>= 0)<br/>
<i>X&#160;</i><br/>
<i>X&#160;</i><br/>
&#160;<br/>
&#160;<br/>
in terms of estimable quantities<br/>
<hr/>
<a name=22></a><img src="./MLSS09_Dawid_2-22_1.png"/><br/>
<img src="./MLSS09_Dawid_2-22_2.png"/><br/>
Hypothesis Test<br/>
<i>W</i><br/>
<i>FX</i><br/>
<i>X</i><br/>
<i>Y</i><br/>
<i>Z</i><br/>
<hr/>
<a name=23></a><img src="./MLSS09_Dawid_2-23_1.png"/><br/>
<img src="./MLSS09_Dawid_2-23_2.png"/><br/>
<img src="./MLSS09_Dawid_2-23_3.png"/><br/>
<img src="./MLSS09_Dawid_2-23_4.png"/><br/>
Mendelian Randomisation<br/>
Does low serum cholesterol level&#160;<br/>
<i>W</i><br/>
increase the risk of cancer?&#160;<br/>
<i>FX</i><br/>
<i>X</i><br/>
<i>Y</i><br/>
<i>X&#160;</i><br/>
= serum&#160;<br/>
cholesterol<br/>
<i>Z</i><br/>
<i>Y&#160;</i><br/>
= cancer<br/>
<i>W&#160;</i><br/>
=&#160;<br/>
diet, smoking, hidden tumour,…<br/>
<i>Z&#160;</i><br/>
= APOE&#160;<br/>
gene<br/>
(E2 allele induces particularly low serum&#160;<br/>cholesterol)<br/>
<hr/>
<a name=24></a><img src="./MLSS09_Dawid_2-24_1.png"/><br/>
<img src="./MLSS09_Dawid_2-24_2.png"/><br/>
<img src="./MLSS09_Dawid_2-24_3.png"/><br/>
<img src="./MLSS09_Dawid_2-24_4.png"/><br/>
<img src="./MLSS09_Dawid_2-24_5.png"/><br/>
<img src="./MLSS09_Dawid_2-24_6.png"/><br/>
<img src="./MLSS09_Dawid_2-24_7.png"/><br/>
Equivalence<br/>
<i>W</i><br/>
<i>W</i><br/>
<i>F</i><br/>
<i>F</i><br/>
<i>X</i><br/>
<i>X</i><br/>
<i>Y</i><br/>
<i>X</i><br/>
<i>X</i><br/>
<i>Y</i><br/>
causal?<br/>
<i>U</i><br/>
<i>Z</i><br/>
<i>Z</i><br/>
<hr/>
<a name=25></a><img src="./MLSS09_Dawid_2-25_1.png"/><br/>
<img src="./MLSS09_Dawid_2-25_2.png"/><br/>
Non-equivalence<br/>
<i>W</i><br/>
<i>W</i><br/>
<i>F</i><br/>
<i>F</i><br/>
<i>X</i><br/>
<i>X</i><br/>
<i>Y</i><br/>
<i>X</i><br/>
<i>X</i><br/>
<i>Y</i><br/>
causal?<br/>
<i>U</i><br/>
<i>Z</i><br/>
<i>F</i><br/>
<i>F</i><br/>
<i>Z</i><br/>
<i>Z</i><br/>
<i>Z</i><br/>
<hr/>
<a name=26></a><img src="./MLSS09_Dawid_2-26_1.png"/><br/>
Can we identify a causal effect from&#160;<br/>
observational data?<br/>
•&#160;&#160;Model with domain and (explicit or implicit)&#160;<br/>
intervention variables, specified ECI properties<br/>
–&#160;e.g. augmented DAG, Pearlian DAG<br/>
•&#160;&#160;Observed variables&#160;V, unobserved variables&#160;U<br/>
•&#160;&#160;Can identify&#160;observational&#160;distribution over&#160;V<br/>
•&#160;&#160;Want to answer&#160;causal&#160;query, e.g.&#160;<i>p</i>(<i>y&#160;</i>|&#160;<i>F&#160;</i>=&#160;<i>x</i>)<br/>
<i>X&#160;&#160;</i>&#160;<br/>
–&#160;write as<br/>
•&#160;&#160;When/how can this be done?<br/>
<hr/>
<a name=27></a><img src="./MLSS09_Dawid_2-27_1.png"/><br/>
<img src="./MLSS09_Dawid_2-27_2.png"/><br/>
<img src="./MLSS09_Dawid_2-27_3.png"/><br/>
<img src="./MLSS09_Dawid_2-27_4.png"/><br/>
<img src="./MLSS09_Dawid_2-27_5.png"/><br/>
<img src="./MLSS09_Dawid_2-27_6.png"/><br/>
Example: “back-door formula”<br/>
<i>Z</i><br/>
<i>F</i><br/>
<i>X</i><br/>
<i>Y</i><br/>
<i>X</i><br/>
<hr/>
<a name=28></a><img src="./MLSS09_Dawid_2-28_1.png"/><br/>
<img src="./MLSS09_Dawid_2-28_2.png"/><br/>
<img src="./MLSS09_Dawid_2-28_3.png"/><br/>
Example: “back-door formula”<br/>
<i>Z</i><br/>
<i>Z</i><br/>
1<br/>
2<br/>
<i>Z</i><br/>
<i>Z</i><br/>
<i>Z</i><br/>
3<br/>
4<br/>
5<br/>
<i>F</i><br/>
<i>X</i><br/>
<i>Z</i><br/>
<i>Y</i><br/>
<i>X</i><br/>
6<br/>
Works for&#160;<i>Z&#160;</i>= (<i>Z&#160;</i>,&#160;<i>Z&#160;</i>), and also for&#160;<i>Z&#160;</i>= (<i>Z&#160;</i>,&#160;<i>Z&#160;</i>)<br/>
3&#160;<br/>
4&#160;<br/>
4&#160;<br/>
5&#160;<br/>
<hr/>
<a name=29></a><img src="./MLSS09_Dawid_2-29_1.png"/><br/>
<img src="./MLSS09_Dawid_2-29_2.png"/><br/>
<img src="./MLSS09_Dawid_2-29_3.png"/><br/>
<img src="./MLSS09_Dawid_2-29_4.png"/><br/>
<img src="./MLSS09_Dawid_2-29_5.png"/><br/>
<img src="./MLSS09_Dawid_2-29_6.png"/><br/>
<img src="./MLSS09_Dawid_2-29_7.png"/><br/>
<img src="./MLSS09_Dawid_2-29_8.png"/><br/>
<img src="./MLSS09_Dawid_2-29_9.png"/><br/>
<img src="./MLSS09_Dawid_2-29_10.png"/><br/>
Example: “front-door formula”<br/>
<i>U</i><br/>
<i>F</i><br/>
<i>X</i><br/>
<i>Z</i><br/>
<i>Y</i><br/>
<i>X</i><br/>
<hr/>
<a name=30></a><img src="./MLSS09_Dawid_2-30_1.png"/><br/>
<img src="./MLSS09_Dawid_2-30_2.png"/><br/>
<img src="./MLSS09_Dawid_2-30_3.png"/><br/>
<img src="./MLSS09_Dawid_2-30_4.png"/><br/>
<img src="./MLSS09_Dawid_2-30_5.png"/><br/>
<img src="./MLSS09_Dawid_2-30_6.png"/><br/>
<img src="./MLSS09_Dawid_2-30_7.png"/><br/>
<img src="./MLSS09_Dawid_2-30_8.png"/><br/>
<img src="./MLSS09_Dawid_2-30_9.png"/><br/>
<img src="./MLSS09_Dawid_2-30_10.png"/><br/>
<img src="./MLSS09_Dawid_2-30_11.png"/><br/>
<img src="./MLSS09_Dawid_2-30_12.png"/><br/>
<img src="./MLSS09_Dawid_2-30_13.png"/><br/>
<img src="./MLSS09_Dawid_2-30_14.png"/><br/>
<img src="./MLSS09_Dawid_2-30_15.png"/><br/>
<img src="./MLSS09_Dawid_2-30_16.png"/><br/>
<img src="./MLSS09_Dawid_2-30_17.png"/><br/>
<img src="./MLSS09_Dawid_2-30_18.png"/><br/>
<img src="./MLSS09_Dawid_2-30_19.png"/><br/>
<img src="./MLSS09_Dawid_2-30_20.png"/><br/>
<img src="./MLSS09_Dawid_2-30_21.png"/><br/>
<img src="./MLSS09_Dawid_2-30_22.png"/><br/>
<img src="./MLSS09_Dawid_2-30_23.png"/><br/>
<img src="./MLSS09_Dawid_2-30_24.png"/><br/>
<img src="./MLSS09_Dawid_2-30_25.png"/><br/>
<img src="./MLSS09_Dawid_2-30_26.png"/><br/>
<img src="./MLSS09_Dawid_2-30_27.png"/><br/>
<img src="./MLSS09_Dawid_2-30_28.png"/><br/>
<img src="./MLSS09_Dawid_2-30_29.png"/><br/>
<img src="./MLSS09_Dawid_2-30_30.png"/><br/>
<img src="./MLSS09_Dawid_2-30_31.png"/><br/>
<img src="./MLSS09_Dawid_2-30_32.png"/><br/>
<img src="./MLSS09_Dawid_2-30_33.png"/><br/>
<img src="./MLSS09_Dawid_2-30_34.png"/><br/>
<img src="./MLSS09_Dawid_2-30_35.png"/><br/>
<img src="./MLSS09_Dawid_2-30_36.png"/><br/>
<img src="./MLSS09_Dawid_2-30_37.png"/><br/>
<img src="./MLSS09_Dawid_2-30_38.png"/><br/>
<img src="./MLSS09_Dawid_2-30_39.png"/><br/>
<img src="./MLSS09_Dawid_2-30_40.png"/><br/>
<img src="./MLSS09_Dawid_2-30_41.png"/><br/>
<img src="./MLSS09_Dawid_2-30_42.png"/><br/>
<img src="./MLSS09_Dawid_2-30_43.png"/><br/>
<img src="./MLSS09_Dawid_2-30_44.png"/><br/>
<img src="./MLSS09_Dawid_2-30_45.png"/><br/>
<img src="./MLSS09_Dawid_2-30_46.png"/><br/>
<img src="./MLSS09_Dawid_2-30_47.png"/><br/>
<img src="./MLSS09_Dawid_2-30_48.png"/><br/>
<img src="./MLSS09_Dawid_2-30_49.png"/><br/>
<img src="./MLSS09_Dawid_2-30_50.png"/><br/>
<i>do</i>-calculus<br/>
<hr/>
<a name=31></a><img src="./MLSS09_Dawid_2-31_1.png"/><br/>
<i>do</i>-calculus<br/>
For a problem modelled by a Pearlian DAG, the&#160;<br/>
<i>do</i>-calculus is&#160;complete:<br/>
•&#160;&#160;We can tell whether a given causal effect is&#160;<br/>
computable (from the observational distribution)<br/>
•&#160;&#160;Any computable causal effect can be computed&#160;<br/>
by successive applications of rules 2 and 3<br/>
–&#160;together with probability calculus, and property&#160;<br/>
(delete dotted arrows)<br/>
•&#160;&#160;There exist &#160;algorithms to accomplish this<br/>
<hr/>
<a name=32></a>4. &#160;Causal Discovery<br/>
<hr/>
<a name=33></a>Probabilistic Causality<br/>
•&#160;&#160;<i>Intuitive concepts&#160;</i>of “cause”, “direct cause”,…<br/>
•&#160;&#160;Principle of the common cause:<br/>
<i>“Variables are independent, given their&#160;<br/>common causes”</i><br/>
•&#160;&#160;Assume&#160;<i>causal DAG&#160;</i>representation:&#160;<br/>
–&#160;direct causes of&#160;<i>V&#160;</i>are its DAG parents<br/>
–&#160;all “common causes”&#160;included<br/>
<hr/>
<a name=34></a>Probabilistic Causality<br/>
<b>CAUSAL MARKOV CONDITION</b><br/>
–&#160;The causal DAG also represents the&#160;observational&#160;<br/>
conditional independence&#160;properties of the&#160;<br/>variables<br/>
•&#160;WHEN??<br/>
•&#160;WHY??<br/>
•&#160;&#160;<b>CAUSAL FAITHFULNESS CONDITION</b><br/>
–&#160;No extra conditional independencies<br/>
•&#160;WHY??<br/>
<hr/>
<a name=35></a>Causal Discovery<br/>
•&#160;&#160;An attempt to learn causal relationships from&#160;<br/>
observational data<br/>
•&#160;&#160;Assume there is an underlying&#160;<i>causal DAG&#160;</i><br/>
(possibly including unobserved variables)&#160;<br/>satisfying the (faithful) Causal Markov Condition<br/>
•&#160;&#160;Use data to search for a DAG representing the&#160;<br/>
observational&#160;independencies<br/>
&#160;<i>model selection</i><br/>
•&#160;&#160;Give this a&#160;causal&#160;interpretation<br/>
<hr/>
<a name=36></a>Causal Discovery<br/>
Two main approaches:<br/>
•&#160;&#160;“Constraint-based”<br/>
–&#160;Qualitative<br/>
–&#160;Infer (patent or latent) conditional independencies&#160;<br/>
between variables<br/>
–&#160;Fit conforming DAG model(s)<br/>
•&#160;&#160;Statistical model selection<br/>
–&#160;Quantitative<br/>
–&#160;General approach, applied to DAG models<br/>
–&#160;Need not commit to one model (model uncertainty)<br/>
<hr/>
<a name=37></a>Constraint-Based Methods<br/>
(complete data)<br/>
•&#160;&#160;Identify/estimate conditional independencies&#160;<br/>
holding between observed variables<br/>
•&#160;&#160;Assume sought-for causal DAG does not&#160;<br/>
involve any variables other than those observed<br/>
<hr/>
<a name=38></a><img src="./MLSS09_Dawid_2-38_1.png"/><br/>
Wermuth-Lauritzen algorithm<br/>
•&#160;&#160;Assume variables are “causally ordered”&#160;<i>a&#160;</i><br/>
<i>priori</i>:&#160;<br/>
(<i>V&#160;</i>,&#160;<i>V&#160;</i>,…,&#160;<i>V&#160;</i>), s.t&#160;arrows can only go from lower to&#160;<br/>
1&#160;<br/>
2&#160;<br/>
<i>N&#160;</i><br/>
higher<br/>
•&#160;&#160;For each&#160;<i>i</i>, identify (smallest) subset&#160;<i>S&#160;</i>of&#160;<br/>
<i>i&#160;</i><br/>
<i>Vi</i>-1&#160;:= (<i>V&#160;</i>,&#160;<i>V&#160;</i>,…,&#160;<i>V&#160;</i>) such that<br/>
1&#160;<br/>
2&#160;<br/>
<i>i-</i>1&#160;<br/>
•&#160;&#160;Draw arrow from each member of&#160;<i>S&#160;</i>to&#160;<i>V</i><br/>
<i>i&#160;</i><br/>
<i>i</i><br/>
<hr/>
<a name=39></a><img src="./MLSS09_Dawid_2-39_1.png"/><br/>
<img src="./MLSS09_Dawid_2-39_2.png"/><br/>
SGS algorithm&#160;<br/>
(no prior ordering)<br/>
1.&#160;&#160;Start with complete undirected graph over&#160;<i>VN</i><br/>
2.&#160;&#160;Remove edges&#160;<i>V–W&#160;</i>s.t., for some&#160;<i>S</i>,&#160;<br/>
3.&#160;&#160;Orient any&#160;<i>V–Z–W&#160;</i>as&#160;<i>V</i>→<i>Z</i>←<i>W&#160;</i>if:<br/>
–&#160;&#160;no edge&#160;<i>V–W</i><br/>
–&#160;&#160;for each&#160;<i>S&#160;</i>⊆&#160;<i>VN &#160;</i>with&#160;<i>Z&#160;</i>∈&#160;<i>S</i>,&#160;<br/>
&#160;<br/>
&#160;<br/>
4.&#160;&#160;Repeat while still possible:<br/>
i.&#160;&#160;if&#160;<i>V</i>→<i>Z –W&#160;</i>but not&#160;<i>V–W</i>, orient as&#160;<i>V</i>→<i>Z&#160;</i>→<i>W<br/></i>ii.&#160;&#160;If&#160;<i>V</i>Ã<i>W&#160;</i>and&#160;<i>V–W</i>, orient as&#160;<i>V</i>→<i>W</i><br/>
<hr/>
<a name=40></a>Comments<br/>
•&#160;<br/>
Wermuth-Lauritzen algorithm<br/>
–&#160;&#160;always finds a valid DAG representation<br/>–&#160;&#160;need not be faithful<br/>–&#160;&#160;depends on prior ordering<br/>
•&#160;<br/>
SGS algorithm<br/>
–&#160;&#160;may not succeed if there is no faithful DAG&#160;<br/>
representation<br/>
–&#160;&#160;output may not be fully oriented<br/>–&#160;&#160;computationally inefficient (too many tests)<br/>–&#160;&#160;better variations: &#160;PC, PC*<br/>
<hr/>
<a name=41></a>Constraint-Based Methods&#160;<br/>
(incomplete data)<br/>
•&#160;&#160;Allow now for unobserved (latent) variables<br/>
•&#160;&#160;Can modify previous algorithms to work just&#160;<br/>
with conditional independencies between&#160;<br/>observed variables<br/>
•&#160;&#160;But latent CI has other (quantitative)&#160;<br/>
implications too…<br/>
<hr/>
<a name=42></a><img src="./MLSS09_Dawid_2-42_1.png"/><br/>
<img src="./MLSS09_Dawid_2-42_2.png"/><br/>
<img src="./MLSS09_Dawid_2-42_3.png"/><br/>
<img src="./MLSS09_Dawid_2-42_4.png"/><br/>
<img src="./MLSS09_Dawid_2-42_5.png"/><br/>
<img src="./MLSS09_Dawid_2-42_6.png"/><br/>
<img src="./MLSS09_Dawid_2-42_7.png"/><br/>
<img src="./MLSS09_Dawid_2-42_8.png"/><br/>
<img src="./MLSS09_Dawid_2-42_9.png"/><br/>
<img src="./MLSS09_Dawid_2-42_10.png"/><br/>
<img src="./MLSS09_Dawid_2-42_11.png"/><br/>
<img src="./MLSS09_Dawid_2-42_12.png"/><br/>
<img src="./MLSS09_Dawid_2-42_13.png"/><br/>
<img src="./MLSS09_Dawid_2-42_14.png"/><br/>
<img src="./MLSS09_Dawid_2-42_15.png"/><br/>
<img src="./MLSS09_Dawid_2-42_16.png"/><br/>
Discrete variables:<br/>
<i>U</i><br/>
<i>A</i><br/>
<i>B</i><br/>
<i>C</i><br/>
<i>D</i><br/>
No CI properties between observables&#160;<i>A</i>,&#160;<i>B</i>,&#160;<i>C</i>,&#160;<i>D</i>.<br/>
But<br/>
– does not depend on&#160;<i>a</i><br/>
<hr/>
<a name=43></a><img src="./MLSS09_Dawid_2-43_1.png"/><br/>
Normal variables:<br/>
<i>U</i><br/>
<i>X</i><br/>
<i>X</i><br/>
<i>X</i><br/>
<i>X</i><br/>
1<br/>
2<br/>
3<br/>
4<br/>
No CI properties between observables&#160;<i>X&#160;</i>,&#160;<i>X&#160;</i>,&#160;<i>X&#160;</i>,&#160;<i>X&#160;</i>.<br/>
1&#160;<br/>
2&#160;<br/>
3&#160;<br/>
4&#160;<br/>
But<br/>
Such properties form basis of TETRAD II program<br/>
<hr/>
<a name=44></a>Bayesian Model Selection<br/>
•&#160;&#160;Consider &#160;collection&#160;M&#160;= {<i>M</i>} of models<br/>•&#160;&#160;Have prior distribution&#160;&#160;(&#160;) for parameter&#160;<br/>
<i>M&#160;</i><br/>
<i>M&#160;</i><br/>
<i>M &#160;</i><br/>
of model&#160;<i>M</i><br/>
•&#160;&#160;Based on data&#160;<i><b>x</b></i>, compute&#160;<i>marginal likelihood&#160;</i>for&#160;<br/>
each model&#160;<i>M</i>:&#160;<br/>
<i>L&#160;</i>=&#160;∫&#160;<i>p</i>(<i><b>x&#160;&#160;</b></i>|&#160;&#160;) d<br/>
<i>M&#160;</i><br/>
<i>M&#160;</i><br/>
<i>M</i><br/>
&#160;<br/>
&#160;<br/>
•&#160;&#160;Use as score for comparing models, or combine&#160;<br/>
with prior distribution {<i>w&#160;</i>} over models to get&#160;<br/>
<i>M&#160;</i><br/>
posterior:<br/>
<i>w*&#160;</i>∝&#160;<i>w&#160;L</i><br/>
<i>M&#160;</i><br/>
<i>M&#160;</i><br/>
<i>M</i><br/>
&#160;<br/>
<hr/>
<a name=45></a>Bayesian Model Selection<br/>
•&#160;&#160;Algebraically straightforward for discrete or&#160;<br/>
Gaussian DAG models, parametrised&#160;by&#160;<br/>parent-child conditional distributions, having&#160;<br/>conjugate priors (with local and global&#160;<br/>independence)<br/>
&#160;Zoubin&#160;Ghahramani’s lectures<br/>
•&#160;&#160;Can arrange hyperparameters&#160;so that&#160;<br/>
indistinguishable (Markov equivalent) models&#160;<br/>get same score<br/>
<hr/>
<a name=46></a><img src="./MLSS09_Dawid_2-46_1.png"/><br/>
Mixed data<br/>
•&#160;&#160;Data from experimental and observational&#160;<br/>
regimes<br/>
•&#160;&#160;Model-selection approach:&#160;<br/>
–&#160;assume Pearlian DAG<br/>
–&#160;ignore local likelihood&#160;contribution when the&#160;<br/>
response variable is set<br/>
•&#160;&#160;Constraint-based approach? &#160;<br/>
–&#160;base on ECI properties, e.g.<br/>
<hr/>
<a name=47></a>A Parting Caution<br/>
•&#160;&#160;We have powerful statistical methods for&#160;<br/>
attacking causal problems<br/>
•&#160;&#160;But to apply them we have to make strong&#160;<br/>
assumptions (e.g. ECI assumptions, relating&#160;<br/>distinct regimes)<br/>
•&#160;&#160;Important to consider and justify these in&#160;<br/>
context<br/>
–&#160;<i>e.g.</i>, Mendelian&#160;randomisation<br/>
“NO CAUSES IN, NO CAUSES OUT”<br/>
<hr/>
<a name=48></a>Thank you!<br/>
<hr/>
<a name=49></a>Further Reading<br/>
•&#160;&#160;A. P. Dawid (2007). &#160;<i>Fundamentals of Statistical Causality</i>. &#160;<br/>
Research Report 279, Department of Statistical Science,&#160;<br/>University College London. &#160;94&#160;<i>pp.<br/></i><a href="http://www.ucl.ac.uk/Stats/research/reports/abs07.html#279">http://www.ucl.ac.uk/Stats/research/reports/abs07.html#279</a><br/>
•&#160;&#160;R. E. Neapolitan (2003).&#160;<i>Learning Bayesian Networks</i>. &#160;<br/>
Prentice Hall, Upper Saddle River, New Jersey.<br/>
•&#160;&#160;J. Pearl (2009).&#160;<i>Causality: Models, Reasoning and Inference&#160;</i><br/>
(second edition).&#160;&#160;Cambridge University Press.<br/>
•&#160;&#160;D. B. Rubin (1978). Bayesian inference for causal effects: the&#160;<br/>
role of randomization.&#160;<i>Annals of Statistics&#160;</i><b>6</b>, 34–68.<br/>
•&#160;&#160;P. Spirtes, C. Glymour, and R. Scheines&#160;(2000).&#160;<i>Causation,&#160;</i><br/>
<i>Prediction and Search&#160;</i>(second edition). &#160;Springer-Verlag,&#160;<br/>New York.<br/>
•&#160;&#160;P. Suppes&#160;(1970).&#160;<i>A Probabilistic Theory of Causality</i>. North&#160;<br/>
Holland, Amsterdam.<br/>
<hr/>
<a name="outline"></a><h1>Document Outline</h1>
<ul>
<li><a href="MLSS09_Dawid_2s.html#1">Statistical Causality</a></li>
<li><a href="MLSS09_Dawid_2s.html#2">Statistical Causality</a></li>
<li>1. The Problems of Causal Inference</li>
<li>Conceptions of Causality</li>
<li>Causal Queries</li>
<li>Causal Enquiry</li>
<li>Problems of observational studies</li>
<li>Problems of observational studies</li>
<li>Problems of observational studies</li>
<li>Problems of observational studies</li>
<li>Problems of observational studies</li>
<li>Simpson’s Paradox</li>
<li>Causal Inference</li>
<li>2. Formal Frameworks for Statistical Causality</li>
<li>Some Formal Frameworks</li>
<li>A SIMPLE (??) PROBLEM</li>
<li>Slide Number 19</li>
<li>Slide Number 20</li>
<li>Structural Model</li>
<li>Slide Number 22</li>
<li>General Functional Model</li>
<li>Slide Number 24</li>
<li>Potential Responses: Problems</li>
<li>Slide Number 26</li>
<li>OBSERVATIONAL STUDY</li>
<li>Slide Number 28</li>
<li>Slide Number 29</li>
<li>Slide Number 30</li>
<li>Slide Number 31</li>
<li>PR interpretation (U = Y)</li>
<li>Slide Number 33</li>
<li>Slide Number 34</li>
<li>Slide Number 35</li>
<li>Slide Number 36</li>
<li><a href="MLSS09_Dawid_2s.html#3">3. Graphical Representations and Applications</a></li>
<li><a href="MLSS09_Dawid_2s.html#4">Graphical Representation</a></li>
<li><a href="MLSS09_Dawid_2s.html#5">Moralization: 1</a></li>
<li><a href="MLSS09_Dawid_2s.html#6">Moralization: 1</a></li>
<li><a href="MLSS09_Dawid_2s.html#7">Moralization: 2</a></li>
<li><a href="MLSS09_Dawid_2s.html#8">Moralization: 3</a></li>
<li><a href="MLSS09_Dawid_2s.html#9">Slide Number 43</a></li>
<li><a href="MLSS09_Dawid_2s.html#10">Augmented DAG</a></li>
<li><a href="MLSS09_Dawid_2s.html#11">Sufficient Covariate“(un)confounder”</a></li>
<li><a href="MLSS09_Dawid_2s.html#12">Slide Number 47</a></li>
<li><a href="MLSS09_Dawid_2s.html#13">Non-confounding</a></li>
<li><a href="MLSS09_Dawid_2s.html#14">Pearlian DAG</a></li>
<li><a href="MLSS09_Dawid_2s.html#15">Slide Number 51</a></li>
<li><a href="MLSS09_Dawid_2s.html#16">Slide Number 52</a></li>
<li><a href="MLSS09_Dawid_2s.html#17">Slide Number 53</a></li>
<li><a href="MLSS09_Dawid_2s.html#18">More complex DAGs</a></li>
<li><a href="MLSS09_Dawid_2s.html#19">Instrumental Variable</a></li>
<li><a href="MLSS09_Dawid_2s.html#20">Instrumental Variable</a></li>
<li><a href="MLSS09_Dawid_2s.html#21">Discrete case</a></li>
<li><a href="MLSS09_Dawid_2s.html#22">Hypothesis Test</a></li>
<li><a href="MLSS09_Dawid_2s.html#23">Mendelian Randomisation</a></li>
<li><a href="MLSS09_Dawid_2s.html#24">Equivalence</a></li>
<li><a href="MLSS09_Dawid_2s.html#25">Non-equivalence</a></li>
<li><a href="MLSS09_Dawid_2s.html#26">Can we identify a causal effect from observational data?</a></li>
<li><a href="MLSS09_Dawid_2s.html#27">Example: “back-door formula”</a></li>
<li><a href="MLSS09_Dawid_2s.html#28">Example: “back-door formula”</a></li>
<li><a href="MLSS09_Dawid_2s.html#29">Example: “front-door formula”</a></li>
<li><a href="MLSS09_Dawid_2s.html#30">do-calculus</a></li>
<li><a href="MLSS09_Dawid_2s.html#31">Slide Number 68</a></li>
<li><a href="MLSS09_Dawid_2s.html#32">4. &#160;Causal Discovery</a></li>
<li><a href="MLSS09_Dawid_2s.html#33">Probabilistic Causality</a></li>
<li><a href="MLSS09_Dawid_2s.html#34">Probabilistic Causality</a></li>
<li><a href="MLSS09_Dawid_2s.html#35">Causal Discovery</a></li>
<li><a href="MLSS09_Dawid_2s.html#36">Causal Discovery</a></li>
<li><a href="MLSS09_Dawid_2s.html#37">Constraint-Based Methods</a></li>
<li><a href="MLSS09_Dawid_2s.html#38">Wermuth-Lauritzen algorithm</a></li>
<li><a href="MLSS09_Dawid_2s.html#39">SGS algorithm(no prior ordering)</a></li>
<li><a href="MLSS09_Dawid_2s.html#40">Comments</a></li>
<li><a href="MLSS09_Dawid_2s.html#41">Constraint-Based Methods(incomplete data)</a></li>
<li><a href="MLSS09_Dawid_2s.html#42">Slide Number 79</a></li>
<li><a href="MLSS09_Dawid_2s.html#43">Slide Number 80</a></li>
<li><a href="MLSS09_Dawid_2s.html#44">Bayesian Model Selection	</a></li>
<li><a href="MLSS09_Dawid_2s.html#45">Bayesian Model Selection	</a></li>
<li><a href="MLSS09_Dawid_2s.html#46">Mixed data</a></li>
<li><a href="MLSS09_Dawid_2s.html#47">A Parting Caution</a></li>
<li><a href="MLSS09_Dawid_2s.html#48">Thank you!</a></li>
<li><a href="MLSS09_Dawid_2s.html#49">Further Reading</a></li>
</ul>
<hr/>
</body>
</html>
