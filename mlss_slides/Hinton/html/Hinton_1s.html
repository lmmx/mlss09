<!DOCTYPE html><html>
<head>
<title></title>
<style type="text/css">
<!--
.xflip {
    -moz-transform: scaleX(-1);
    -webkit-transform: scaleX(-1);
    -o-transform: scaleX(-1);
    transform: scaleX(-1);
    filter: fliph;
}
.yflip {
    -moz-transform: scaleY(-1);
    -webkit-transform: scaleY(-1);
    -o-transform: scaleY(-1);
    transform: scaleY(-1);
    filter: flipv;
}
.xyflip {
    -moz-transform: scaleX(-1) scaleY(-1);
    -webkit-transform: scaleX(-1) scaleY(-1);
    -o-transform: scaleX(-1) scaleY(-1);
    transform: scaleX(-1) scaleY(-1);
    filter: fliph + flipv;
}
-->
</style>
</head>
<body>
<a name=1></a>MLSS&#160;Tutorial&#160;on:<br/>
Deep Belief Nets<br/>
(An&#160;updated&#160;and extended&#160;version&#160;of&#160;my&#160;2007&#160;NIPS tutorial)<br/>
Geoffrey&#160;Hinton<br/>
Canadian&#160;Institute&#160;for&#160;Advanced&#160;Research<br/>
&amp;<br/>
Department&#160;of Computer&#160;Science<br/>
University&#160;of Toronto<br/>
<hr/>
<a name=2></a>Some&#160;things you&#160;will learn in this tutorial<br/>
•&#160;How to learn&#160;multi-layer&#160;generative&#160;models&#160;of unlabelled&#160;<br/>
data&#160;by&#160;learning&#160;one&#160;layer&#160;of features at a time.<br/>
–&#160;How to&#160;add&#160;Markov&#160;Random&#160;Fields&#160;in&#160;each hidden&#160;layer.<br/>
•&#160;How to use generative&#160;models&#160;to make discriminative&#160;<br/>
training methods work&#160;much&#160;better&#160;for classification&#160;and&#160;<br/>regression.<br/>
–&#160;How to&#160;extend&#160;this approach&#160;to&#160;Gaussian&#160;Processes and&#160;<br/>
how&#160;to&#160;learn&#160;complex,&#160;&#160;domain-specific&#160;kernels&#160;for a&#160;<br/>Gaussian Process.<br/>
•&#160;How to perform non-linear&#160;dimensionality&#160;reduction&#160;on very&#160;<br/>
large datasets<br/>
–&#160;How to learn&#160;binary,&#160;low-dimensional&#160;codes&#160;and&#160;how&#160;to&#160;<br/>
use&#160;them for very fast&#160;document&#160;retrieval.<br/>
•&#160;How to learn&#160;multilayer&#160;generative&#160;models&#160;of high-<br/>
dimensional&#160;sequential&#160;data.<br/>
<hr/>
<a name=3></a>A&#160;spectrum&#160;of&#160;machine&#160;learning tasks<br/>
Typical&#160;Statistics------------Artificial&#160;Intelligence<br/>
•&#160;Low-dimensional&#160;data&#160;(e.g.&#160;<br/>
•&#160;High-dimensional&#160;data&#160;(e.g.&#160;<br/>
less&#160;than&#160;100&#160;dimensions)<br/>
more&#160;than&#160;100&#160;dimensions)<br/>
•&#160;The&#160;noise&#160;is not&#160;sufficient&#160;to&#160;<br/>
•&#160;Lots&#160;of&#160;noise&#160;in the&#160;data<br/>
obscure&#160;the&#160;structure&#160;in the&#160;<br/>data&#160;if&#160;we&#160;process&#160;it&#160;right.<br/>
•<br/>
•&#160;There&#160;is a&#160;huge&#160;amount&#160;of&#160;<br/>
There&#160;is not&#160;much&#160;structure&#160;in&#160;<br/>
structure&#160;in&#160;the&#160;data,&#160;but&#160;the&#160;<br/>
the&#160;data,&#160;and&#160;what&#160;structure&#160;<br/>
structure&#160;is&#160;too&#160;complicated&#160;to&#160;<br/>
there&#160;is,&#160;can&#160;be&#160;represented&#160;by&#160;<br/>
be&#160;represented&#160;by&#160;a&#160;simple&#160;<br/>
a&#160;fairly&#160;simple&#160;model.<br/>
model.<br/>
•&#160;The&#160;main problem&#160;is&#160;figuring&#160;<br/>
•&#160;The&#160;main problem&#160;is&#160;<br/>
out&#160;a way&#160;to&#160;represent&#160;the&#160;<br/>
distinguishing&#160;true&#160;structure&#160;<br/>
complicated&#160;structure&#160;so&#160;that&#160;it&#160;<br/>
from&#160;noise.<br/>
can&#160;be&#160;learned.<br/>
<hr/>
<a name=4></a>Historical&#160;background:<br/>
First&#160;generation&#160;neural&#160;networks<br/>
•&#160;Perceptrons&#160;(~1960)&#160;<br/>
Bomb<br/>
Toy<br/>
output&#160;units&#160;&#160;<br/>
used a&#160;layer&#160;of&#160;hand-<br/>
e.g.&#160;class&#160;labels<br/>
coded features and&#160;tried&#160;<br/>to&#160;recognize&#160;objects by&#160;<br/>learning&#160;how&#160;to weight&#160;<br/>these&#160;features.<br/>
non-adaptive<br/>
–&#160;There&#160;was&#160;a&#160;neat&#160;<br/>
hand-coded<br/>features<br/>
learning&#160;algorithm&#160;for&#160;<br/>adjusting the weights.<br/>
–&#160;But&#160;perceptrons&#160;are&#160;<br/>
input&#160;units&#160;<br/>
fundamentally&#160;limited&#160;<br/>
e.g.&#160;pixels<br/>
in&#160;what&#160;they&#160;can learn&#160;<br/>to&#160;do.<br/>
Sketch of a&#160;typical&#160;<br/>perceptron from the&#160;1960’s<br/>
<hr/>
<a name=5></a>Second&#160;generation&#160;neural networks&#160;(~1985)<br/>
Compare&#160;outputs&#160;with&#160;<br/>
Back-propagate&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160;&#160;<br/>
co&#160;&#160;&#160;<br/>
rrect&#160;answer&#160;to&#160;get&#160;<br/>
error&#160;signal&#160;to&#160;<br/>
error&#160;signal<br/>
get&#160;derivatives&#160;<br/>for&#160;learning<br/>
outputs<br/>
hidden&#160;<br/>layers<br/>
input&#160;vector<br/>
<hr/>
<a name=6></a>A&#160;temporary&#160;digression<br/>
•&#160;Vapnik&#160;and&#160;his&#160;co-workers developed&#160;a very clever&#160;type&#160;<br/>
of&#160;perceptron called&#160;a&#160;Support&#160;Vector&#160;Machine.<br/>
–&#160;Instead&#160;of hand-coding&#160;the&#160;layer&#160;of&#160;non-adaptive&#160;<br/>
features,&#160;each&#160;training&#160;example&#160;is used&#160;to&#160;create a&#160;<br/>new&#160;feature using&#160;a fixed&#160;recipe.<br/>
•&#160;The&#160;feature&#160;computes&#160;how&#160;similar&#160;a&#160;test&#160;example&#160;is to&#160;that&#160;<br/>
training&#160;example.&#160;<br/>
–&#160;Then&#160;a clever&#160;optimization&#160;technique&#160;is used&#160;to&#160;select&#160;<br/>
the&#160;best subset of&#160;the features and to decide&#160;how&#160;to&#160;<br/>weight each&#160;feature&#160;when&#160;classifying&#160;a&#160;test&#160;case.<br/>
•&#160;But&#160;its&#160;just&#160;a&#160;perceptron&#160;and&#160;has&#160;all&#160;the&#160;same&#160;limitations.<br/>
•&#160;In&#160;the&#160;1990’s,&#160;many researchers&#160;abandoned&#160;neural&#160;<br/>
networks&#160;with&#160;multiple&#160;adaptive&#160;hidden&#160;layers&#160;because&#160;<br/>Support Vector Machines&#160;worked&#160;better.<br/>
<hr/>
<a name=7></a>What&#160;is wrong&#160;with back-propagation?<br/>
•&#160;It&#160;requires&#160;labeled training&#160;data.<br/>
–&#160;Almost&#160;all&#160;data&#160;is unlabeled.<br/>
•&#160;The&#160;learning time&#160;does&#160;not scale&#160;well<br/>
–&#160;It&#160;is very&#160;slow&#160;in&#160;networks&#160;with&#160;multiple&#160;<br/>
hidden&#160;layers.<br/>
•&#160;It&#160;can&#160;get stuck&#160;in&#160;poor&#160;local&#160;optima.<br/>
–&#160;These&#160;are&#160;often&#160;quite&#160;good,&#160;but for&#160;deep&#160;<br/>
nets&#160;they are far&#160;from&#160;optimal.<br/>
<hr/>
<a name=8></a>Overcoming&#160;the limitations&#160;of &#160;back-<br/>
propagation<br/>
•&#160;Keep&#160;the&#160;efficiency and&#160;simplicity&#160;of&#160;using a&#160;<br/>
gradient method&#160;for&#160;adjusting the&#160;weights, but&#160;use&#160;<br/>it&#160;for&#160;modeling&#160;the&#160;structure of the&#160;sensory&#160;input.<br/>
–&#160;Adjust&#160;the&#160;weights&#160;to&#160;maximize&#160;the&#160;probability&#160;<br/>
that&#160;a generative&#160;model&#160;would&#160;have produced&#160;<br/>the&#160;sensory input.&#160;<br/>
–&#160;Learn&#160;p(image)&#160;not &#160;p(label&#160;| image)<br/>
•&#160;If&#160;you&#160;want&#160;to&#160;do&#160;computer&#160;vision,&#160;first&#160;learn&#160;<br/>
computer graphics<br/>
•&#160;What&#160;kind&#160;of&#160;generative model&#160;should&#160;we&#160;learn?<br/>
<hr/>
<a name=9></a>Belief Nets<br/>
•&#160;A&#160;belief&#160;net&#160;is a directed&#160;<br/>
stochastic<br/>
acyclic graph&#160;composed&#160;of&#160;<br/>
hidden&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<br/>
stochastic&#160;variables.<br/>
cause<br/>
•&#160;We&#160;get to&#160;observe&#160;some of&#160;<br/>
the&#160;variables&#160;and&#160;we&#160;would&#160;<br/>like to solve&#160;two problems:<br/>
•&#160;The&#160;inference&#160;problem:&#160;Infer&#160;<br/>
the&#160;states of&#160;the&#160;unobserved&#160;<br/>variables.<br/>
visible&#160;<br/>
•&#160;The&#160;learning&#160;problem:&#160;Adjust&#160;<br/>
effect<br/>
the&#160;interactions&#160;between&#160;<br/>
We&#160;will&#160;use&#160;nets&#160;composed&#160;of&#160;<br/>
variables&#160;to make the&#160;<br/>
layers&#160;of&#160;stochastic&#160;binary&#160;variables&#160;<br/>
network&#160;more likely&#160;to&#160;<br/>
with&#160;weighted&#160;connections.&#160;&#160;Later,&#160;<br/>we&#160;will&#160;generalize&#160;to&#160;other&#160;types&#160;of&#160;<br/>
generate&#160;the&#160;observed&#160;data.<br/>
variable.<br/>
<hr/>
<a name=10></a>Stochastic&#160;binary&#160;units<br/>
(Bernoulli&#160;variables)<br/>
•<br/>
1<br/>
These&#160;have&#160;a state&#160;of 1&#160;<br/>or&#160;0.<br/>
<i>p</i>(<br/>
&#160;)<br/>
1<br/>
<i>i</i><br/>
<i>s</i><br/>
•&#160;The&#160;probability&#160;of&#160;<br/>
turning on is determined&#160;<br/>
0<br/>
by&#160;the&#160;weighted&#160;input&#160;<br/>
0<br/>
<i>b&#160;</i><br/>
from&#160;other units&#160;(plus a&#160;<br/>
<i>i</i><br/>
<i>sjwji</i><br/>
bias)<br/>
<i>j</i><br/>
1<br/>
<i>p</i>(<i>s&#160;</i>&#160;)<br/>
1<br/>
<br/>
<i>i</i><br/>
1&#160;exp(<i>b&#160;</i><br/>
<i>i</i><br/>
<i>sjwji</i>)<br/>
<i>j</i><br/>
<hr/>
<a name=11></a>Learning&#160;Deep Belief Nets<br/>
•&#160;It&#160;is easy to generate an&#160;<br/>
unbiased&#160;example&#160;at the&#160;<br/>
stochastic<br/>
leaf nodes,&#160;so we&#160;can see&#160;<br/>
hidden&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<br/>
what kinds&#160;of data the&#160;<br/>
cause<br/>
network&#160;believes&#160;in.<br/>
•&#160;It&#160;is hard to&#160;infer&#160;the&#160;<br/>
posterior distribution&#160;over&#160;<br/>all&#160; possible&#160;configurations&#160;<br/>of&#160;hidden&#160;causes.<br/>
•&#160;It&#160;is hard to&#160;even&#160;get&#160;&#160;a&#160;<br/>
sample from&#160;the posterior.<br/>
visible&#160;<br/>effect<br/>
•&#160;So&#160;how&#160;can we&#160;learn&#160;deep&#160;<br/>
belief&#160;nets that&#160;have&#160;<br/>millions&#160;of parameters?<br/>
<hr/>
<a name=12></a>The&#160;learning&#160;rule&#160;for&#160;sigmoid&#160;belief nets<br/>
•&#160;Learning&#160;is easy&#160;if&#160;we&#160;can&#160;<br/>
<i>s</i><br/>
j<br/>
<i>j</i><br/>
get&#160;an&#160;unbiased&#160;sample&#160;<br/>
<i>w&#160;ji</i><br/>
from&#160;the posterior&#160;<br/>distribution&#160;over hidden&#160;<br/>
i<br/>
<i>si</i><br/>
states&#160;given&#160;the&#160;observed&#160;<br/>data.<br/>
1<br/>
<i>p&#160;</i>&#160;<i>p</i>(<i>s&#160;</i>&#160;)<br/>
1&#160;<br/>
<i>i</i><br/>
<i>i</i><br/>
•&#160;For&#160;each&#160;unit,&#160;maximize&#160;<br/>
1&#160;exp(&#160;<i>s&#160;jwji</i>)<br/>
the&#160;log&#160;probability&#160;that its&#160;<br/>
<i>j</i><br/>
binary state&#160;in&#160;the&#160;sample&#160;<br/>
<i>w</i><br/>
<br/>
&#160;&#160;<i>s&#160;</i>(<i>s&#160;</i>&#160;<i>p&#160;</i>)<br/>
<i>ji</i><br/>
<i>j</i><br/>
<i>i</i><br/>
<i>i</i><br/>
from&#160;the posterior&#160;would&#160;be&#160;<br/>generated by&#160;the&#160;sampled&#160;<br/>
learning&#160;<br/>
binary&#160;states of&#160;its parents.&#160;<br/>
rate<br/>
<hr/>
<a name=13></a>Explaining&#160;away&#160;(Judea&#160;Pearl)<br/>
•&#160;Even&#160;if two&#160;hidden&#160;causes are independent,&#160;they&#160;can&#160;<br/>
become&#160;dependent&#160;when&#160;we&#160;observe&#160;an effect&#160;that they&#160;can&#160;<br/>both&#160;influence.&#160;<br/>
–&#160;If&#160;we&#160;learn&#160;that there was&#160;an earthquake&#160;it&#160;reduces&#160;the&#160;<br/>
probability&#160;that&#160;the house&#160;jumped because&#160;of&#160;a&#160;truck.<br/>
-10<br/>
-10<br/>
truck&#160;hits&#160;house<br/>
earthquake<br/>
20<br/>
20<br/>
posterior<br/>
p(1,1)=.0001<br/>p(1,0)=.4999<br/>
-20<br/>
house&#160;jumps<br/>
p(0,1)=.4999<br/>p(0,0)=.0001<br/>
<hr/>
<a name=14></a>Why&#160;it is usually very&#160;hard to learn&#160;&#160; &#160;&#160;<br/>
sigmoid&#160;belief nets&#160;one&#160;layer&#160;at&#160;a&#160;time<br/>
•&#160;To&#160;learn&#160;W,&#160;we&#160;need&#160;the&#160;posterior&#160;<br/>
distribution&#160;in&#160;the first&#160;hidden&#160;layer.<br/>
•&#160;Problem 1: The&#160;posterior&#160;is typically&#160;<br/>
hidden&#160;variables<br/>
complicated&#160;because&#160;of “explaining&#160;<br/>
away”.<br/>
•&#160;Problem&#160;2:&#160;The&#160;posterior&#160;depends&#160;<br/>
hidden&#160;variables<br/>
on&#160;the&#160;prior&#160;as&#160;well&#160;as the&#160;likelihood.&#160;<br/>
–&#160;So&#160;to&#160;learn&#160;W,&#160;we&#160;need&#160;to know&#160;<br/>
prior<br/>
the&#160;weights&#160;in&#160;higher&#160;layers,&#160;even&#160;<br/>if&#160;we&#160;are&#160;only&#160;approximating&#160;the&#160;<br/>
hidden&#160;variables<br/>
posterior.&#160;All&#160;the&#160;weights&#160;interact.<br/>
•<br/>
likelihood<br/>
W<br/>
Problem&#160;3:&#160;We&#160;need&#160;to integrate&#160;<br/>over&#160;all&#160;possible&#160;configurations&#160;of&#160;<br/>
data<br/>
the&#160;higher&#160;variables&#160;to get the prior&#160;<br/>for&#160;first&#160;hidden&#160;layer.&#160;Yuk!<br/>
<hr/>
<a name=15></a>Some methods&#160;of learning&#160;<br/>
deep&#160;belief&#160;nets<br/>
•&#160;Monte&#160;Carlo&#160;methods&#160;can be used to sample&#160;<br/>
from&#160;the&#160;posterior.<br/>
–&#160;But its&#160;painfully&#160;slow&#160;for&#160;large,&#160;deep&#160;models.<br/>
•&#160;In&#160;the&#160;1990’s&#160;people&#160;developed&#160;variational&#160;<br/>
methods&#160;for&#160;learning&#160;deep belief nets<br/>
–&#160;These only get&#160;approximate&#160;samples&#160;from&#160;the&#160;<br/>
posterior.&#160;<br/>
–&#160;Nevetheless, the learning&#160;is still guaranteed&#160;to&#160;<br/>
improve a&#160;variational &#160;bound on the&#160;log&#160;<br/>probability&#160;of&#160;generating the&#160;observed&#160;data.<br/>
<hr/>
<a name=16></a>The&#160;breakthrough&#160;that makes deep&#160;<br/>
learning&#160;efficient<br/>
•&#160;To&#160;learn&#160;deep&#160;nets&#160;efficiently, we need&#160;to learn&#160;one&#160;layer&#160;<br/>
of&#160;features&#160;at&#160;a time.&#160;This does&#160;not work well&#160;if&#160;we&#160;<br/>assume&#160;that the&#160;latent&#160;variables&#160;are independent&#160;in&#160;the&#160;<br/>prior :<br/>
–&#160;The&#160;latent&#160;variables&#160;are not independent&#160;in&#160;the&#160;<br/>
posterior&#160;&#160;so&#160;inference&#160;is hard&#160;for&#160;non-linear&#160;models.<br/>
–&#160;The&#160;learning&#160;tries&#160;to find independent&#160;causes using&#160;<br/>
one&#160;hidden&#160;layer&#160;which&#160;is not usually&#160;possible.<br/>
•&#160;We&#160;need&#160;a way of learning&#160;one&#160;layer&#160;at a&#160;time&#160;that takes&#160;<br/>
into&#160;account&#160;&#160;the&#160;fact&#160;that we will&#160;be&#160;learning&#160;more&#160;<br/>hidden&#160;layers&#160;later.<br/>
–&#160;We&#160;solve&#160;this problem&#160;by using&#160;an undirected&#160;model.<br/>
<hr/>
<a name=17></a>Two&#160;types of&#160;generative&#160;neural&#160;network<br/>
•&#160;If&#160;we connect&#160;binary&#160;stochastic&#160;neurons&#160;in&#160;a&#160;<br/>
directed&#160;acyclic&#160;graph&#160;we&#160;get&#160;a Sigmoid&#160;Belief&#160;<br/>Net (Radford&#160;Neal&#160;1992).<br/>
•&#160;If&#160;we connect&#160;binary&#160;stochastic&#160;neurons using&#160;<br/>
symmetric&#160;connections&#160;we get&#160;a Boltzmann&#160;<br/>Machine&#160;(Hinton&#160;&amp; Sejnowski,&#160;1983).<br/>
–&#160;If&#160;we restrict&#160;the&#160;connectivity&#160;in&#160;a&#160;special way,&#160;<br/>
it&#160;is&#160;easy&#160;to learn&#160;a Boltzmann machine.<br/>
<hr/>
<a name=18></a>Restricted&#160;Boltzmann&#160;Machines<br/>
(Smolensky ,1986,&#160;called&#160;them “harmoniums”)<br/>
•&#160;We&#160;restrict&#160;the connectivity&#160;to make&#160;<br/>
learning&#160;easier.<br/>
hidden<br/>
–&#160;Only&#160;one&#160;layer&#160;of hidden&#160;units.<br/>
•<br/>
j<br/>
We&#160;will&#160;deal&#160;with more&#160;layers&#160;later<br/>
–&#160;No&#160;connections&#160;between&#160;hidden&#160;units.<br/>
•&#160;In&#160;an RBM,&#160;the&#160;hidden&#160;units&#160;are&#160;<br/>
conditionally&#160;independent&#160;given&#160;the&#160;<br/>
i<br/>
visible&#160;states.&#160;&#160;<br/>
visible<br/>
–&#160;So&#160;we can&#160;quickly&#160;get an unbiased&#160;<br/>
sample from&#160;the posterior&#160;distribution&#160;<br/>when given&#160;a&#160;data-vector.<br/>
–&#160;This&#160;is a big&#160;advantage&#160;over directed&#160;<br/>
belief&#160;nets<br/>
<hr/>
<a name=19></a>The Energy of a joint&#160;configuration<br/>
(ignoring&#160;terms&#160;to do with biases)<br/>
binary&#160;state&#160;of&#160;<br/>
binary&#160;state&#160;of&#160;<br/>
visible&#160;unit&#160;i<br/>
hidden&#160;unit&#160;j<br/>
<i>E</i>(<i>v,h</i>)&#160;&#160;&#160;&#160;<i>i</i><br/>
<i>v&#160;h&#160;j&#160;ij</i><br/>
<i>w</i><br/>
<i>i</i>,&#160;<i>j</i><br/>
Energy&#160;with configuration&#160;<br/>
weight&#160;between&#160;<br/>
v&#160;on&#160;the&#160;visible&#160;units&#160;and&#160;<br/>
units&#160;i and&#160;j<br/>
h&#160;on&#160;the&#160;hidden&#160;units<br/>
<i>E</i><br/>
&#160;(<i>v</i>,<i>h</i><br/>
<br/>
)&#160;&#160;<i>v&#160;hij</i><br/>
<i>w</i><br/>
&#160;<i>ij</i><br/>
<hr/>
<a name=20></a>Weights&#160;&#160;Energies&#160;&#160;Probabilities<br/>
•&#160;Each&#160;possible&#160;joint configuration&#160;of&#160;the&#160;visible&#160;<br/>
and&#160;hidden&#160;units has&#160;an&#160;energy<br/>
–&#160;The&#160;energy&#160;is&#160;determined&#160;by&#160;the weights&#160;and&#160;<br/>
biases&#160;(as in a&#160;Hopfield&#160;net).<br/>
•&#160;The energy&#160;of a joint&#160;configuration&#160;of the&#160;visible&#160;<br/>
and hidden&#160;units&#160;determines&#160;its&#160;probability:<br/>
<i>E</i>(<i>v</i>,<i>h</i>)<br/>
<i>p</i>(<i>v</i>,&#160;<i>h</i>)&#160;&#160;<i>e</i><br/>
•&#160;The&#160;probability&#160;of&#160;a configuration&#160;over&#160;the visible&#160;<br/>
units&#160;is&#160;found by summing&#160;the&#160;probabilities&#160;of all&#160;<br/>the&#160;joint configurations&#160;that contain&#160;it.&#160;<br/>
<hr/>
<a name=21></a>Using&#160;energies&#160;to define&#160;probabilities<br/>
<i>E</i>(<i>v</i>,<i>h</i>)<br/>
•<br/>
<i>e</i><br/>
The&#160;probability&#160;of a&#160;joint&#160;<br/>
<i>p</i>(<i>v</i>,&#160;<i>h</i>)&#160;<br/>
configuration&#160;over&#160;both visible&#160;<br/>
&#160;<i>E</i>(<i>u</i>,<i>g</i><br/>
<i>e</i><br/>
)<br/>
and&#160;hidden&#160;units&#160;depends&#160;on&#160;<br/>the&#160;energy&#160;of that&#160;joint&#160;<br/>
<i>u</i>,<i>g</i><br/>
partition&#160;<br/>
configuration&#160;compared&#160;with&#160;<br/>
function<br/>
the&#160;energy&#160;of&#160;all&#160;other joint&#160;<br/>configurations.<br/>
&#160;<i>E</i>(<i>v</i>,<i>h</i>)<br/>
•<br/>
<i>e</i><br/>
The&#160;probability&#160;of a&#160;<br/>configuration&#160;of the&#160;visible&#160;<br/>
<i>p</i>(<i>v</i>)&#160;&#160;<i>h</i><br/>
units is the&#160;sum&#160;of the&#160;<br/>
&#160;<i>E</i>(<i>u</i>,<i>g</i>)<br/>
probabilities&#160;of all&#160;the&#160;joint&#160;<br/>
<i>e</i><br/>
configurations&#160;that contain&#160;it.<br/>
<i>u</i>,<i>g</i><br/>
<hr/>
<a name=22></a>A&#160;picture&#160;of&#160;the&#160;maximum&#160;likelihood&#160;learning&#160;<br/>
algorithm&#160;for&#160;an&#160;RBM<br/>
j<br/>
j<br/>
j<br/>
j<br/>
0<br/>
<br/>
<br/>
<i>v</i><br/>
<br/>
<i>v&#160;</i><br/>
<i>ih&#160;j</i><br/>
<i>ih&#160;j</i><br/>
a&#160;fantasy<br/>
i<br/>
i<br/>
i<br/>
i<br/>
t&#160;=&#160;0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;t&#160;=&#160;1&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;t&#160;=&#160;2&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;t&#160;=&#160;infinity<br/>
Start&#160;with&#160;a&#160;training&#160;vector on the&#160;visible&#160;units.<br/>
Then&#160;alternate&#160;between&#160;updating&#160;all&#160;the&#160;hidden&#160;units&#160;in&#160;<br/>parallel&#160;and&#160;updating&#160;all&#160;the&#160;visible&#160;units&#160;in&#160;parallel.<br/>
&#160;log&#160;<i>p</i>(<i>v</i>)<br/>
0<br/>
<br/>
&#160;<i>v&#160;h&#160;</i>&#160;&#160;<i>v&#160;h&#160;</i><br/>
<br/>
<i>i&#160;j</i><br/>
<i>i&#160;j</i><br/>
<i>ij</i><br/>
<i>w</i><br/>
<hr/>
<a name=23></a>A&#160;quick way&#160;to learn an&#160;RBM<br/>
j<br/>
j<br/>
Start&#160;with a&#160;training&#160;vector&#160;on&#160;the&#160;<br/>visible&#160;units.<br/>
0<br/>
<i>v&#160;</i><br/>
1<br/>
<i>v&#160;</i><br/>
<i>ih&#160;j</i><br/>
<i>ih&#160;j</i><br/>
Update&#160;all the&#160;hidden&#160;units&#160;in&#160;<br/>parallel<br/>
i<br/>
i<br/>
Update&#160;the&#160;all&#160;the&#160;visible units&#160;in&#160;<br/>parallel&#160;to&#160;get&#160;a&#160;“reconstruction”.<br/>
t&#160;=&#160;0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;t&#160;=&#160;1&#160;&#160;&#160;<br/>
Update&#160;the&#160;hidden&#160;units&#160;again.&#160;<br/>
data<br/>
reconstruction<br/>
<i>w&#160;</i>&#160;&#160;(<br/>
0<br/>
1<br/>
<i>v&#160;h&#160;</i>&#160;&#160;<i>v&#160;h&#160;</i>&#160;)<br/>
<i>ij</i><br/>
<i>i&#160;j</i><br/>
<i>i&#160;j</i><br/>
This&#160;is not following&#160;the&#160;gradient&#160;of&#160;the log&#160;likelihood.&#160;But it&#160;<br/>works well.&#160;It&#160;is approximately&#160;following&#160;the&#160;gradient&#160;of another&#160;<br/>objective function (Carreira-Perpinan&#160;&amp;&#160;Hinton,&#160;2005).<br/>
<hr/>
<a name=24></a>How to learn&#160;a set of features&#160;that are good&#160;for&#160;<br/>
reconstructing&#160;images&#160;of the&#160;digit 2<br/>
50&#160;binary&#160;<br/>
50&#160;binary&#160;<br/>
feature&#160;<br/>
feature&#160;<br/>
neurons<br/>
neurons<br/>
Increment&#160;weights&#160;<br/>
Decrement&#160;weights&#160;<br/>
between&#160;an&#160;active&#160;<br/>
between&#160;an&#160;active&#160;<br/>
pixel&#160;and&#160;an&#160;active&#160;<br/>
pixel&#160;and&#160;an&#160;active&#160;<br/>
feature<br/>
feature<br/>
16&#160;x&#160;16&#160;<br/>
16&#160;x&#160;16&#160;<br/>
pixel&#160;&#160;&#160;&#160;&#160;<br/>
pixel &#160;&#160;&#160;&#160;<br/>
image<br/>
image<br/>
data&#160;<br/>
reconstruction&#160;&#160;&#160;&#160;<br/>
(reality)<br/>
(better&#160;than&#160;reality)<br/>
<hr/>
<a name=25></a><img src="./Hinton_1-25_1.jpg"/><br/>
The&#160;final&#160;50&#160;x&#160;256&#160;weights<br/>
Each&#160;neuron&#160;grabs a different feature.<br/>
<hr/>
<a name=26></a><img src="./Hinton_1-26_1.png"/><br/>
<img src="./Hinton_1-26_2.png"/><br/>
How well&#160;can we&#160;reconstruct&#160;the&#160;digit images&#160;<br/>
from&#160;the&#160;binary&#160;feature&#160;activations?<br/>
Reconstruction&#160;<br/>
Reconstruction&#160;<br/>
from&#160;activated&#160;<br/>
from activated&#160;<br/>
Data<br/>
binary&#160;features<br/>
Data<br/>
binary&#160;features<br/>
New&#160;test&#160;images&#160;from&#160;<br/>
Images&#160;from&#160;an&#160;<br/>
the&#160;digit&#160;class&#160;that&#160;the&#160;<br/>
unfamiliar&#160;digit&#160;class&#160;<br/>
model&#160;was&#160;trained&#160;on<br/>
(the&#160;network&#160;tries&#160;to&#160;see&#160;<br/>every&#160;image&#160;as&#160;a 2)<br/>
<hr/>
<a name=27></a>Three&#160;ways&#160;to&#160;combine&#160;probability density&#160;<br/>
models&#160;(an&#160;underlying&#160;theme&#160;of&#160;the&#160;tutorial)<br/>
•&#160;<b>Mixture:&#160;</b>Take&#160;a weighted&#160;average&#160;of the&#160;distributions.<br/>
–&#160;It&#160;can&#160;never&#160;be&#160;sharper&#160;than&#160;the individual&#160;distributions.&#160;<br/>
It’s&#160;a very weak&#160;way&#160;to combine&#160;models.<br/>
•&#160;<b>Product:&#160;</b>Multiply&#160;the distributions&#160;at each point&#160;and&#160;then&#160;<br/>
renormalize&#160;(this&#160;is&#160;how&#160;an RBM&#160;combines&#160;the&#160;distributions&#160;defined&#160;<br/>by&#160;each&#160;hidden&#160;unit)<br/>
–&#160;Exponentially&#160;more&#160;powerful&#160;than a&#160;mixture.&#160;The&#160;<br/>
normalization&#160;makes maximum&#160;likelihood&#160;learning&#160;<br/>difficult,&#160;but approximations&#160;allow&#160;us&#160;to learn&#160;anyway.<br/>
•&#160;<b>Composition:&#160;</b>Use the values&#160;of&#160;the&#160;latent variables&#160;of&#160;one&#160;<br/>
model&#160;as&#160;the&#160;data for&#160;the next&#160;model.<br/>
–&#160;Works&#160;well&#160;for&#160;learning&#160;multiple&#160;layers&#160;of representation,&#160;<br/>
but&#160;only&#160;if&#160;the individual&#160;models&#160;are&#160;undirected.<br/>
<hr/>
<a name=28></a>Training&#160;a deep&#160;network<br/>
(the&#160;main&#160;reason RBM’s&#160;are interesting)<br/>
•&#160;First&#160;train&#160;a layer&#160;of features that&#160;receive&#160;input&#160;directly&#160;<br/>
from&#160;the pixels.<br/>
•&#160;Then&#160;treat&#160;the&#160;activations&#160;of the&#160;trained&#160;features&#160;as if&#160;<br/>
they&#160;were&#160;pixels&#160;and&#160;learn&#160;features&#160;of features in&#160;a&#160;<br/>second hidden&#160;layer.<br/>
•&#160;It&#160;can&#160;be proved&#160;that&#160;each&#160;time&#160;we&#160;add another layer&#160;of&#160;<br/>
features&#160;we&#160;improve a variational&#160;lower&#160;bound&#160;on the&#160;log&#160;<br/>probability&#160;of the&#160;training&#160;data.<br/>
–&#160;The&#160;proof is slightly&#160;complicated.&#160;<br/>–&#160;But&#160;it&#160;is based&#160;on&#160;a&#160;neat equivalence&#160;between&#160;an&#160;<br/>
RBM and&#160;a&#160;deep&#160;directed&#160;model&#160;(described&#160;later)<br/>
<hr/>
<a name=29></a>The generative&#160;model&#160;after learning&#160;3 layers<br/>
•<br/>
To&#160;generate&#160;data:&#160;<br/>
h3<br/>
1.&#160;Get&#160;an equilibrium&#160;sample&#160;<br/>
from&#160;the top-level&#160;RBM by&#160;<br/>
3<br/>
<i>W</i><br/>
performing&#160;alternating&#160;Gibbs&#160;<br/>sampling&#160;for a long&#160;time.<br/>
h2<br/>
2.&#160;Perform&#160;a&#160;top-down&#160;pass to&#160;<br/>
get&#160;states&#160;for&#160;all&#160;the&#160;other&#160;<br/>
2<br/>
<i>W</i><br/>
layers.<br/>
h1<br/>
So&#160;the&#160;lower&#160;level&#160;bottom-up&#160;<br/>
1<br/>
<i>W</i><br/>
connections&#160;&#160;are&#160;not&#160;part of&#160;<br/>
data<br/>
the&#160;generative&#160;model.&#160;They&#160;<br/>are&#160;just&#160;used&#160;for inference.<br/>
<hr/>
<a name=30></a>Why&#160;does greedy&#160;learning&#160;work?&#160;&#160; &#160; &#160; &#160;<br/>
An&#160;aside:&#160;Averaging&#160;factorial&#160;distributions&#160;&#160; &#160;&#160;&#160;&#160;<br/>
•&#160;If&#160;you average&#160;some factorial distributions, you&#160;<br/>
do NOT get a&#160;factorial&#160;distribution.<br/>
–&#160;In&#160;an&#160;RBM,&#160;the&#160;posterior over the&#160;hidden&#160;units&#160;<br/>
is&#160;factorial&#160;for&#160;each&#160;visible&#160;vector.<br/>
–&#160;But&#160;the&#160;aggregated&#160;posterior&#160;over&#160;all&#160;training&#160;<br/>
cases&#160;is&#160;not factorial&#160;(even if the data was&#160;<br/>generated&#160;by&#160;the&#160;RBM&#160;itself).<br/>
<hr/>
<a name=31></a>Why&#160;does&#160;greedy&#160;learning&#160;work?<br/>
•&#160;Each&#160;RBM converts&#160;its&#160;data&#160;distribution&#160;<br/>
into&#160;an&#160;aggregated&#160;posterior&#160;distribution&#160;<br/>over&#160;its&#160;hidden&#160;units.&#160;<br/>
<i>p</i>(<i>h&#160;</i>|<i>W&#160;</i>)<br/>
•<br/>
Task&#160;2<br/>
This&#160;divides the&#160;task&#160;of&#160;modeling&#160;its&#160;<br/>data&#160;into&#160;two tasks:<br/>
–&#160;Task&#160;1:&#160;Learn&#160;generative&#160;weights&#160;<br/>
aggregated&#160;&#160; &#160;<br/>
that&#160;can&#160;convert&#160;the&#160;aggregated&#160;<br/>posterior&#160;distribution&#160;over&#160;the&#160;hidden&#160;<br/>
posterior distribution&#160;&#160; &#160;&#160;<br/>
units&#160;back&#160;into&#160;the&#160;data&#160;distribution.<br/>
on&#160;hidden&#160;units<br/>
–&#160;Task&#160;2:&#160;Learn&#160;to&#160;model&#160;the&#160;<br/>
aggregated&#160;posterior&#160;distribution&#160;<br/>over&#160;the&#160;hidden&#160;units.<br/>
<i>p</i>(<i>v&#160;</i>|&#160;,<br/>
<i>h&#160;W&#160;</i>)<br/>
Task&#160;1<br/>
–&#160;The&#160;RBM does&#160;a good&#160;job&#160;of&#160;task&#160;1&#160;<br/>
and&#160;a&#160;moderately&#160;good&#160;job&#160;of&#160;task&#160;2.<br/>
•&#160;Task&#160;2 is&#160;easier&#160;(for&#160;the&#160;next&#160;RBM)&#160;than&#160;<br/>
modeling&#160;the&#160;original&#160;data&#160;because&#160;the&#160;<br/>
data&#160;distribution&#160;<br/>
aggregated&#160;posterior&#160;distribution&#160;is&#160;<br/>
on&#160;visible&#160;units<br/>
closer&#160;to&#160;a distribution&#160;that&#160;an&#160;RBM&#160;can&#160;<br/>model&#160;perfectly.<br/>
<hr/>
<a name=32></a>Why&#160;does greedy&#160;learning&#160;work?<br/>
The&#160;weights, W, &#160;in the&#160;bottom level RBM&#160;define&#160;<br/>p(v|h)&#160;and&#160;they also, indirectly, define&#160;p(h).<br/>
So&#160;we&#160;can express&#160;the RBM&#160;model&#160;as<br/>
<i>p</i>(<i>v</i>)&#160;&#160;&#160;<i>p</i>(<i>h</i>)&#160;<i>p</i>(<i>v&#160;</i>|&#160;<i>h</i>)<br/>
<i>h</i><br/>
If&#160;we leave&#160;p(v|h)&#160;alone and&#160;improve&#160;p(h), we&#160;will&#160;<br/>improve p(v).&#160;<br/>
To improve&#160;p(h), we&#160;need&#160;it&#160;to&#160;be&#160;a&#160;better model&#160;of&#160;<br/>the&#160;aggregated posterior&#160;distribution&#160;over&#160;hidden&#160;<br/>vectors&#160;produced&#160;by&#160;applying&#160;W to the&#160;data.<br/>
<hr/>
<a name=33></a>Which distributions&#160;are factorial in a&#160;<br/>
directed&#160;belief&#160;net?<br/>
•&#160;In&#160;a directed&#160;belief net&#160;with&#160;one hidden&#160;layer, the&#160;<br/>
posterior over the&#160;hidden&#160;units&#160;&#160;p(h|v)&#160;is&#160;non-<br/>factorial&#160;(due&#160;to explaining&#160;away).<br/>
–&#160;The&#160;aggregated&#160;posterior is factorial if the&#160;<br/>
data was&#160;generated&#160;by&#160;the&#160;directed&#160;model.<br/>
•&#160;It’s&#160;the opposite&#160;way&#160;round from an undirected&#160;<br/>
model which&#160;has factorial&#160;posteriors&#160;and a non-<br/>factorial&#160;prior&#160;&#160;p(h)&#160;over&#160;the&#160;hiddens.&#160;<br/>
•&#160;The&#160;intuitions&#160;that&#160;people&#160;have&#160;from&#160;using&#160;directed&#160;<br/>
models are&#160;very misleading&#160;for&#160;undirected&#160;models.<br/>
<hr/>
<a name=34></a>Why&#160;does greedy&#160;learning&#160;fail in&#160;a directed module?<br/>
•&#160;A&#160;directed&#160;module&#160;also&#160;converts&#160;its&#160;data&#160;<br/>
distribution&#160;into an&#160;aggregated&#160;&#160;posterior&#160;<br/>
<i>p</i>(<i>h&#160;</i>|&#160;<i>W&#160;</i>)<br/>
2<br/>
Task&#160;2<br/>
–&#160;Task&#160;1&#160;The&#160;learning&#160;is&#160;now&#160;harder&#160;<br/>
because&#160;the&#160;posterior&#160;for&#160;each&#160;training&#160;<br/>case&#160;is non-factorial.<br/>
aggregated&#160;&#160; &#160;<br/>
–&#160;Task&#160;2&#160;is&#160;performed&#160;using&#160;an&#160;<br/>
posterior distribution&#160;&#160; &#160;&#160;<br/>
independent&#160;prior.&#160;This&#160;is a&#160;very&#160;bad&#160;<br/>approximation&#160;unless&#160;the&#160;aggregated&#160;<br/>
on&#160;hidden&#160;units<br/>
posterior&#160;is&#160;close&#160;to&#160;factorial.<br/>
Task&#160;1<br/>
<i>p</i>(<i>v&#160;</i>|&#160;,<br/>
<i>h&#160;W&#160;</i>)<br/>
•&#160;A&#160;directed&#160;module&#160;attempts&#160;to&#160;make&#160;the&#160;<br/>
1<br/>
aggregated&#160;posterior&#160;factorial&#160;in one&#160;step.&#160;<br/>
–&#160;This&#160;is too&#160;difficult&#160;and&#160;leads&#160;to&#160;a&#160;bad&#160;<br/>
compromise.&#160;There&#160;is also&#160;no&#160;<br/>
data&#160;distribution&#160;<br/>
guarantee&#160;that&#160;the&#160;aggregated&#160;<br/>
on&#160;visible&#160;units<br/>
posterior&#160;is&#160;easier&#160;to&#160;model&#160;than&#160;the&#160;<br/>data&#160;distribution.<br/>
<hr/>
<a name=35></a>A&#160;model of digit&#160;recognition<br/>
The&#160;top&#160;two layers&#160;form&#160;an&#160;<br/>associative&#160;memory&#160;&#160;whose&#160;&#160;<br/>
2000 top-level&#160;neurons<br/>
energy&#160;landscape&#160;models&#160;the&#160;low&#160;<br/>dimensional&#160;manifolds&#160;of&#160;the&#160;<br/>digits.<br/>
10&#160;label&#160;<br/>
The&#160;energy&#160;valleys have&#160;names<br/>
500&#160;neurons<br/>
neurons<br/>
The&#160;model&#160;learns&#160;to generate&#160;<br/>
500&#160;neurons<br/>
combinations&#160;of labels&#160;and&#160;images.&#160;<br/>
To&#160;perform recognition&#160;we&#160;start&#160;with a&#160;<br/>neutral state&#160;of the&#160;label&#160;units&#160;and&#160;do&#160;<br/>
28&#160;x&#160;28&#160;<br/>
an&#160;up-pass&#160;from&#160;the&#160;image&#160;followed&#160;<br/>
pixel&#160;&#160; &#160;&#160;<br/>
by&#160;a&#160;few iterations&#160;of the&#160;top-level&#160;<br/>
image<br/>
associative&#160;memory.<br/>
<hr/>
<a name=36></a>Fine-tuning&#160;with&#160;a&#160;contrastive&#160;version&#160;of&#160;the&#160;<br/>
“wake-sleep”&#160;algorithm<br/>
After&#160;learning&#160;many&#160;layers&#160;of features,&#160;we&#160;can fine-tune&#160;<br/>
the&#160;features&#160;to&#160;improve&#160;generation.<br/>
1.&#160;&#160;Do a stochastic bottom-up&#160;pass<br/>
–&#160;Adjust&#160;the top-down&#160;weights&#160;to be good&#160;at&#160;<br/>
reconstructing the&#160;feature&#160;activities&#160;in&#160;the layer&#160;below.<br/>
2.&#160;Do&#160;a few iterations&#160;of&#160;sampling&#160;in&#160;the&#160;top level&#160;RBM<br/>
--&#160;Adjust the&#160;weights&#160;in&#160;the top-level&#160;RBM.<br/>
3.&#160;Do&#160;a&#160;stochastic top-down&#160;pass<br/>
–&#160;Adjust&#160;the bottom-up&#160;weights&#160;to&#160;be&#160;good&#160;at&#160;<br/>
reconstructing the&#160;feature&#160;activities&#160;in&#160;the layer&#160;above.<br/>
<hr/>
<a name=37></a>Show&#160;the movie&#160;of the network&#160;<br/>
generating&#160;digits<br/>
(available at www.cs.toronto/~hinton)<br/>
<hr/>
<a name=38></a><img src="./Hinton_1-38_1.jpg"/><br/>
Samples&#160;generated&#160;by&#160;letting&#160;the associative&#160;<br/>
memory run&#160;with&#160;one&#160;label&#160;clamped.&#160;There&#160;are&#160;<br/>
1000&#160;iterations&#160;of&#160;alternating&#160;Gibbs&#160;sampling&#160;<br/>
between samples.<br/>
<hr/>
<a name=39></a><img src="./Hinton_1-39_1.jpg"/><br/>
Examples&#160;of correctly&#160;recognized&#160;handwritten&#160;digits<br/>
that&#160;the&#160;neural network&#160;had&#160;never seen&#160;before &#160; &#160;&#160;&#160; &#160; &#160;&#160;<br/>
Its&#160;very&#160;<br/>good<br/>
<hr/>
<a name=40></a>How well&#160;does it discriminate&#160;on&#160;MNIST&#160;test set with&#160;<br/>
no&#160;extra&#160;information&#160;about geometric&#160;distortions?<br/>
•&#160;Generative&#160;model&#160;based&#160;on&#160;RBM’s &#160;&#160; &#160;&#160; &#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;1.25%<br/>•&#160;Support Vector Machine&#160;&#160;(Decoste&#160;et.&#160;al.)<br/>
1.4%&#160;&#160;&#160;<br/>
•&#160;Backprop with&#160;1000&#160;hiddens&#160;(Platt)&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; ~1.6%<br/>•&#160;Backprop with&#160;500&#160;--&gt;300 hiddens&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160; ~1.6%<br/>•&#160;K-Nearest Neighbor&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;~ 3.3%<br/>•&#160;See&#160;Le&#160;Cun&#160;et.&#160;al.&#160;1998&#160;for more&#160;results<br/>
•&#160;Its&#160;better&#160;than backprop&#160;and&#160;much more&#160;neurally&#160;plausible&#160;<br/>
because the neurons&#160;only&#160;need&#160;to&#160;send one&#160;kind&#160;of&#160;signal,&#160;<br/>and&#160;the&#160;teacher can be another&#160;sensory&#160;input.<br/>
<hr/>
<a name=41></a>Unsupervised&#160;“pre-training”&#160;also&#160;helps for&#160;<br/>
models&#160;that have&#160;more&#160;data&#160;and better&#160;priors<br/>
•&#160;Ranzato&#160;et.&#160;al. (NIPS&#160;2006)&#160;used&#160;an&#160;additional&#160;<br/>
600,000 distorted digits.<br/>
•&#160;They&#160;also&#160;used&#160;convolutional multilayer&#160;neural&#160;<br/>
networks&#160;that have some&#160;built-in, local&#160;<br/>translational invariance.<br/>
Back-propagation alone: &#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;0.49%&#160;<br/>
Unsupervised&#160;layer-by-layer<br/>pre-training followed&#160;by&#160;backprop: &#160; 0.39%&#160;(record)<br/>
<hr/>
<a name=42></a>Another&#160;view&#160;of&#160;why layer-by-layer&#160;&#160;&#160;&#160;<br/>
learning&#160;works&#160;(Hinton, Osindero&#160;&amp;&#160;Teh&#160;2006)<br/>
•&#160;There is an&#160;unexpected&#160;equivalence&#160;between&#160;<br/>
RBM’s&#160;and directed&#160;networks&#160;with&#160;many&#160;layers&#160;<br/>that&#160;all use&#160;the same&#160;weights.<br/>
–&#160;This&#160;equivalence&#160;also&#160;gives insight&#160;into why&#160;<br/>
contrastive&#160;divergence&#160;learning&#160;works.<br/>
<hr/>
<a name=43></a>An&#160;infinite sigmoid&#160;belief net&#160;<br/>
etc.<br/>
that&#160;is&#160;equivalent to&#160;an&#160;RBM<br/>
<i>T</i><br/>
<i>W</i><br/>
h2<br/>
•&#160;The&#160;distribution&#160;generated&#160;by this&#160;<br/>
infinite&#160;directed&#160;net&#160;with&#160;replicated&#160;<br/>
<i>W</i><br/>
weights is the equilibrium&#160;distribution&#160;<br/>
v2<br/>
for&#160;a&#160;compatible&#160;pair&#160;of conditional&#160;<br/>
<i>T</i><br/>
<i>W</i><br/>
distributions:&#160;p(v|h)&#160;and&#160;p(h|v)&#160;that&#160;<br/>
h<br/>
are&#160;both defined&#160;by W<br/>
1<br/>
–&#160;A&#160;top-down&#160;pass of the&#160;directed&#160;<br/>
<i>W</i><br/>
net&#160;is exactly&#160;equivalent&#160;to letting&#160;<br/>
v1<br/>
a&#160;Restricted Boltzmann&#160;Machine&#160;<br/>
<i>T</i><br/>
<i>W</i><br/>
settle&#160;to equilibrium.<br/>
h0<br/>
–&#160;So&#160;this infinite&#160;directed&#160;net &#160;<br/>
defines the&#160;same distribution&#160;as&#160;<br/>
<i>W</i><br/>
an&#160;RBM.<br/>
v0<br/>
<hr/>
<a name=44></a>Inference&#160;in a&#160;directed&#160;net&#160;<br/>
etc.<br/>
with&#160;replicated&#160;weights<br/>
<i>T</i><br/>
<i>W</i><br/>
•<br/>
h2<br/>
The&#160;variables&#160;in&#160;h0 are conditionally&#160;<br/>independent&#160;given&#160;v0.<br/>
<i>W</i><br/>
–&#160;Inference&#160;is trivial. We just&#160;<br/>
v2<br/>
multiply v0&#160;by&#160;W&#160;transpose.<br/>
<i>T</i><br/>
<i>W</i><br/>
–&#160;The&#160;model&#160;above&#160;h0 implements&#160;<br/>
a&#160;complementary&#160;prior.<br/>
h1<br/>
–&#160;Multiplying&#160;v0 by&#160;W transpose<br/>
<i>W</i><br/>
gives the&#160;product&#160;of the&#160;likelihood&#160;<br/>
v1<br/>
term&#160;and&#160;the&#160;prior term.<br/>
<i>T</i><br/>
•<br/>
+<br/>
+<br/>
Inference&#160;in&#160;the&#160;directed&#160;net&#160;is&#160;<br/>
<i>W</i><br/>
exactly equivalent&#160;to letting a&#160;<br/>
h0<br/>
Restricted&#160;Boltzmann&#160;Machine&#160;<br/>
<i>W</i><br/>
settle&#160;to equilibrium&#160;starting at the&#160;<br/>
+<br/>
+<br/>
data.<br/>
v0<br/>
<hr/>
<a name=45></a>etc.<br/>
<i>T</i><br/>
•<br/>
<i>W</i><br/>
The&#160;learning&#160;rule for&#160;a&#160;sigmoid&#160;belief&#160;<br/>
2<br/>
net&#160;is:<br/>
h2&#160;<i>s&#160;j</i><br/>
<i>w</i><br/>
<br/>
&#160;<i>s&#160;</i>(<i>s&#160;</i>&#160;ˆ<i>s&#160;</i>)<br/>
<i>T</i><br/>
<i>ij</i><br/>
<i>j</i><br/>
<i>i</i><br/>
<i>i</i><br/>
<i>W</i><br/>
<i>W</i><br/>
v<br/>
2<br/>
2&#160;<i>si</i><br/>
•&#160;With&#160;replicated&#160;weights&#160;this&#160;becomes:<br/>
<i>T</i><br/>
<i>W</i><br/>
<i>W</i><br/>
<i>s</i>0&#160;(<i>s</i>0&#160;&#160;<i>s</i>1)&#160;<br/>
h<br/>
1<br/>
1<br/>
<i>s&#160;j</i><br/>
<i>j</i><br/>
<i>i</i><br/>
<i>i</i><br/>
<i>T</i><br/>
<i>W</i><br/>
<i>W</i><br/>
<i>s</i>1(<i>s</i>0&#160;&#160;<i>s</i>1&#160;)&#160;<br/>
1<br/>
<i>i</i><br/>
<i>j</i><br/>
<i>j</i><br/>
v1&#160;<i>si</i><br/>
1<br/>
1<br/>
2<br/>
<i>T</i><br/>
<i>s&#160;</i>(<i>s&#160;</i>&#160;<i>s&#160;</i>)&#160;<br/>
<i>W</i><br/>
<i>W</i><br/>
<i>j</i><br/>
<i>i</i><br/>
<i>i</i><br/>
...<br/>
h<br/>
0<br/>
0<br/>
<i>s&#160;j</i><br/>
&#160;<br/>
<i>s&#160;j&#160;i</i><br/>
<i>s</i><br/>
<i>T</i><br/>
<i>W</i><br/>
<i>W</i><br/>
v<br/>
0<br/>
0&#160;<i>si</i><br/>
<hr/>
<a name=46></a>Learning&#160;a deep directed&#160;<br/>
etc.<br/>
network<br/>
<i>T</i><br/>
<i>W</i><br/>
•&#160;First&#160;learn&#160;with&#160;all&#160;the&#160;weights&#160;tied<br/>
h2<br/>
–&#160;This&#160;is exactly&#160;equivalent&#160;to&#160;<br/>
<i>W</i><br/>
learning&#160;an&#160;RBM<br/>
v2<br/>
–&#160;Contrastive&#160;divergence&#160;learning&#160;<br/>
<i>T</i><br/>
<i>W</i><br/>
is&#160;equivalent&#160;to ignoring&#160;the small&#160;<br/>
h<br/>
derivatives contributed&#160;by the&#160;tied&#160;<br/>
1<br/>
weights between&#160;deeper&#160;layers.<br/>
<i>W</i><br/>
v1<br/>
<i>T</i><br/>
<i>W</i><br/>
h0<br/>
h0<br/>
<i>W</i><br/>
<i>W</i><br/>
v0<br/>
v0<br/>
<hr/>
<a name=47></a>•&#160;Then&#160;freeze&#160;the&#160;first&#160;layer&#160;of weights&#160;<br/>
etc.<br/>
in&#160;both directions&#160;and&#160;learn&#160;the&#160;<br/>
<i>T</i><br/>
<i>W</i><br/>
remaining&#160;weights&#160;(still tied&#160;<br/>together).<br/>
h2<br/>
–&#160;This&#160;is equivalent&#160;to learning&#160;<br/>
<i>W</i><br/>
another RBM,&#160;using&#160;the&#160;<br/>
v2<br/>
aggregated&#160;posterior distribution&#160;<br/>
<i>T</i><br/>
<i>W</i><br/>
of&#160;h0 as the&#160;data.<br/>
h1<br/>
<i>W</i><br/>
v1<br/>
v1<br/>
<i>T</i><br/>
<i>W</i><br/>
<i>W</i><br/>
h0<br/>
h0<br/>
<i>T</i><br/>
<i>W</i><br/>
<i>W&#160;frozen</i><br/>
<i>frozen</i><br/>
v0<br/>
<hr/>
<a name=48></a>How&#160;many&#160;layers&#160;should&#160;we use&#160;and&#160;how&#160;<br/>
wide&#160;should&#160;they be?&#160;<br/>
•&#160;There is no simple&#160;answer.&#160;<br/>
–&#160;Extensive&#160;experiments&#160;by&#160;Yoshua&#160;Bengio’s&#160;group&#160;<br/>
(described&#160;later)&#160;suggest&#160;that several&#160;hidden&#160;layers&#160;is&#160;<br/>better&#160;than&#160;one.&#160;<br/>
–&#160;Results&#160;are fairly robust against&#160;changes&#160;in&#160;the size&#160;of&#160;a&#160;<br/>
layer,&#160;but the&#160;top layer should&#160;be big.<br/>
•&#160;Deep belief&#160;nets&#160;give&#160;their creator a&#160;lot of freedom.&#160;<br/>
–&#160;The&#160;best way&#160;to use that&#160;freedom&#160;depends&#160;on the&#160;task.<br/>–&#160;With&#160;enough&#160;narrow&#160;layers&#160;we&#160;can model&#160;any distribution&#160;<br/>
over&#160;binary&#160;vectors (Sutskever&#160;&amp; Hinton,&#160;2007)<br/>
<hr/>
<a name=49></a>What&#160;happens&#160;when&#160;the&#160;weights&#160;in&#160;higher&#160;layers&#160;<br/>
become different from&#160;the&#160;weights&#160;in&#160;the&#160;first layer?<br/>
•&#160;The&#160;higher&#160;layers&#160;no longer&#160;implement&#160;a complementary&#160;<br/>
prior.<br/>
–&#160;So&#160;performing&#160;inference&#160;using&#160;the&#160;frozen&#160;weights&#160;in&#160;<br/>
the&#160;first&#160;layer&#160;is no longer&#160;correct.&#160;&#160;But&#160;its&#160;still&#160;pretty&#160;<br/>good.<br/>
–&#160;Using&#160;this&#160;incorrect&#160;inference&#160;procedure&#160;gives&#160;a&#160;<br/>
variational&#160;&#160;lower&#160;bound&#160;on&#160;the&#160;log&#160;probability&#160;of&#160;the&#160;<br/>data.&#160;<br/>
•&#160;The&#160;higher&#160;layers&#160;learn&#160;a prior&#160;that is closer to&#160;the&#160;<br/>
aggregated&#160;posterior distribution&#160;of the&#160;first&#160;hidden&#160;layer.<br/>
–&#160;This&#160;improves&#160;the&#160;network’s&#160;model&#160;of&#160;the data.<br/>
•&#160;Hinton,&#160;Osindero&#160;and&#160;Teh&#160;(2006)&#160;prove&#160;that&#160;this&#160;<br/>
improvement&#160;is always&#160;bigger&#160;than&#160;the&#160;loss&#160;in the&#160;variational&#160;<br/>bound&#160;caused&#160;by&#160;using&#160;less&#160;accurate&#160;inference.<br/>
<hr/>
<a name=50></a>An&#160;improved&#160;version&#160;of Contrastive&#160;<br/>
Divergence&#160;learning&#160;(if time permits)<br/>
•&#160;The&#160;main&#160;worry&#160;with CD&#160;is that&#160;there will&#160;be&#160;deep&#160;<br/>
minima&#160;of the&#160;energy&#160;function far away&#160;from&#160;the&#160;<br/>data.&#160;<br/>
–&#160;To&#160;find these we&#160;need&#160;to&#160;run the Markov&#160;chain&#160;for&#160;<br/>
a&#160;long&#160;time (maybe&#160;thousands&#160;of steps).&#160;<br/>
–&#160;But&#160;we&#160;cannot&#160;afford&#160;to&#160;run the chain&#160;for too&#160;long&#160;<br/>
for each&#160;update of the&#160;weights.<br/>
•&#160;Maybe&#160;we&#160;can&#160;run the&#160;same&#160;Markov&#160;chain&#160;over&#160;<br/>
many&#160;weight&#160;updates?&#160;(Neal,&#160;1992)<br/>
–&#160;If&#160;the&#160;learning&#160;rate is very&#160;small,&#160;this should&#160;be&#160;<br/>
equivalent&#160;to running&#160;the&#160;chain&#160;for&#160;many&#160;steps&#160;<br/>and&#160;then&#160;doing&#160;a bigger weight&#160;update.<br/>
<hr/>
<a name=51></a>Persistent&#160;CD<br/>
(Tijmen&#160;Teileman,&#160;ICML&#160;2008&#160;&amp; 2009)<br/>
•&#160;Use&#160;minibatches&#160;of 100 cases&#160;to&#160;estimate&#160;the&#160;<br/>
first&#160;term in the gradient.&#160;Use&#160;a single&#160;batch&#160;of&#160;<br/>100 fantasies to estimate the&#160;second&#160;term in the&#160;<br/>gradient.&#160;<br/>
•&#160;After&#160;each&#160;weight&#160;update,&#160;generate&#160;the&#160;new&#160;<br/>
fantasies&#160;from the previous&#160;fantasies by using&#160;<br/>one alternating&#160;Gibbs&#160;update.<br/>
–&#160;So&#160;the&#160;fantasies&#160;can get far from&#160;the&#160;data.<br/>
<hr/>
<a name=52></a>Contrastive&#160;divergence&#160;as an&#160;<br/>
adversarial&#160;game<br/>
•&#160;Why&#160;does&#160;persisitent CD work&#160;so&#160;well&#160;with&#160;only&#160;<br/>
100 negative&#160;examples&#160;to characterize the&#160;<br/>whole&#160;partition function?<br/>
–&#160;For&#160;all interesting problems&#160;the&#160;partition&#160;<br/>
function&#160;is&#160;highly&#160;multi-modal.<br/>
–&#160;How does&#160;it&#160;manage&#160;to find all&#160;the&#160;modes&#160;<br/>
without starting at the data?&#160;<br/>
<hr/>
<a name=53></a>The&#160;learning&#160;causes&#160;very fast mixing<br/>
•&#160;The learning&#160;interacts&#160;with the Markov&#160;chain.<br/>
•&#160;Persisitent&#160;Contrastive&#160;Divergence&#160;cannot&#160;be&#160;<br/>
analysed&#160;by viewing&#160;the&#160;learning&#160;as&#160;an&#160;outer loop.<br/>
–&#160;Wherever the&#160;fantasies&#160;outnumber&#160;the&#160;<br/>
positive&#160;data,&#160;the free-energy&#160;surface&#160;is&#160;<br/>raised. This&#160;makes the&#160;fantasies&#160;rush around&#160;<br/>hyperactively.<br/>
<hr/>
<a name=54></a><img src="./Hinton_1-54_1.png"/><br/>
<img src="./Hinton_1-54_2.png"/><br/>
<img src="./Hinton_1-54_3.png"/><br/>
<img src="./Hinton_1-54_4.png"/><br/>
<img src="./Hinton_1-54_5.png"/><br/>
<img src="./Hinton_1-54_6.png"/><br/>
<img src="./Hinton_1-54_7.png"/><br/>
<img src="./Hinton_1-54_8.png"/><br/>
How&#160;persistent CD moves between&#160;the&#160;<br/>
modes&#160;of the&#160;model’s&#160;distribution<br/>
•&#160;If&#160;a mode&#160;has&#160;more&#160;fantasy&#160;<br/>
particles&#160;than data, the free-<br/>energy&#160;surface&#160;is raised&#160;until&#160;<br/>the&#160;fantasy particles&#160;escape.<br/>
–&#160;This&#160;can&#160;overcome&#160;&#160;free-<br/>
energy&#160;barriers&#160;that&#160;would&#160;<br/>be&#160;too&#160;high&#160;for the&#160;Markov&#160;<br/>Chain&#160;to&#160;jump.<br/>
•&#160;The&#160;free-energy&#160;surface&#160;is&#160;<br/>
being&#160;changed&#160;to&#160;help&#160;<br/>mixing&#160;in&#160;addition&#160;to&#160;defining&#160;<br/>the&#160;model.<br/>
<hr/>
<a name=55></a>Summary so&#160;far<br/>
•&#160;Restricted&#160;Boltzmann&#160;Machines&#160;provide&#160;a simple&#160;way&#160;to&#160;<br/>
learn a layer of features&#160;without&#160;any supervision.<br/>
–&#160;Maximum&#160;likelihood&#160;learning&#160;is computationally&#160;<br/>
expensive&#160;because&#160;of the&#160;normalization&#160;term,&#160;but&#160;<br/>contrastive&#160;divergence&#160;learning&#160;is fast&#160;and&#160;usually&#160;<br/>works well.<br/>
•&#160;Many&#160;layers&#160;of representation&#160;can be learned&#160;by treating&#160;<br/>
the&#160;hidden&#160;states&#160;of one&#160;RBM&#160;as&#160;the visible&#160;data for&#160;<br/>training the next&#160;RBM&#160;(a composition&#160;of experts).<br/>
•&#160;This&#160;creates good&#160;generative&#160;models&#160;that&#160;can then be&#160;<br/>
fine-tuned.<br/>
–&#160;Contrastive&#160;wake-sleep&#160;can&#160;fine-tune generation.<br/>
<hr/>
<a name=56></a>BREAK<br/>
<hr/>
<a name=57></a>Overview&#160;of the rest of&#160;the tutorial<br/>
•&#160;How to&#160;fine-tune a&#160;greedily&#160;trained&#160;generative&#160;<br/>
model&#160;to&#160;be&#160;better at discrimination.<br/>
•&#160;How to&#160;learn a&#160;kernel for&#160;a Gaussian&#160;process.<br/>•&#160;How to&#160;use deep&#160;belief nets&#160;for&#160;non-linear&#160;<br/>
dimensionality&#160;reduction and&#160;document&#160;retrieval.<br/>
•&#160;How to&#160;learn a&#160;generative hierarchy&#160;of&#160;<br/>
conditional&#160;random&#160;fields.<br/>
•&#160;A&#160;more&#160;advanced&#160;learning&#160;module&#160;for&#160;deep&#160;<br/>
belief nets&#160;that contains&#160;multiplicative&#160;<br/>interactions.<br/>
•&#160;How to&#160;learn deep&#160;models&#160;of&#160;sequential data.<br/>
<hr/>
<a name=58></a>Fine-tuning&#160;for discrimination<br/>
•&#160;First learn one&#160;layer at a&#160;time&#160;greedily.<br/>•&#160;Then&#160;treat this&#160;as&#160;“pre-training”&#160;that finds&#160;a good&#160;<br/>
initial&#160;set of weights&#160;which can&#160;be&#160;fine-tuned&#160;by&#160;&#160;<br/>a local&#160;search procedure.<br/>
–&#160;Contrastive wake-sleep&#160;is&#160;one way&#160;of fine-<br/>
tuning the&#160;model&#160;to be&#160;better at generation.<br/>
•&#160;Backpropagation&#160;can&#160;be&#160;used&#160;to&#160;fine-tune the&#160;<br/>
model&#160;for better&#160;discrimination.<br/>
–&#160;This overcomes&#160;many&#160;of the&#160;limitations&#160;of&#160;<br/>
standard&#160;backpropagation.<br/>
<hr/>
<a name=59></a>Why&#160;backpropagation&#160;works&#160;better&#160;with&#160;<br/>
greedy&#160;pre-training:&#160;The&#160;optimization&#160;view<br/>
•&#160;Greedily&#160;learning&#160;one&#160;layer at a&#160;time scales well&#160;<br/>
to&#160;really&#160;big networks,&#160;especially&#160;if&#160;we have&#160;<br/>locality&#160;in&#160;each layer.<br/>
•&#160;We do&#160;not start backpropagation&#160;until&#160;we&#160;already&#160;<br/>
have&#160;sensible&#160;feature&#160;detectors that should&#160;<br/>already be&#160;very&#160;helpful&#160;for the&#160;discrimination&#160;task.<br/>
–&#160;So&#160;the&#160;initial&#160;gradients&#160;are sensible and&#160;<br/>
backprop&#160;only needs to&#160;perform&#160;a&#160;local&#160;search&#160;<br/>from&#160;a sensible starting point.<br/>
<hr/>
<a name=60></a>Why&#160;backpropagation&#160;works&#160;better&#160;with&#160;<br/>
greedy&#160;pre-training:&#160;The&#160;overfitting&#160;view<br/>
•&#160;Most&#160;of&#160;the information&#160;in&#160;the&#160;final&#160;weights&#160;comes&#160;from&#160;<br/>
modeling&#160;the&#160;distribution&#160;of&#160;input&#160;vectors.&#160;<br/>
–&#160;The&#160;input&#160;vectors &#160;generally&#160;contain&#160;a&#160;lot&#160;more&#160;<br/>
information&#160;than&#160;the&#160;labels.<br/>
–&#160;The&#160;precious&#160;information&#160;in&#160;the&#160;labels&#160;is only&#160;used&#160;for&#160;<br/>
the&#160;final&#160;fine-tuning.&#160;<br/>
–&#160;The&#160;fine-tuning&#160;only&#160;modifies&#160;the&#160;features&#160;slightly&#160;to get&#160;<br/>
the&#160;category boundaries&#160;right. It&#160;does not&#160;need&#160;to&#160;<br/>discover&#160;features.<br/>
•&#160;This&#160;type of&#160;backpropagation&#160;works well&#160;even&#160;if&#160;most of&#160;<br/>
the&#160;training&#160;data is unlabeled.&#160;<br/>
–&#160;The&#160;unlabeled&#160;data is still&#160;very useful&#160;for&#160;discovering&#160;<br/>
good features.<br/>
<hr/>
<a name=61></a>First,&#160;model the&#160;distribution&#160;of&#160;digit&#160;images<br/>
The&#160;top&#160;two&#160;layers&#160;form&#160;a restricted&#160;<br/>
2000&#160;units<br/>
Boltzmann&#160;machine&#160;whose&#160;free&#160;energy&#160;<br/>landscape&#160;should&#160;model&#160;the&#160;low&#160;<br/>dimensional&#160;manifolds&#160;of&#160;the&#160;digits.<br/>
500 units&#160;<br/>
The&#160;network learns&#160;a density&#160;model&#160;for&#160;<br/>unlabeled&#160;digit&#160;images. When&#160;we&#160;generate&#160;<br/>from&#160;the model&#160;we&#160;get things&#160;that look like&#160;<br/>
500 units&#160;<br/>
real digits of all&#160;classes.&#160;<br/>
But&#160;do the hidden&#160;features&#160;really&#160;help&#160;with&#160;<br/>digit discrimination?&#160;<br/>
28&#160;x&#160;28&#160;<br/>pixel&#160;&#160;&#160;&#160;&#160;<br/>
Add&#160;10&#160;softmaxed units&#160;to the&#160;top&#160;and&#160;do&#160;<br/>
image<br/>
backpropagation.<br/>
<hr/>
<a name=62></a>Results&#160;on&#160;permutation-invariant&#160;MNIST&#160;task<br/>
•&#160;Very&#160;carefully&#160;trained&#160;backprop&#160;net with&#160; &#160; &#160; 1.6%&#160;<br/>
one&#160;or&#160;two hidden&#160;layers&#160;(Platt;&#160;Hinton)<br/>
•&#160;SVM&#160;(Decoste &amp; Schoelkopf,&#160;2002) &#160;&#160; &#160;&#160; &#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;1.4%<br/>
•&#160;Generative model&#160;of&#160;joint density&#160;of &#160; &#160;&#160;&#160; &#160; &#160;&#160; &#160;1.25%&#160;<br/>
images&#160;and labels&#160;(+&#160;generative&#160;fine-tuning)<br/>
•&#160;Generative&#160;model&#160;of unlabelled&#160;digits&#160; &#160;&#160;&#160; &#160; &#160;&#160;1.15%&#160;<br/>
followed&#160;by&#160;gentle backpropagation&#160;&#160; &#160; &#160;&#160; &#160; &#160;&#160; &#160;&#160;&#160;&#160;<br/>(Hinton &amp; Salakhutdinov,&#160;Science&#160;2006)<br/>
<hr/>
<a name=63></a><img src="./Hinton_1-63_1.png"/><br/>
<img src="./Hinton_1-63_2.png"/><br/>
Learning&#160;Dynamics&#160;of&#160;Deep&#160;Nets<br/>
the&#160;next&#160;4&#160;slides&#160;describe&#160;work&#160;by Yoshua&#160;Bengio’s&#160;group<br/>
Before&#160;fine-tuning<br/>
After&#160;fine-tuning<br/>
<hr/>
<a name=64></a><img src="./Hinton_1-64_1.png"/><br/>
<img src="./Hinton_1-64_2.png"/><br/>
Effect of&#160;Unsupervised&#160;Pre-training<br/>
Erhan&#160;et.&#160;al.&#160;&#160;&#160;&#160;AISTATS’2009&#160;<br/>
64<br/>
<hr/>
<a name=65></a><img src="./Hinton_1-65_1.png"/><br/>
<img src="./Hinton_1-65_2.png"/><br/>
Effect of&#160;Depth<br/>
without&#160;pre-training<br/>
with&#160;pre-training<br/>
w/o&#160;pre-training<br/>
65<br/>
<hr/>
<a name=66></a><img src="./Hinton_1-66_1.jpg"/><br/>
Learning&#160;Trajectories&#160;in Function&#160;Space&#160;<br/>
(a&#160;2-D visualization&#160;produced&#160;with t-SNE)<br/>
Erhan&#160;et.&#160;al.&#160; &#160; AISTATS’2009&#160;<br/>
•&#160;Each&#160;point&#160;is a&#160;<br/>
model&#160;in function&#160;<br/>space<br/>
•&#160;Color&#160;= epoch<br/>•&#160;Top:&#160;trajectories &#160;&#160;&#160;&#160;&#160;<br/>
without&#160;pre-training.&#160;<br/>Each&#160;trajectory&#160;<br/>converges to&#160;a&#160;<br/>different&#160;local&#160;min.<br/>
•&#160;Bottom:&#160;Trajectories&#160;<br/>
with pre-training.&#160;<br/>
•&#160;No&#160;overlap!<br/>
<hr/>
<a name=67></a><img src="./Hinton_1-67_1.png"/><br/>
<img src="./Hinton_1-67_2.png"/><br/>
<img src="./Hinton_1-67_3.png"/><br/>
<img src="./Hinton_1-67_4.png"/><br/>
Why&#160;unsupervised&#160;pre-training&#160;makes&#160;sense<br/>
stuff<br/>
stuff<br/>
high&#160;<br/>
low&#160;<br/>
bandwidth<br/>
bandwidth<br/>
image<br/>
label<br/>
image<br/>
label<br/>
If&#160;image-label&#160;pairs&#160;were&#160;<br/>
If&#160;image-label&#160;pairs&#160;are&#160;<br/>
generated this way,&#160;it&#160;<br/>
generated this way,&#160;it&#160;<br/>
would&#160;make sense&#160;to&#160;try&#160;<br/>
makes&#160;sense&#160;to&#160;first&#160;learn&#160;<br/>
to&#160;go&#160;straight from&#160;<br/>
to&#160;recover&#160;the&#160;stuff&#160;that&#160;<br/>
images to&#160;labels.&#160;&#160;<br/>
caused the&#160;image&#160;by&#160;<br/>
For&#160;example,&#160;&#160;do the&#160;<br/>
inverting the high&#160;<br/>
pixels&#160;have&#160;even&#160;parity?<br/>
bandwidth&#160;pathway.<br/>
<hr/>
<a name=68></a>Modeling&#160;real-valued&#160;data<br/>
•&#160;For&#160;images&#160;of digits&#160;it&#160;is possible&#160;to represent&#160;<br/>
intermediate intensities&#160;as if&#160;they&#160;were&#160;probabilities&#160;by&#160;<br/>using “mean-field”&#160;logistic&#160;units.<br/>
–&#160;We&#160;can treat&#160;intermediate&#160;values&#160;as the&#160;probability&#160;<br/>
that&#160;the&#160;pixel&#160;is inked.<br/>
•&#160;This&#160;will&#160;not work for&#160;real&#160;images.<br/>
–&#160;In&#160;a real image, the intensity of&#160;a&#160;pixel&#160;is almost&#160;<br/>
always&#160;almost exactly&#160;the&#160;average&#160;of the&#160;neighboring&#160;<br/>pixels.<br/>
–&#160;Mean-field&#160;logistic&#160;units cannot&#160;represent precise&#160;<br/>
intermediate values.<br/>
<hr/>
<a name=69></a>Replacing&#160;binary&#160;variables&#160;by&#160;<br/>
integer-valued&#160;variables<br/>
(Teh&#160;and&#160;Hinton,&#160;2001)<br/>
•&#160;One way&#160;to&#160;model&#160;an&#160;integer-valued&#160;variable is&#160;<br/>
to&#160;make&#160;N identical&#160;copies&#160;of a binary&#160;unit.&#160;<br/>
•&#160;All copies&#160;have&#160;the&#160;same&#160;probability, &#160; &#160;&#160; &#160;&#160;&#160; &#160; &#160;&#160; &#160; &#160;&#160; &#160; &#160;&#160; &#160; &#160;&#160; &#160;<br/>
of&#160;being&#160;“on”&#160;: &#160;p =&#160;logistic(x)<br/>
–&#160;The&#160;total&#160;number&#160;of&#160;“on”&#160;copies&#160;is&#160;like the&#160;<br/>
firing rate of a neuron.<br/>
–&#160;It&#160;has a &#160;binomial&#160;distribution&#160;with&#160;mean&#160;N&#160;p&#160;<br/>
and variance&#160;N&#160;p(1-p)<br/>
<hr/>
<a name=70></a>A&#160;better&#160;way&#160;to&#160;implement integer values<br/>
•&#160;Make&#160;many copies&#160;of a&#160;binary&#160;unit.&#160;<br/>•&#160;All copies&#160;have&#160;the&#160;same weights&#160;and&#160;the same&#160;<br/>
adaptive bias,&#160;b,&#160;but they&#160;have&#160;different&#160;fixed&#160;offsets&#160;to&#160;<br/>the&#160;bias:<br/>
<i>b&#160;</i><br/>
,<br/>
5<br/>
.<br/>
0<br/>
<i>b&#160;</i><br/>
,<br/>
5<br/>
.<br/>
1<br/>
<i>b&#160;</i><br/>
,<br/>
5<br/>
.<br/>
2<br/>
<i>b&#160;</i><br/>
,<br/>
5<br/>
.<br/>
3<br/>
....<br/>
<i>x&#160;</i><br/>
<hr/>
<a name=71></a>A&#160;fast&#160;approximation<br/>
<i>n</i><br/>
logisti&#160;(<br/>
c&#160;<i>x&#160;</i><br/>
5<br/>
.<br/>
0&#160;&#160;<i>n</i>)<br/>
<br/>
log&#160;1<br/>
(<br/>
<i>x</i><br/>
&#160;<i>e&#160;</i>)<br/>
<br/>
<i>n&#160;</i>1<br/>
<br/>
•&#160;Contrastive&#160;divergence&#160;learning&#160;works&#160;well&#160;for the sum of&#160;<br/>
binary&#160;units&#160;with&#160;offset&#160;biases.<br/>
•&#160;It&#160;also&#160;works&#160;for&#160;rectified linear&#160;units.&#160;These are much faster&#160;<br/>
to&#160;compute than the&#160;sum&#160;of&#160;many logistic&#160;units.<br/>
output&#160;= max(0,&#160;&#160;x&#160;+&#160;randn*sqrt(logistic(x))&#160;&#160;)<br/>
<hr/>
<a name=72></a>How&#160;to&#160;train&#160;a&#160;bipartite&#160;network&#160;of&#160;rectified&#160;<br/>
linear&#160;units<br/>
•&#160;Just&#160;use contrastive&#160;divergence&#160;to lower&#160;the&#160;energy&#160;of&#160;<br/>
data&#160;and raise&#160;the&#160;energy&#160;of&#160;nearby&#160;configurations&#160;that&#160;<br/>the&#160;model&#160;prefers to&#160;the data.<br/>
Start&#160;with a&#160;training&#160;vector&#160;on&#160;the&#160;<br/>
j<br/>
j<br/>
visible&#160;units.<br/>
<i>v&#160;h&#160;</i><br/>
Update&#160;all&#160;hidden&#160;units&#160;in parallel&#160;<br/>
<i>i</i><br/>
<i>j</i><br/>
data<br/>
<i>v&#160;h&#160;</i><br/>
<i>i</i><br/>
<i>j</i><br/>
recon<br/>
with&#160;sampling&#160;noise<br/>
Update&#160;the&#160;visible&#160;units&#160;in parallel&#160;<br/>
i<br/>
i<br/>
to&#160;get&#160;a “reconstruction”.<br/>
data<br/>
reconstruction<br/>
Update&#160;the&#160;hidden&#160;units&#160;again<br/>
<i>w&#160;</i>&#160;&#160;(&#160;<i>v&#160;h&#160;</i><br/>
&#160;<i>v&#160;h&#160;</i><br/>
)<br/>
<i>ij</i><br/>
<i>i</i><br/>
<i>j</i><br/>
data<br/>
<i>i</i><br/>
<i>j</i><br/>
recon<br/>
<hr/>
<a name=73></a><img src="./Hinton_1-73_1.jpg"/><br/>
<b>3D Object&#160;Recognition:&#160;The&#160;NORB&#160;dataset</b><br/>
<b>Stereo-pairs&#160;of grayscale&#160;images of&#160;toy&#160;objects.</b><br/>
<b>Animals</b><br/>
<b>Humans</b><br/>
<b>Normalized-</b><br/>
<b>Planes</b><br/>
<b>uniform&#160;<br/>version&#160;of&#160;<br/>NORB</b><br/>
<b>Trucks</b><br/>
<b>Cars</b><br/>
<b>-&#160;6 lighting&#160;conditions,&#160;162&#160;viewpoints<br/></b>-<b>Five&#160;object instances per class in&#160;the training&#160;set<br/></b>-&#160;<b>A&#160;<i>different&#160;</i></b><b>set of&#160;five&#160;instances per&#160;class&#160;in&#160;the&#160;test&#160;set<br/>-&#160;24,300&#160;training&#160;cases,&#160;24,300&#160;test cases</b><br/>
<hr/>
<a name=74></a>Simplifying&#160;the data<br/>
•&#160;Each&#160;training case&#160;is a stereo-pair&#160;of 96x96&#160;images.<br/>
–&#160;The&#160;object&#160;is centered.<br/>–&#160;The&#160;edges&#160;of&#160;the&#160;image&#160;are mainly&#160;blank.<br/>–&#160;The&#160;background&#160;is uniform&#160;and bright.<br/>
•&#160;To&#160;make&#160;learning&#160;faster I used&#160;simplified&#160;the&#160;data:<br/>
–&#160;Throw&#160;away&#160;one image.<br/>–&#160;Only&#160;use the middle&#160;64x64&#160;pixels&#160;of the&#160;other&#160;<br/>
image.<br/>
–&#160;Downsample&#160;to 32x32&#160;by&#160;averaging&#160;4&#160;pixels.<br/>
<hr/>
<a name=75></a>Simplifying&#160;the&#160;data&#160;even&#160;more&#160;so&#160;that&#160;it&#160;can&#160;<br/>
be&#160;modeled&#160;by&#160;rectified&#160;linear units<br/>
•&#160;The&#160;intensity&#160;histogram for each 32x32&#160;image&#160;has a&#160;<br/>
sharp&#160;peak&#160;for&#160;the bright background.<br/>
•&#160;Find this&#160;peak&#160;and&#160;call&#160;it&#160;zero.<br/>•&#160;Call&#160;all&#160;intensities&#160;brighter&#160;than&#160;the background&#160;zero.<br/>•&#160;Measure intensities&#160;downwards&#160;from&#160;the background&#160;<br/>
intensity.<br/>
0<br/>
<hr/>
<a name=76></a>Test&#160;set&#160;error&#160;rates on NORB&#160;after greedy&#160;<br/>
learning&#160;of&#160;one&#160;or&#160;two&#160;hidden&#160;layers&#160;using&#160;<br/>
rectified&#160;linear units&#160;<br/>
Full&#160;NORB&#160;(2 images&#160;of&#160;96x96)<br/>•&#160;Logistic regression&#160;on&#160;the&#160;raw&#160;pixels&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160;20.5%<br/>•&#160;Gaussian SVM&#160;(trained by Leon&#160;Bottou) &#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160; 11.6%<br/>•&#160;Convolutional&#160;neural&#160;net &#160;(Le Cun’s&#160;group)&#160;&#160; &#160;&#160; &#160;&#160;6.0%<br/>
(convolutional&#160;nets&#160;have&#160;knowledge&#160;of translations&#160;built&#160;in)&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160; &#160;&#160;<br/>
Reduced&#160;NORB&#160;(1&#160;image&#160;32x32)<br/>•&#160;Logistic regression&#160;on the&#160;raw&#160;pixels&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; 30.2%<br/>•&#160;Logistic regression&#160;on first&#160;hidden&#160;layer&#160;&#160; &#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;14.9%&#160;<br/>•&#160;Logistic regression&#160;on second&#160;hidden&#160;layer&#160;&#160; &#160;&#160;&#160;10.2%<br/>
<hr/>
<a name=77></a><img src="./Hinton_1-77_1.jpg"/><br/>
The&#160;<br/>receptive&#160;<br/>fields of&#160;<br/>some&#160;<br/>rectified&#160;<br/>linear&#160;<br/>hidden&#160;<br/>units.<br/>
<hr/>
<a name=78></a>A&#160;standard type of real-valued&#160;visible unit<br/>
•&#160;We&#160;can model&#160;pixels&#160;as&#160;<br/>
Gaussian variables.&#160;<br/>
<br/>
Alternating Gibbs&#160;<br/>
E&#160;<br/>
sampling&#160;is still&#160;easy,&#160;<br/>though learning&#160;needs&#160;to&#160;<br/>be&#160;much slower.<br/>
<i>b</i><br/>
<i>v&#160;</i><br/>
<i>i</i><br/>
<i>i</i><br/>
energy-gradient&#160;<br/>
parabolic&#160;<br/>
produced&#160;by&#160;the&#160;total&#160;<br/>
containment&#160;<br/>
input&#160;to&#160;a&#160;visible&#160;unit<br/>
function<br/>
(<br/>
<br/>
2<br/>
<i>i</i><br/>
<i>v</i><br/>
<i>i</i><br/>
<i>b&#160;</i>)<br/>
<i>i</i><br/>
<i>v</i><br/>
<i>E</i>(&#160;<i>,</i><br/>
<b>v&#160;h</b>)&#160;&#160;<br/>
<br/>
2<br/>
<i>b</i><br/>
&#160;<br/>
<i>j&#160;h&#160;j</i><br/>
<i>h&#160;j&#160;ij</i><br/>
<i>w</i><br/>
<br/>
<i>i&#160;</i><br/>
<br/>
<i>vis</i><br/>
2&#160;<i>i</i><br/>
<i>j&#160;</i>&#160;<i>hid</i><br/>
<i>i</i>,&#160;<i>j</i><br/>
<i>i</i><br/>
Welling&#160;et.&#160;al. (2005) show&#160;how&#160;to extend&#160;RBM’s&#160;to the&#160;<br/>exponential&#160;family.&#160;See also&#160;Bengio&#160;et.&#160;al. (2007)<br/>
<hr/>
<a name=79></a><img src="./Hinton_1-79_1.png"/><br/>
A&#160;random&#160;sample&#160;of 10,000&#160;binary&#160;filters learned&#160;<br/>
by&#160;Alex&#160;Krizhevsky&#160;on a million&#160;32x32&#160;color&#160;images.<br/>
<hr/>
<a name=80></a>Combining&#160;deep&#160;belief nets&#160;with&#160;Gaussian processes<br/>
•&#160;Deep belief&#160;nets&#160;can benefit a&#160;lot&#160;from&#160;unlabeled&#160;data&#160;<br/>
when&#160;labeled&#160;data is scarce.<br/>
–&#160;They&#160;just use the labeled&#160;data for fine-tuning.<br/>
•&#160;Kernel methods,&#160;like&#160;Gaussian&#160;processes, work&#160;well&#160;on&#160;<br/>
small&#160;labeled&#160;training&#160;sets&#160;but are slow&#160;for&#160;large&#160;training&#160;<br/>sets.<br/>
•&#160;So&#160;when&#160;there is a lot of unlabeled&#160;data and only&#160;a little&#160;<br/>
labeled&#160;data, combine&#160;the&#160;two approaches:<br/>
–&#160;First&#160;learn&#160;a&#160;deep&#160;belief&#160;net&#160;without&#160;using&#160;the labels.<br/>–&#160;Then&#160;apply&#160;a Gaussian&#160;process model&#160;to the&#160;deepest&#160;<br/>
layer of&#160;features.&#160;This works better than using&#160;the&#160;raw&#160;<br/>data.<br/>
–&#160;Then&#160;use&#160;GP’s&#160;to get the derivatives&#160;that are back-<br/>
propagated&#160;through the&#160;deep&#160;belief&#160;net.&#160;This&#160;is a&#160;<br/>
further&#160;win.&#160;It&#160;allows&#160;GP’s&#160;to fine-tune&#160;complicated&#160;<br/>domain-specific&#160;kernels.<br/>
<hr/>
<a name=81></a><img src="./Hinton_1-81_1.jpg"/><br/>
Learning&#160;to extract the orientation of a face patch&#160;<br/>
(Salakhutdinov&#160;&amp; Hinton,&#160;NIPS&#160;2007)<br/>
<hr/>
<a name=82></a><img src="./Hinton_1-82_1.jpg"/><br/>
<img src="./Hinton_1-82_2.jpg"/><br/>
The&#160;training&#160;and test sets for predicting&#160;<br/>
face&#160;orientation<br/>
100,&#160;500,&#160;or&#160;1000&#160;labeled&#160;cases<br/>
11,000&#160;unlabeled&#160;cases<br/>
face&#160;patches&#160;from&#160;new&#160;people<br/>
<hr/>
<a name=83></a>The root&#160;mean&#160;squared&#160;error&#160;in&#160;the&#160;orientation&#160;<br/>
when&#160;combining&#160;GP’s with&#160;deep&#160;belief nets<br/>
GP&#160;on&#160;<br/>
GP&#160;on&#160;<br/>
GP&#160;on top-level&#160;<br/>
the&#160;<br/>
top-level&#160;<br/>
features&#160;with&#160;<br/>
pixels<br/>
features<br/>
fine-tuning<br/>
100&#160;labels&#160;22.2&#160;&#160; &#160;&#160;&#160; &#160;&#160;17.9&#160;&#160; &#160;&#160; &#160;&#160; &#160;15.2<br/>
500 labels&#160;17.2&#160;&#160; &#160;&#160;&#160; &#160;&#160;12.7&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160; &#160;7.2<br/>
1000&#160;labels&#160;16.3&#160;&#160; &#160;&#160;&#160; &#160;&#160;11.2&#160; &#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;6.4<br/>
Conclusion:&#160;The&#160;deep&#160;features&#160;are much&#160;better&#160;<br/>than the&#160;pixels. Fine-tuning&#160;helps&#160;a lot.<br/>
<hr/>
<a name=84></a>Deep&#160;Autoencoders<br/>
28x28<br/>
<i>T</i><br/>
(Hinton &amp; Salakhutdinov,&#160;2006)<br/>
1<br/>
<i>W</i><br/>
1000&#160;&#160;neurons<br/>
•&#160;They&#160;always&#160;looked&#160;like&#160;a&#160;really&#160;<br/>
<i>W&#160;T</i><br/>
2<br/>
nice way to&#160;do&#160;non-linear&#160;<br/>
500 neurons<br/>
dimensionality&#160;reduction:<br/>
<i>T</i><br/>
3<br/>
<i>W</i><br/>
–&#160;But&#160;it&#160;is&#160;very&#160;difficult&#160;to&#160;<br/>
250 neurons<br/>
optimize deep&#160;autoencoders&#160;<br/>
<i>W&#160;T</i><br/>
4<br/>
using&#160;backpropagation.<br/>
linear&#160;<br/>
30<br/>
units<br/>
•&#160;We&#160;now&#160;have&#160;a&#160;much better way&#160;<br/>
<i>W</i>4<br/>
to&#160;optimize&#160;them:<br/>
250 neurons<br/>
–&#160;First&#160;train&#160;a stack&#160;of 4&#160;RBM’s<br/>
<i>W</i>3<br/>
–&#160;Then&#160;“unroll”&#160;them.&#160;&#160;<br/>
500 neurons<br/>
–<br/>
<i>W</i><br/>
Then&#160;fine-tune&#160;with&#160;backprop.<br/>
2<br/>
1000&#160;&#160;neurons<br/>
<i>W</i>1<br/>
28x28<br/>
<hr/>
<a name=85></a><img src="./Hinton_1-85_1.jpg"/><br/>
A&#160;comparison&#160;of&#160;methods&#160;for&#160;compressing&#160;<br/>
digit&#160;images to 30&#160;real numbers.<br/>
real&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<br/>data<br/>
30-D&#160;&#160;&#160;&#160;&#160;&#160;&#160;<br/>deep&#160;auto<br/>
30-D&#160;logistic&#160;<br/>PCA<br/>
30-D&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;<br/>PCA<br/>
<hr/>
<a name=86></a>Retrieving&#160;documents&#160;that are similar&#160;<br/>
to&#160;a query document<br/>
•&#160;We can&#160;use an autoencoder&#160;to find low-<br/>
dimensional&#160;codes&#160;for&#160;documents&#160;that allow&#160;<br/>fast&#160;and accurate&#160;retrieval&#160;of&#160;similar&#160;<br/>documents&#160;from&#160;a large&#160;set.<br/>
•&#160;We start&#160;by&#160;converting&#160;each&#160;document&#160;into&#160;a&#160;<br/>
“bag&#160;of&#160;words”. &#160;This&#160;a&#160;2000&#160;dimensional&#160;<br/>vector&#160;that contains&#160;the counts&#160;for&#160;each&#160;of&#160;the&#160;<br/>2000&#160;commonest&#160;words.<br/>
<hr/>
<a name=87></a>How&#160;to compress&#160;the count vector&#160;<br/>
output&#160;<br/>
2000&#160;&#160;reconstructed&#160;counts<br/>
vector<br/>
•&#160;We&#160;train&#160;the&#160;neural&#160;<br/>
500 neurons<br/>
network&#160;to&#160;reproduce&#160;its&#160;<br/>input vector as&#160;its&#160;output<br/>
250&#160;neurons<br/>
•&#160;This&#160;forces it&#160;to&#160;<br/>
compress as much&#160;<br/>
10<br/>
information as possible&#160;<br/>into the&#160;10&#160;numbers in&#160;<br/>the&#160;central&#160;bottleneck.<br/>
250&#160;neurons<br/>
•&#160;These&#160;10&#160;numbers are&#160;<br/>
then&#160;a&#160;good&#160;way to&#160;<br/>
500&#160;neurons<br/>
compare documents.<br/>
input&#160;<br/>
2000&#160;&#160;word&#160;counts<br/>
vector<br/>
<hr/>
<a name=88></a>Performance&#160;of&#160;the&#160;autoencoder&#160;at&#160;<br/>
document&#160;retrieval<br/>
•&#160;Train&#160;on&#160;bags of 2000&#160;words&#160;for&#160;400,000&#160;training&#160;cases&#160;<br/>
of&#160;business&#160;documents.<br/>
–&#160;First&#160;train&#160;a stack&#160;of RBM’s. Then fine-tune&#160;with&#160;<br/>
backprop.<br/>
•&#160;Test&#160;on a separate 400,000&#160;documents.&#160;<br/>
–&#160;Pick&#160;one&#160;test&#160;document&#160;as a query.&#160;Rank&#160;order all&#160;the&#160;<br/>
other&#160;test documents by using&#160;the&#160;cosine&#160;of&#160;the&#160;angle&#160;<br/>between codes.&#160;<br/>
–&#160;Repeat&#160;this using&#160;each&#160;of the&#160;400,000&#160;test&#160;documents&#160;<br/>
as&#160;the&#160;query&#160;(requires&#160;0.16 trillion&#160;comparisons).<br/>
•&#160;Plot the&#160;number&#160;of retrieved documents&#160;against&#160;the&#160;<br/>
proportion that are in the same&#160;hand-labeled&#160;class as&#160;the&#160;<br/>query document.&#160;<br/>
<hr/>
<a name=89></a><img src="./Hinton_1-89_1.jpg"/><br/>
Proportion&#160;of retrieved documents&#160;in&#160;same class&#160;as&#160;query<br/>
Number&#160;of&#160;documents&#160;retrieved<br/>
<hr/>
<a name=90></a><img src="./Hinton_1-90_1.jpg"/><br/>
First&#160;compress&#160;all&#160;documents&#160;to 2&#160;numbers&#160;using&#160;a&#160;type of&#160;PCA&#160;&#160; &#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160;<br/>Then&#160;use&#160;different colors&#160;for&#160;different&#160;document&#160;categories<br/>
<hr/>
<a name=91></a><img src="./Hinton_1-91_1.jpg"/><br/>
First&#160;compress&#160;all&#160;documents&#160;to 2&#160;numbers.&#160; &#160;&#160;&#160;&#160; &#160;&#160;&#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160; &#160;&#160;&#160;&#160;<br/>
Then&#160;use&#160;different colors&#160;for&#160;different&#160;document&#160;categories<br/>
<hr/>
<a name=92></a>Finding&#160;binary&#160;codes&#160;for&#160;documents<br/>
2000&#160;&#160;reconstructed&#160;counts<br/>
•&#160;Train&#160;an&#160;auto-encoder&#160;using&#160;30&#160;<br/>
logistic&#160;units&#160;for&#160;the code layer.<br/>
500&#160;neurons<br/>
•&#160;During&#160;the&#160;fine-tuning&#160;stage,&#160;<br/>
add&#160;noise&#160;to the&#160;inputs&#160;to the&#160;<br/>code&#160;units.<br/>
250&#160;neurons<br/>
–&#160;The&#160;“noise”&#160;vector for&#160;each&#160;<br/>
training case&#160;is fixed. So we&#160;<br/>still get a&#160;deterministic&#160;<br/>
30<br/>
gradient.&#160;<br/>
noise<br/>
–&#160;The&#160;noise&#160;forces their&#160;<br/>
activities &#160;to&#160;become&#160;bimodal&#160;<br/>
250&#160;neurons<br/>
in&#160;order&#160;to resist&#160;the&#160;effects&#160;<br/>of&#160;the&#160;noise.<br/>
–<br/>
500&#160;neurons<br/>
Then&#160;we&#160;simply&#160;round&#160;the&#160;<br/>activities of the&#160;30 code&#160;units&#160;<br/>to&#160;1 or 0.<br/>
2000&#160;&#160;word&#160;counts<br/>
<hr/>
<a name=93></a><img src="./Hinton_1-93_1.jpg"/><br/>
Semantic&#160;hashing:&#160;Using a&#160;deep&#160;autoencoder&#160;as&#160;a&#160;<br/>
hash-function for&#160;finding&#160;approximate&#160;matches&#160;<br/>
(Salakhutdinov &amp; Hinton,&#160;2007)<br/>
hash&#160;<br/>function<br/>
“supermarket&#160;search”<br/>
<hr/>
<a name=94></a>How&#160;good&#160;is a&#160;shortlist&#160;found&#160;this&#160;way?&#160;<br/>
•&#160;We have only&#160;implemented&#160;it&#160;for&#160;a million&#160;<br/>
documents&#160;with&#160;20-bit codes&#160;---&#160;but what could&#160;<br/>possibly&#160;go&#160;wrong?<br/>
–&#160;A&#160;20-D&#160;hypercube allows&#160;us&#160;to capture&#160;enough&#160;<br/>
of&#160;the&#160;similarity&#160;structure of our&#160;document&#160;set.&#160;<br/>
•&#160;The shortlist found&#160;using&#160;binary&#160;codes&#160;actually&#160;<br/>
improves&#160;the precision-recall&#160;curves&#160;of TF-IDF.<br/>
–&#160;Locality&#160;sensitive&#160;hashing&#160;(the fastest&#160;other&#160;<br/>
method)&#160;is 50 times&#160;slower&#160;and&#160;has worse&#160;<br/>precision-recall&#160;curves.<br/>
<hr/>
<a name=95></a>Generating&#160;the parts of&#160;an object&#160;<br/>
•&#160;One&#160;way&#160;to&#160;maintain&#160;the&#160;<br/>
“square”<br/>
pose&#160;parameters&#160;<br/>
+<br/>
constraints&#160;between&#160;the&#160;parts&#160;is&#160;<br/>to&#160;generate&#160;each&#160;part&#160;very&#160;<br/>
sloppy&#160;&#160;top-down&#160;<br/>
accurately<br/>
activation&#160;of&#160;parts<br/>
–&#160;But&#160;this&#160;would&#160;require&#160;a&#160;lot&#160;of&#160;<br/>
communication&#160;bandwidth.<br/>
•&#160;Sloppy&#160;top-down&#160;specification&#160;of&#160;<br/>
features&#160;with&#160;<br/>
the&#160;parts&#160;is&#160;less&#160;demanding&#160;<br/>
top-down&#160;<br/>
–&#160;but&#160;it&#160;messes&#160;up&#160;relationships&#160;<br/>
support<br/>
between&#160;features<br/>
–&#160;so&#160;use&#160;redundant&#160;features&#160;<br/>
and&#160;use&#160;lateral&#160;interactions&#160;to&#160;<br/>
clean-up&#160;using&#160;<br/>
clean&#160;up&#160;the&#160;mess.<br/>
known&#160;interactions<br/>
•&#160;Each&#160;transformed&#160;feature&#160;helps&#160;<br/>
to&#160;locate&#160;the&#160;others<br/>
–&#160;This&#160;allows&#160;a&#160;noisy&#160;channel<br/>
Its&#160;like&#160;soldiers&#160;on&#160;<br/>a&#160;parade&#160;ground<br/>
<hr/>
<a name=96></a>Semi-restricted&#160;Boltzmann&#160;Machines<br/>
•&#160;We&#160;restrict&#160;the connectivity&#160;to make&#160;<br/>
learning&#160;easier.<br/>
hidden<br/>
•&#160;Contrastive&#160;divergence&#160;learning&#160;requires&#160;<br/>
the&#160;hidden&#160;units to be in&#160;conditional&#160;<br/>
j<br/>
equilibrium&#160;with&#160;the visibles.<br/>
–&#160;But&#160;it&#160;does&#160;not&#160;require&#160;the&#160;visible&#160;units&#160;<br/>
to&#160;be in&#160;conditional&#160;equilibrium&#160;with&#160;<br/>
i<br/>
the&#160;hiddens.<br/>
visible<br/>
–&#160;All we&#160;require&#160;is that&#160;the visible&#160;units&#160;<br/>
are&#160;closer&#160;to equilibrium&#160;in&#160;the&#160;<br/>reconstructions than&#160;in&#160;the&#160;data.<br/>
•&#160;So&#160;we&#160;can&#160;allow&#160;connections&#160;between&#160;<br/>
the&#160;visibles.<br/>
<hr/>
<a name=97></a>Learning&#160;a semi-restricted Boltzmann&#160;Machine<br/>
1.&#160;Start&#160;with a&#160;<br/>
j<br/>
j<br/>
training&#160;vector&#160;on&#160;the&#160;<br/>visible&#160;units.<br/>
0<br/>
<i>v&#160;</i><br/>
1<br/>
<i>v&#160;</i><br/>
<i>ih&#160;j</i><br/>
<i>ih&#160;j</i><br/>
2.&#160;Update&#160;all of&#160;the&#160;<br/>hidden&#160;units&#160;in&#160;<br/>
i<br/>
k<br/>
i<br/>
parallel<br/>
k<br/>
i<br/>
k<br/>
i<br/>
k<br/>
3.&#160;Repeatedly&#160;update&#160;<br/>
t&#160;=&#160;0 &#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;&#160;t&#160;=&#160;1 &#160;&#160;<br/>
all of&#160;the&#160;visible units&#160;<br/>
data<br/>
reconstruction<br/>
in&#160;parallel&#160;using&#160;<br/>mean-field&#160;updates&#160;<br/>
<i>w&#160;</i>&#160;&#160;(<br/>
0<br/>
1<br/>
<i>v&#160;h&#160;</i>&#160;&#160;<i>v&#160;h&#160;</i>&#160;)<br/>
(with&#160;the&#160;hiddens&#160;<br/>
<i>ij</i><br/>
<i>i&#160;j</i><br/>
<i>i&#160;j</i><br/>
fixed)&#160;to&#160;get&#160;a&#160;<br/>“reconstruction”.<br/>
<i>l&#160;</i>&#160;&#160;(<br/>
0<br/>
1<br/>
<i>v&#160;v&#160;</i>&#160;&#160;<i>v&#160;v&#160;</i>&#160;)<br/>
<i>ik</i><br/>
<i>i&#160;k</i><br/>
<i>i&#160;k</i><br/>
4.&#160;Update&#160;all of&#160;the&#160;<br/>
update&#160;for&#160;a&#160;<br/>
hidden&#160;units&#160;again.&#160;<br/>
lateral&#160;weight<br/>
<hr/>
<a name=98></a>Learning&#160;in&#160;Semi-restricted&#160;Boltzmann&#160;<br/>
Machines&#160;<br/>
•&#160;Method&#160;1:&#160;To&#160;form a&#160;reconstruction, cycle&#160;<br/>
through the visible&#160;units&#160;updating&#160;each in turn&#160;<br/>using the&#160;top-down&#160;input from the&#160;hiddens&#160;plus&#160;<br/>the&#160;lateral&#160;input from the&#160;other&#160;visibles.&#160;<br/>
•&#160;Method&#160;2:&#160;Use&#160;“mean&#160;field” visible&#160;units&#160;that&#160;<br/>
have&#160;real&#160;values.&#160;Update&#160;them all in parallel.<br/>
–&#160;Use&#160;damping&#160;to prevent oscillations<br/>
<i>t&#160;</i>1<br/>
<br/>
<i>t</i><br/>
<i>p</i><br/>
&#160;<i>p</i><br/>
&#160;&#160;(1&#160;)&#160;&#160;(<i>x&#160;</i>)<br/>
<i>i</i><br/>
<i>i</i><br/>
<i>i</i><br/>
damping<br/>
total&#160;input to&#160;i<br/>
<hr/>
<a name=99></a>Results&#160;on&#160;modeling&#160;natural&#160;image&#160;patches&#160;<br/>
using&#160;a stack&#160;of&#160;RBM’s&#160;(Osindero&#160;and Hinton)<br/>
•&#160;Stack&#160;of&#160;RBM’s&#160;learned&#160;one&#160;at&#160;a&#160;time.<br/>
1000&#160;top-<br/>
•&#160;400&#160;Gaussian&#160;visible units&#160;that&#160;see&#160;<br/>
level&#160;units.&#160;<br/>
whitened&#160;image&#160;patches<br/>
No&#160;MRF.<br/>
–&#160;Derived&#160;from&#160;100,000&#160;Van&#160;Hateren&#160;<br/>
Undirected&#160;Connections<br/>
image&#160;patches,&#160;each&#160;20x20&#160;<br/>
•<br/>
Hidden&#160;<br/>
The&#160;hidden&#160;units&#160;are&#160;all binary.<br/>
MRF with&#160;<br/>
–&#160;The&#160;lateral&#160;connections&#160;are&#160;<br/>
500&#160;units<br/>
learned&#160;when&#160;they&#160;are&#160;the&#160;visible&#160;<br/>units&#160;of&#160;their&#160;RBM.<br/>
Directed&#160;Connections<br/>
•&#160;Reconstruction&#160;involves letting the&#160;<br/>
Hidden&#160;<br/>
visible&#160;units&#160;of&#160;each&#160;RBM settle&#160;using&#160;<br/>
MRF with&#160;<br/>
mean-field&#160;dynamics.<br/>
2000&#160;units<br/>
–&#160;The&#160;already&#160;decided&#160;states&#160;in the&#160;<br/>
Directed&#160;Connections<br/>
level&#160;above&#160;determine&#160;the&#160;effective&#160;<br/>biases&#160;during&#160;mean-field&#160;settling.&#160;<br/>
400&#160;<br/>Gaussian&#160;<br/>units&#160;<br/>
<hr/>
<a name=100></a><img src="./Hinton_1-100_1.jpg"/><br/>
<img src="./Hinton_1-100_2.png"/><br/>
<img src="./Hinton_1-100_3.jpg"/><br/>
<img src="./Hinton_1-100_4.png"/><br/>
<img src="./Hinton_1-100_5.jpg"/><br/>
<img src="./Hinton_1-100_6.png"/><br/>
<img src="./Hinton_1-100_7.jpg"/><br/>
<img src="./Hinton_1-100_8.png"/><br/>
Without&#160;lateral connections<br/>
real data<br/>
samples from&#160;model<br/>
<hr/>
<a name=101></a><img src="./Hinton_1-101_1.jpg"/><br/>
<img src="./Hinton_1-101_2.png"/><br/>
<img src="./Hinton_1-101_3.jpg"/><br/>
<img src="./Hinton_1-101_4.png"/><br/>
<img src="./Hinton_1-101_5.jpg"/><br/>
<img src="./Hinton_1-101_6.png"/><br/>
<img src="./Hinton_1-101_7.jpg"/><br/>
<img src="./Hinton_1-101_8.png"/><br/>
With&#160;lateral connections<br/>
real data<br/>
samples from&#160;model<br/>
<hr/>
<a name=102></a>A&#160;funny way to use an&#160;MRF<br/>
•&#160;The&#160;lateral&#160;connections&#160;form&#160;an MRF.<br/>•&#160;The&#160;MRF&#160;is used&#160;during&#160;learning&#160;and&#160;generation.<br/>•&#160;The&#160;MRF is&#160;not&#160;used&#160;for inference.<br/>
–&#160;This&#160;is &#160;a novel&#160;idea&#160;so vision&#160;researchers&#160;don’t like&#160;it.<br/>
•&#160;The&#160;MRF enforces constraints.&#160;During&#160;inference,&#160;<br/>
constraints&#160;do&#160;not need&#160;to&#160;be&#160;enforced&#160;because&#160;the data&#160;<br/>obeys them.<br/>
–&#160;The&#160;constraints only&#160;need&#160;to be enforced during&#160;<br/>
generation.<br/>
•&#160;Unobserved&#160;hidden&#160;units cannot enforce constraints.<br/>
–&#160;To&#160;enforce constraints&#160;requires&#160;lateral&#160;connections&#160;or&#160;<br/>
observed descendants.<br/>
<hr/>
<a name=103></a>Why&#160;do we whiten&#160;data?<br/>
•&#160;Images&#160;typically&#160;have&#160;strong&#160;pair-wise&#160;correlations.<br/>•&#160;Learning&#160;higher&#160;order statistics&#160;is difficult when&#160;there are&#160;<br/>
strong&#160;pair-wise&#160;correlations.<br/>
–&#160;Small&#160;changes&#160;in&#160;parameter&#160;values&#160;that improve&#160;the&#160;<br/>
modeling&#160;of higher-order&#160;statistics&#160;may&#160;be rejected&#160;<br/>because they form&#160;a slightly&#160;worse&#160;model&#160;of&#160;the&#160;much&#160;<br/>stronger pair-wise&#160;statistics.<br/>
•&#160;So&#160;we often&#160;remove the second-order&#160;statistics&#160;before&#160;<br/>
trying&#160;to learn&#160;the&#160;higher-order&#160;statistics.<br/>
<hr/>
<a name=104></a>Whitening&#160;the&#160;learning&#160;signal&#160;instead&#160;<br/>
of&#160;the&#160;data<br/>
•&#160;Contrastive&#160;divergence&#160;learning&#160;can remove the effects&#160;<br/>
of&#160;the&#160;second-order&#160;statistics&#160;on the&#160;learning&#160;without&#160;<br/>actually changing&#160;the&#160;data.<br/>
–&#160;The&#160;lateral&#160;connections&#160;model&#160;the&#160;second&#160;order&#160;<br/>
statistics<br/>
–&#160;If&#160;a&#160;pixel&#160;can be reconstructed correctly&#160;using&#160;second&#160;<br/>
order statistics,&#160;its&#160;will&#160;be the&#160;same in the&#160;<br/>reconstruction as&#160;in&#160;the&#160;data.&#160;<br/>
–&#160;The&#160;hidden&#160;units can&#160;then&#160;focus on&#160;modeling&#160;high-<br/>
order structure&#160;that cannot be predicted&#160;by the&#160;lateral&#160;<br/>connections.<br/>
•&#160;For&#160;example,&#160;a&#160;pixel close&#160;to&#160;an&#160;edge,&#160;where&#160;interpolation&#160;<br/>
from&#160;nearby&#160;pixels causes&#160;incorrect&#160;smoothing.<br/>
<hr/>
<a name=105></a>Towards&#160;a more&#160;powerful,&#160;multi-linear&#160;<br/>
stackable&#160;learning module<br/>
•&#160;So&#160;far,&#160;the&#160;states&#160;of&#160;the&#160;units in&#160;one&#160;layer&#160;have only&#160;been&#160;<br/>
used&#160;to&#160;determine&#160;the effective&#160;biases&#160;of the&#160;units&#160;in&#160;the&#160;<br/>layer&#160;below.<br/>
•&#160;It&#160;would&#160;be much&#160;more&#160;powerful&#160;to modulate&#160;the&#160;pair-wise&#160;<br/>
interactions in&#160;the&#160;layer&#160;below.&#160;<br/>
–&#160;A&#160;good&#160;way to&#160;design&#160;a&#160;hierarchical&#160;system&#160;is to allow&#160;<br/>
each&#160;level&#160;to determine&#160;the&#160;objective&#160;function of the level&#160;<br/>below.&#160;<br/>
•&#160;To&#160;modulate&#160;pair-wise&#160;interactions&#160;we&#160;need&#160;higher-order&#160;<br/>
Boltzmann&#160;machines.&#160;<br/>
<hr/>
<a name=106></a>Higher&#160;order&#160;Boltzmann&#160;machines&#160;<br/>
(Sejnowski, ~1986)<br/>
•&#160;The&#160;usual&#160;energy&#160;function is quadratic&#160;in&#160;the&#160;states:<br/>
<i>E&#160;</i>&#160;<i>bias&#160;terms&#160;</i>&#160;&#160;<i>iss&#160;j&#160;ij</i><br/>
<i>w</i><br/>
<i>i</i>&#160;<i>j</i><br/>
•&#160;But&#160;we&#160;could&#160;use higher&#160;order interactions:&#160;<br/>
<i>E&#160;</i>&#160;<i>bias&#160;terms&#160;</i>&#160;&#160;<i>iss&#160;jsk&#160;ijk</i><br/>
<i>w</i><br/>
<i>i</i>&#160;<i>j</i><i>k</i><br/>
•&#160;Unit&#160;k acts as&#160;a switch. When unit k is on,&#160;it switches&#160;<br/>
in&#160;the&#160;pairwise&#160;interaction&#160;between&#160;unit&#160;i and&#160;unit&#160;j.&#160;<br/>
–&#160;Units&#160;i and&#160;j&#160;can also&#160;be viewed&#160;as switches&#160;that&#160;<br/>
control&#160;the pairwise&#160;interactions&#160;between&#160;j&#160;and k&#160;<br/>or&#160;between&#160;i and k.<br/>
<hr/>
<a name=107></a>Using&#160;higher-order&#160;Boltzmann&#160;machines to&#160;<br/>
model&#160;image&#160;transformations&#160;<br/>
(the unfactored&#160;version)<br/>
•&#160;A&#160;global&#160;transformation&#160;specifies&#160;which pixel&#160;<br/>
goes to&#160;which&#160;other&#160;pixel.<br/>
•&#160;Conversely, each pair of similar&#160;intensity&#160;pixels,&#160;<br/>
one in each image,&#160;votes&#160;for&#160;a particular&#160;global&#160;<br/>transformation.<br/>
image&#160;transformation<br/>
image(t)<br/>
image(t+1)<br/>
<hr/>
<a name=108></a>Factoring&#160;three-way&#160;&#160; &#160; &#160; &#160; &#160;&#160;&#160;<br/>
multiplicative&#160;interactions<br/>
&#160;<i>E&#160;</i>&#160;<i>s&#160;s&#160;s&#160;w</i><br/>
unfactored<br/>
<i>i</i><br/>
<i>j&#160;h</i><br/>
<i>ijh</i><br/>
<i>i</i>,&#160;<i>j</i>,<i>h</i><br/>
with&#160;cubically&#160;<br/>many parameters<br/>
&#160;<i>E&#160;</i>&#160;<i>s&#160;s&#160;s&#160;w&#160;w&#160;w</i><br/>
factored&#160;&#160; &#160;&#160;&#160; &#160;&#160;<br/>
<i>i</i><br/>
<i>j&#160;h</i><br/>
<i>if</i><br/>
<i>jf</i><br/>
<i>hf</i><br/>
<i>f</i><br/>
<i>i</i>,&#160;<i>j</i>,<i>h</i><br/>
with linearly&#160;<br/>many&#160;parameters&#160;<br/>per factor.<br/>
<hr/>
<a name=109></a>A&#160;picture of the low-rank&#160;tensor&#160;<br/>
contributed&#160;by factor f<br/>
<i>wjf</i><br/>
Each&#160;layer&#160;is a scaled&#160;version&#160;<br/>of&#160;the&#160;same matrix.&#160;<br/>
<i>whf</i><br/>
The&#160;basis&#160;matrix&#160;is specified&#160;<br/>
<i>wif</i><br/>
as&#160;an&#160;outer product&#160;with&#160;<br/>typical&#160;term&#160;<i>w&#160;w</i><br/>
<i>if</i><br/>
<i>jf</i><br/>
So&#160;each&#160;active hidden&#160;unit&#160;<br/>contributes&#160;a scalar,&#160;&#160;&#160;&#160;&#160; &#160;&#160;<br/>
<i>w&#160;</i>&#160;<br/>
<i>hf</i><br/>
times&#160;the matrix&#160;specified&#160;by&#160;<br/>factor&#160;f .<br/>
<hr/>
<a name=110></a>Inference&#160;with factored three-way&#160;<br/>
multiplicative&#160;interactions<br/>
<br/>
The&#160;energy&#160;<br/>
<i>E&#160;</i><br/>
<i>s&#160;s&#160;s&#160;w&#160;w&#160;w</i><br/>
<i>f</i><br/>
&#160;<i>i&#160;j&#160;h&#160;if&#160;jf&#160;hf</i><br/>
contributed&#160;by&#160;<br/>
<i>i</i>,&#160;<i>j</i>,<i>h</i><br/>
factor&#160;f.<br/>
<i>E&#160;</i>(<i>s&#160;</i>&#160;0)&#160;&#160;<i>E&#160;</i>(<i>s&#160;</i>&#160;)1<br/>
<i>w</i><br/>
<i>s&#160;w</i><br/>
<i>s&#160;w</i><br/>
<i>f</i><br/>
<i>h</i><br/>
<i>f</i><br/>
<i>h</i><br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<br/>
<i>hf&#160;</i>&#160;<i>i&#160;if&#160;</i><br/>
&#160;&#160;<i>j&#160;jf&#160;</i><br/>
&#160;<i>i</i><br/>
<br/>
&#160;<i>j</i><br/>
<br/>
How&#160;changing&#160;the&#160;binary&#160;state&#160;<br/>
What&#160;unit&#160;h&#160;needs&#160;<br/>
of&#160;unit&#160;h&#160;changes&#160;the&#160;energy&#160;<br/>
to&#160;know&#160;in order&#160;to&#160;<br/>
contributed&#160;by&#160;factor&#160;f.<br/>
do&#160;Gibbs&#160;sampling<br/>
<hr/>
<a name=111></a>Belief&#160;propagation<br/>
<i>h</i><br/>
The&#160;outgoing&#160;message&#160;<br/>
<i>whf</i><br/>
at&#160;each&#160;vertex&#160;of&#160;the&#160;<br/>factor&#160;is the product&#160;of&#160;<br/>the&#160;weighted&#160;sums at&#160;<br/>
<i>f</i><br/>
the&#160;other two&#160;vertices.<br/>
<i>wif</i><br/>
<i>wjf</i><br/>
<i>i</i><br/>
<i>j</i><br/>
<hr/>
<a name=112></a>Learning&#160;with factored&#160;three-way&#160;<br/>
multiplicative&#160;interactions<br/>
<br/>
<br/>
<br/>
<br/>
<i>h</i><br/>
&#160;<br/>
<br/>
<br/>
<br/>
<i>m</i><br/>
<i>s&#160;w</i><br/>
<i>s&#160;w</i><br/>
<br/>
<br/>
<i>f</i><br/>
<i>i</i><br/>
<i>if</i><br/>
<i>j</i><br/>
<i>jf</i><br/>
<br/>
<br/>
<br/>
<br/>
&#160;<i>i</i><br/>
<br/>
&#160;<i>j</i><br/>
<br/>
message&#160;<br/>from&#160;factor&#160;f&#160;<br/>to&#160;unit&#160;h<br/>
<i>E</i><br/>
<br/>
<i>E</i><br/>
<br/>
<i>f</i><br/>
<i>f</i><br/>
<i>w</i><br/>
<br/>
&#160;<br/>
&#160;<br/>
<i>hf</i><br/>
<i>w</i><br/>
<br/>
<i>w</i><br/>
<br/>
<i>hf</i><br/>
<i>hf</i><br/>
data<br/>
model<br/>
<i>h</i><br/>
<i>h</i><br/>
&#160;<i>s&#160;m</i><br/>
&#160;<i>s&#160;m</i><br/>
<i>h</i><br/>
<i>f</i><br/>
<i>h</i><br/>
<i>f</i><br/>
data<br/>
d<br/>
mo&#160;el<br/>
<hr/>
<a name=113></a>Roland&#160;data<br/>
<hr/>
<a name=114></a>Modeling&#160;the&#160;correlational&#160;structure of a static&#160;image&#160;<br/>
by&#160;using&#160;two&#160;copies of the image<br/>
Each&#160;factor sends the&#160;<br/>
<i>h</i><br/>
squared output&#160;of a&#160;linear&#160;<br/>filter&#160;to the hidden&#160;units.<br/>
<i>whf</i><br/>
It&#160;is exactly&#160;the&#160;standard&#160;<br/>model&#160;of&#160;simple&#160;and&#160;<br/>
<i>f</i><br/>
complex&#160;cells.&#160;It&#160;allows&#160;<br/>complex&#160;cells&#160;to extract&#160;<br/>
<i>w</i><br/>
<i>wjf</i><br/>
<i>if</i><br/>
oriented energy.<br/>
<i>i</i><br/>
<i>j</i><br/>
The&#160;standard model&#160;drops&#160;<br/>out&#160;of doing&#160;belief&#160;<br/>propagation&#160;for&#160;&#160;a&#160;factored&#160;<br/>
Copy 1<br/>
Copy 2<br/>
third-order energy&#160;function.&#160;<br/>
<hr/>
<a name=115></a>An&#160;advantage&#160;of modeling&#160;correlations&#160;<br/>
between&#160;pixels&#160;rather&#160;than pixels<br/>
•&#160;During&#160;generation, a “vertical&#160;edge”&#160;unit can&#160;turn&#160;off&#160;<br/>
the&#160;horizontal&#160;interpolation&#160;in a region&#160;without&#160;<br/>worrying&#160;about&#160;exactly&#160;where&#160;the intensity&#160;<br/>discontinuity&#160;will be.<br/>
–&#160;This&#160;gives&#160;some&#160;translational&#160;invariance<br/>–&#160;It&#160;also gives&#160;a&#160;lot&#160;of invariance&#160;to brightness&#160;and&#160;<br/>
contrast.<br/>
–&#160;So&#160;the&#160;“vertical&#160;edge” unit&#160;is like&#160;a&#160;complex&#160;cell.<br/>
•&#160;By&#160;modulating&#160;the&#160;correlations&#160;between&#160;pixels&#160;rather&#160;<br/>
than&#160;the&#160;pixel&#160;intensities,&#160;the generative&#160;model&#160;can&#160;<br/>still&#160;allow&#160;interpolation parallel&#160;to&#160;the edge.<br/>
<hr/>
<a name=116></a>A&#160;principle&#160;of hierarchical&#160;systems<br/>
•&#160;Each&#160;level in the&#160;hierarchy&#160;should&#160;not try to&#160;<br/>
micro-manage&#160;the&#160;level below.<br/>
•&#160;Instead,&#160;it should create&#160;an&#160;objective function for&#160;<br/>
the&#160;level below&#160;and&#160;leave the&#160;level below&#160;to&#160;<br/>optimize&#160;it.<br/>
–&#160;This&#160;allows&#160;the&#160;fine details&#160;of&#160;the&#160;solution&#160;to&#160;<br/>
be&#160;decided locally&#160;where&#160;the&#160;detailed&#160;<br/>information&#160;is&#160;available.<br/>
•&#160;Objective functions&#160;are a&#160;good&#160;way&#160;to&#160;do&#160;<br/>
abstraction.&#160;<br/>
<hr/>
<a name=117></a>Time series&#160;models<br/>
•&#160;Inference&#160;is&#160;difficult in directed&#160;models&#160;of time&#160;<br/>
series if&#160;we use non-linear&#160;distributed&#160;<br/>representations&#160;in&#160;the hidden units.<br/>
–&#160;It&#160;is&#160;hard&#160;to&#160;fit Dynamic&#160;Bayes Nets&#160;to high-<br/>
dimensional&#160;sequences&#160;(e.g motion&#160;capture&#160;<br/>data).&#160;<br/>
•&#160;So&#160;people&#160;tend to avoid&#160;distributed&#160;<br/>
representations&#160;and use&#160;much weaker&#160;methods&#160;<br/>(e.g.&#160;HMM’s).<br/>
<hr/>
<a name=118></a>Time series&#160;models<br/>
•&#160;If&#160;we&#160;really&#160;need&#160;distributed&#160;representations&#160;(which&#160;we&#160;<br/>
nearly always&#160;do),&#160;we&#160;can make inference&#160;much simpler&#160;<br/>by&#160;using&#160;three tricks:<br/>
–&#160;Use&#160;an&#160;RBM&#160;for&#160;the&#160;interactions&#160;between&#160;hidden&#160;and&#160;<br/>
visible&#160;variables.&#160;This ensures&#160;that the&#160;main&#160;source of&#160;<br/>information&#160;wants the&#160;posterior&#160;to be factorial.<br/>
–&#160;Model&#160;short-range temporal&#160;information&#160;by&#160;allowing&#160;<br/>
several&#160;previous&#160;frames&#160;to provide&#160;input to&#160;the&#160;hidden&#160;<br/>units and&#160;to the&#160;visible&#160;units.<br/>
•&#160;This&#160;leads&#160;to a&#160;temporal&#160;module&#160;that can&#160;be stacked<br/>
–&#160;So&#160;we&#160;can&#160;use&#160;greedy&#160;learning&#160;to&#160;learn&#160;deep&#160;models&#160;<br/>
of&#160;temporal&#160;structure.&#160;<br/>
<hr/>
<a name=119></a>An&#160;application&#160;to modeling&#160;<br/>
motion&#160;capture data&#160;<br/>
(Taylor, Roweis&#160;&amp;&#160;Hinton,&#160;2007)<br/>
•&#160;Human&#160;motion&#160;can&#160;be&#160;captured&#160;by&#160;placing&#160;<br/>
reflective&#160;markers&#160;on&#160;the&#160;joints and&#160;then using&#160;<br/>lots&#160;of infrared&#160;cameras&#160;to&#160;track the&#160;3-D&#160;<br/>positions&#160;of&#160;the&#160;markers.<br/>
•&#160;Given a skeletal&#160;model,&#160;the&#160;3-D&#160;positions&#160;of&#160;the&#160;<br/>
markers&#160;can be converted into&#160;the&#160;joint angles&#160;<br/>plus&#160;6 parameters&#160;that describe the&#160;3-D&#160;position &#160;<br/>and the&#160;roll,&#160;pitch and&#160;yaw of the pelvis.<br/>
–&#160;We&#160;only&#160;represent&#160;changes&#160;in&#160;yaw&#160;because&#160;physics&#160;<br/>
doesn’t&#160;care about its value&#160;and&#160;we&#160;want&#160;to avoid&#160;<br/>circular variables.<br/>
<hr/>
<a name=120></a>The&#160;conditional&#160;RBM model&#160;<br/>
(a&#160;partially&#160;observed&#160;CRF)<br/>
<i>j</i><br/>
•&#160;Start&#160;with&#160;a generic&#160;RBM.<br/>•<br/>
h<br/>
Add two types of conditioning&#160;<br/>connections.<br/>
•&#160;Given the&#160;data,&#160;the&#160;hidden&#160;units&#160;<br/>
at&#160;time&#160;t are&#160;conditionally&#160;<br/>independent.<br/>
<i>i</i><br/>
•&#160;The&#160;autoregressive weights&#160;can&#160;<br/>
v<br/>
model&#160;most short-term temporal&#160;<br/>structure&#160;very&#160;well,&#160;leaving the&#160;<br/>hidden&#160;units&#160;to model&#160;nonlinear&#160;<br/>irregularities&#160;(such as&#160;when&#160;the&#160;<br/>foot&#160;hits&#160;the&#160;ground).<br/>
t-2<br/>
t-1<br/>
t<br/>
<hr/>
<a name=121></a>Causal&#160;generation&#160;from&#160;a&#160;learned&#160;model<br/>
•&#160;Keep the&#160;previous&#160;visible&#160;states fixed.<br/>
<i>j</i><br/>
–&#160;They&#160;provide&#160;a&#160;time-dependent&#160;<br/>
bias for&#160;the hidden&#160;units.<br/>
•&#160;Perform&#160;alternating&#160;Gibbs sampling&#160;<br/>
for&#160;a&#160;few iterations&#160;between&#160;the&#160;<br/>hidden&#160;units and&#160;the&#160;most recent&#160;<br/>visible&#160;units.<br/>
<i>i</i><br/>
–&#160;This&#160;picks&#160;new&#160;hidden&#160;and&#160;visible&#160;<br/>
states&#160;that&#160;are compatible&#160;with&#160;<br/>each other and&#160;with the&#160;recent&#160;<br/>history.<br/>
<hr/>
<a name=122></a>Higher&#160;level&#160;models<br/>
•<br/>
<i>k</i><br/>
Once&#160;we&#160;have&#160;trained&#160;the&#160;model,&#160;we&#160;can&#160;<br/>add&#160;layers&#160;like&#160;in&#160;a&#160;Deep&#160;Belief&#160;Network.<br/>
•&#160;The&#160;previous&#160;layer CRBM&#160;is kept,&#160;and&#160;its&#160;<br/>
output,&#160;while driven&#160;by&#160;the&#160;data&#160;is treated&#160;<br/>
as&#160;a&#160;new&#160;kind of&#160;“fully&#160;observed”&#160;data.<br/>
•<br/>
<i>j</i><br/>
The&#160;next&#160;level CRBM has&#160;the&#160;same&#160;<br/>architecture&#160;as&#160;the&#160;first&#160;(though&#160;we&#160;can&#160;<br/>alter&#160;the&#160;number&#160;of&#160;units&#160;it&#160;uses)&#160;and&#160;is&#160;<br/>trained&#160;the&#160;same&#160;way.<br/>
•&#160;Upper&#160;levels of&#160;the&#160;network&#160;model&#160;more&#160;<br/>
“abstract”&#160;concepts.<br/>
<i>i</i><br/>
•&#160;This&#160;greedy&#160;learning&#160;procedure&#160;can&#160;be&#160;<br/>
justified&#160;using&#160;a variational&#160;bound.<br/>
t-2<br/>
t-1<br/>
t<br/>
<hr/>
<a name=123></a><img src="./Hinton_1-123_1.png"/><br/>
Learning&#160;with “style” labels<br/>
<i>k</i><br/>
<i>l</i><br/>
•&#160;As&#160;in&#160;the&#160;generative&#160;model&#160;of&#160;<br/>
handwritten&#160;digits&#160;(Hinton&#160;et&#160;al.&#160;<br/>2006), style labels&#160;can be&#160;<br/>
<br/>
provided&#160;as part of the&#160;input to&#160;<br/>
<i>j</i><br/>
the&#160;top layer.<br/>
•&#160;The&#160;labels&#160;are represented&#160;by&#160;<br/>
<i>i</i><br/>
turning on one unit&#160;in&#160;a&#160;group of&#160;<br/>units,&#160;but they&#160;can also&#160;be&#160;<br/>blended.<br/>
t-2<br/>
t-1<br/>
t<br/>
<hr/>
<a name=124></a>Show&#160;demo’s&#160;of multiple&#160;styles of&#160;<br/>
walking<br/>
These&#160;can&#160;be&#160;found&#160;at&#160;<br/>
www.cs.toronto.edu/~gwtaylor/<br/>
<hr/>
<a name=125></a>Readings&#160;on deep&#160;belief&#160;nets<br/>
A&#160;reading&#160;list&#160;(that is still being&#160;updated)&#160;can be&#160;<br/>
found at&#160;<br/>
www.cs.toronto.edu/~hinton/deeprefs.html<br/>
<hr/>
</body>
</html>
